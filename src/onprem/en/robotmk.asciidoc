// -*- coding: utf-8 -*-
// IGNORE + MyApp1 MyApplication_mybot mybot × →
// NONASCII →
include::global_attr.adoc[]
= {CMK} Synthetic Monitoring with Robotmk
:revdate: 2024-07-31
:title: {CMK} Synthetic Monitoring with Robotmk
:description: {CMK} Synthetic Monitoring integrates software testing based on Robot Framework into your monitoring.

{related-start}
xref:wato_monitoringagents#[Monitoring agents]
xref:agent_deployment#[Automatic agent updates]
{related-end}


[#intro]
== Synthetic monitoring with Robot Framework

{cee-only} {CMK} Synthetic Monitoring is available in the commercial {CMK} editions, but it requires an link:https://checkmk.com/request-quote/synthetic-monitoring[additional subscription^].
You can however test the function with up to three tests free of charge and without a time limit.

With {CMK} you can monitor your own infrastructure very closely -- right down to the question of whether a particular service, such as a web server, is running properly.
If your website is operated via a third-party cloud service, you will not have access to the service itself, but you can use an HTTP check to verify whether the website is accessible.
But will that say anything about the user experience? The fact that an online store is accessible does not mean that navigation, ordering processes and the like work smoothly.

This is where {CMK} Synthetic Monitoring comes in.
With the Robotmk plug-in, {CMK} offers genuine end-to-end monitoring, i.e. the monitoring of running applications from the user's perspective.
The actual testing is carried out by the open-source software link:https://robotframework.org/[Robot Framework^] -- of which {comfull} is also a member.

The automation software can be used to fully replicate a user's behavior, for example to simulate order processes in online stores, 'click-by-click'.
The special thing about Robot Framework is that tests are not written in a fully-fledged programming language, but are defined using easy-to-use keywords such as `Open Browser` or `Click Button`.
An `Open Browser checkmk.com` is sufficient to call up the {CMK} website.
Several test cases are then combined in so-called test suites (in the form of a `.robot` file).

Robotmk can now trigger these Robot Framework test suites on the host and monitor their execution and results as services in {CMK}.
In the {CMK} web interface you will then find the status, associated performance graphs and the original evaluations of Robot Framework itself.


=== Components

Multiple components work together to create this end-to-end monitoring, so here is a brief overview.


==== {CMK} server

{CMK} Synthetic monitoring is realized via Robotmk, which uses an agent plug-in as a data collector, and the Robotmk scheduler (on the monitored host) for triggering Robot Framework projects.
Synthetic monitoring is activated and configured via the [.guihint]#Robotmk Scheduler# rule.
Here you specify which test suites should be executed and how exactly Robot Framework should start them -- summarized in a _plan._
Once rolled out, the Robotmk scheduler on the target host ensures the scheduled execution of your Robot Framework suites.

In the monitoring, a number of new services will be generated: [.guihint]#RMK Scheduler Status# shows the status of the scheduler itself, i.e. whether test suites could be started successfully.
There are also services for all configured test plans (such as [.guihint]#RMK MyApp1 Plan#) and individual tests from test suites (such as [.guihint]#RMK MyApp1 Test#).
The services of the individual tests also include the original Robot Framework reports.

Then there are two optional service rules: [.guihint]#Robotmk plan# and [.guihint]#Robotmk test# provide for fine-tuning the plan and test services -- for example, to effect status changes at certain runtimes.

////  
// Translation - begin

Zu guter Letzt existieren noch zwei Regeln zum _KPI-Monitoring:_ KPI steht für Key Performance Indicator und meint in diesem Kontext einzelne Keywords.
Über die Regel [.guihint]#Robotmk KPI discovery# lassen sich Keywords als separate Services ins Monitoring holen und über [.guihint]#Robotmk KPI monitoring# entsprechend auswerten.
Wie genau das Keyword-Monitoring funktioniert, zeigen wir unten in einem separaten Kapitel.

Etwas abseits der normalen Regeln gibt es im Bereich [.guihint]#Setup# noch das Feature [.guihint]#Managed robots.#
Die Kurzversion: Robots, die auf dem {CMK}-Server verwaltet und via {CMK}-Agent ausgerollt werden -- für Details steht abermals ein eigenes Kapitel zur Verfügung.

//// 
// Translation - end

.The Robotmk rules in {CMK}
image::robotmk_services_menu.png[alt="Robotmk rules in the setup menu."]


==== Test machine

You can provide the Robot Framework test suites on a Windows or Linux host.
For execution, Robot Framework requires access to their dependencies (Python, libraries, drivers for browser automation and so on).
This configuration is independent of {CMK} and can be stored declaratively in a portable package.
This is performed with the open-source command line tool link:https://github.com/robocorp/rcc[RCC^].
This tool uses your configuration files in YAML format to build virtual Python environments including dependencies and the Robot Framework itself.
The Robotmk scheduler running as a background process triggers this build and then executes the tests itself.

Such an _RCC automation package_ with the package configuration (`robot.yaml`), the definition of the execution environment (`conda.yaml`) and the test suites (`tests.robot`) is also called _robot_.
RCC and the scheduler are rolled out with the {CMK} agent, the automation package must be available on the host.

The great advantage of RCC is that the executing test host itself does not require a configured Python environment.

The agent itself is only required for the transfer of results, logs and screenshots.
This also enables the monitoring of very long-running or locally very resource-intensive suites -- provided that your Windows host has the corresponding capacities.


//// 
// Translation - begin

Ein Wort noch zu den Betriebssystemen der Test-Hosts -- Windows und Linux verhalten sich nämlich minimal unterschiedlich.
Insbesondere weichen freilich die gesetzten Pfade ab; in den folgenden Beispielen führen wir nur Windows-Pfade an (sofern nicht wirklich explizite Pfade benötigt werden).
Für den Fall, dass RCC offline arbeiten muss, gibt es zudem Unterschiede bezüglich Nutzerkontext des Robotmk-Schedulers und der nötigen Befehle -- hier gehen wir natürlich explizit auf beide Systeme ein. 

Und auch wenn es nicht direkt mit {CMK} zu tun hat: Die link:https://robotframework-browser.org/[Browser-Bibliothek von Robot Framework^] nutzt Playwright -- und Playwright läuft nicht auf allen von {CMK} unterstützten Linux-Systemen.
Beachten Sie die entsprechenden link:https://playwright.dev/docs/intro#system-requirements[Systemvoraussetzungen.^]

//// 
// Translation - end

[#ruleconfig]
== Monitoring test suites with Robotmk

In the following, we will show you how to include a test suite in the monitoring.
As an example we will use a simple Hello World suite which only outputs two strings and which waits briefly between each.
An introduction to Robot Framework is of course not the subject of this article, but a brief look at the automation package and the demo test suite is necessary so that you can see which data ends up where in the monitoring.

The example runs on the basis of RCC, so that the Windows host does not have to be configured separately.
The `rcc.exe` is rolled out with the agent and can be found under `C:\ProgramData\checkmk\agent\bin\`.
You can download the sample suite as a ZIP file link:https://github.com/elabit/robotmk-examples/blob/main/minimal.zip[via GitHub^].
The directory of the suite:

.C:\robots\mybot\
[{file}]
----
conda.yaml
robot.yaml
tests.robot
----

[TIP]
====
RCC can also process test suites based on a number of other programming languages, but for use in {CMK} it must be the Robot Framework declaration.
====

The suite directory now contains two important files:
The declaration of the environment required for execution in the file `conda.yaml` and the actual tests in the file `tests.robot` (the suite).
The `robot.yaml` file is not relevant for use in {CMK}, but is required by RCC.

For the sake of completeness, here is a brief look into `robot.yaml` file:

.C:\robots\mybot\robot.yaml
[{file}]
----
tasks:
  task1:
    # (task definitions are not required by Robotmk,
    but expected by RCC to be compatible with other Robocorp features)
    shell: echo "nothing to do"

environmentConfigs:
  - conda.yaml

artifactsDir: output 
----

At first, `tasks` defines which tasks, here tests, are to be executed at all.
However, although this part is formally required by RCC, it is not used by Robotmk.

[TIP]
====
Robot Framework distinguishes between tests and tasks, which stand for automations.
However, both are used in exactly the same way.
====

In the `environmentConfigs` area, only the `conda.yaml` is referenced, which takes care about the actual environment.

In this case, only the Python, Pip and Robot Framework dependencies are installed for the environment.
The environment build later appears in the monitoring as [.guihint]#RCC environment build status#.
The tests can only be processed and consequently monitored if the environment has been built successfully.

.C:\robots\mybot\conda.yaml
[{file}]
----
channels:
  - conda-forge

dependencies:
  - python=3.10.12
  - pip=23.2.1
  - pip:
     - robotframework==7.1
----

The actual test suite now looks like this:

.C:\robots\mybot\tests.robot
[{file}]
----
*** Settings ***
Documentation Template robot main suite.

*** Variables ***
${MYVAR}    Hello Checkmk!

*** Test Cases ***
My Test
    Log ${MYVAR}
    Sleep 3
    Log Done.

----

Here, only the value of the `MYVAR` variable is output, then following a 3 second wait, `Done` will be output.
You can set the value of the variable later in the {CMK} web interface -- otherwise the default `Hello Checkmk!` specified here will be used.

[TIP]
====
You can run this test suite manually.
To do this, the agent and RCC must already be installed (or you can download the RCC binary yourself).
First navigate to your test suite directory, where the `tests.robot` is also located.
Then start the RCC shell with `C:\ProgramData\checkmk\agent\bin\rcc.exe task shell`.
The virtual environment defined in `conda.yaml` is then created.
Then start the suite with `robot tests.robot`.
====

And this is exactly what the Robotmk scheduler does as soon as the agent plug-in has been activated.


[#agentconfig]
=== Configure a rule for the agent plug-in

You can find the Robotmk scheduler under [.guihint]#Setup > Agent rules > Robotmk scheduler (Windows)#.
As the rule is quite extensive, here is a look at the empty configuration:

.Configuration of the agent plug-in
image::robotmk_scheduler_00.png[alt="Empty Robotmk scheduler rule."]

First, the scheduler requires the base directory in which all your test suites are located.
Enter this arbitrary, explicit file path under [.guihint]#Base directory of suites#, for example `C:\robots`.

.Base directory for all Robot Framework projects
image::robotmk_scheduler_01.png[alt="Path for test suites."]

The [.guihint]#Parallel plan groups# that are shown now are a {CMK}-specific concept.

To explain this, we must first go down one hierarchy level: Here you can see the item [.guihint]#Sequential plans#.
Such a sequential plan defines which suites are to be executed with which parameters.
Robot Framework will process these suites one after the other.
The reason for this is simple: in practice, tests are sometimes run on the desktop and several test suites could get in each other's way at the same time (think of them stealing each others control of the mouse cursor).

The plan groups are now an encapsulation for sequentially executed plans -- and are themselves executed in parallel.
Again, the reasoning is simple: this allows test suites that do not rely on the desktop to be executed in their own plans without delay -- the test suite used in this article is a good example of such processing.

Back to the dialog: The only explicit setting is the execution interval, which you set under [.guihint]#Group execution interval#.

.Interval for the (parallel) execution of plan groups
image::robotmk_scheduler_02.png[alt='Execution interval for execution groups.']

[IMPORTANT]
====
The plans in the plan group naturally have their own runtimes, determined by the timeout of a single execution and the maximum number of repeated executions in the event of failed tests. 
The execution interval of the plan group must therefore be greater than the sum of the maximum runtimes of all plans in the group.
The maximum runtime of a plan is calculated as follows: [.guihint]#Limit per attempt# × (1 + [.guihint]#Maximum number of re-executions#).
====

Now it's time to configure the first plan.
You can enter any name under [.guihint]#Application name#.
This name does not have to be unique!
The name of the application to be monitored makes sense here, for example `OnlineShop`, or here in this example simply `MyApplication`.
Of course, it can happen that this online store is tested several times, either by other test suites or by the same test suite with different parameters.
In such cases, the [.guihint]#Variant# field is used to achieve unambiguous results despite identical names.
For example, if the application `OnlineShop` is tested once in German and once in English (via corresponding parameters), you could use corresponding abbreviations here.
The monitoring will then return results for `My OnlineShop_en` and `My OnlineShop_de`.

However, the specification under [.guihint]#Relative path to test suite file or folder# is necessary.
The path is relative to the base directory specified above, e.g. `mybot\test.robot` for `C:\robots\`.
Alternatively, a directory (with several `robot` files) can also be specified here, in which case it would simply be `mybot`. 

.Plan for the execution of suites 
image::robotmk_scheduler_03.png[alt="Name and path of the suite."]

Continue with the [.guihint]#Execution configuration.#
Under [.guihint]#Limit per attempt# you define the maximum elapsed time -- per attempt -- that a test suite may run.
With [.guihint]#Robot Framework re-executions# you can now instruct Robot Framework to repeat test suites completely or incrementally if tests fail.
If the individual tests in a test suite are independent of each other, the incremental strategy is the best way to save time.
If, on the other hand, the test suite tests a logical sequence, such as "Login -> Call up product page -> Product in shopping cart -> Checkout", the test suite must of course be completely reprocessed.
In the end, there is always only one result.

In the case of complete retries, only the results from self-contained suites are taken into account for the final result: If a test fails on its final retry, the test suite is counted as a failure.
In the case of incremental retries, the final result is made up of the best partial results: If some tests only run successfully on the third attempt, the final result is also counted as a success.
Reminder: The combination of attempts and maximum run times of all plans in a plan group determines their minimum execution interval.

.Failed tests/suites can be repeated
image::robotmk_scheduler_04.png[alt="Configuration of execution runtimes and repetitions."]

By default, execution via RCC is activated under [.guihint]#Automated environment setup (via RCC)#, for which you must enter two values.
Firstly, RCC requires the specification of where the `robot.yaml` file is located.
Its primary purpose is to reference the `conda.yaml` file, which is responsible for setting up the Python environment, i.e. installing Python and dependencies.
This specification is relative to the base directory that you have set above under [.guihint]#Relative path to test suite file or folder#.
The YAML files can be saved in subdirectories, but best practice is the top suite directory.
For the above base directory `C:\robot\` and the suite directory `C:\robot\mybot` it is accordingly `mybot\robot.yaml`.

With the following time limit for building the Python environment, you should bear in mind that sometimes large volumes of data need to be downloaded and set up.
Especially for the required browsers, several hundred megabytes are quickly accumulated -- but only for the first run.
RCC only rebuilds environments if the content of `conda.yaml` has changed.

.Time limit for building virtual environments
image::robotmk_scheduler_05.png[alt="RCC configuration of the suite."]

Under [.guihint]#Robot Framework parameters# you have the possibility to use some of the command line parameters of Robot Framework (which are also displayed by the command `robot --help`).
If you want to use additional parameters, the option [.guihint]#Argument files# will help.
A file specified here can contain any robot parameters.
Further information about the individual parameters can be found in the inline help.

For our example project, only the option [.guihint]#Variables# is activated and a variable `MYVAR` with the value `My Value` is set.
Remember the command `Log ${MYVAR}` at the top of the file `tests.robot`?
This is the corresponding reference.

.Some options of the `robot` command
image::robotmk_scheduler_06.png[alt="Command line parameters of Robot Framework."]

//// 
// Translation - begin

Besonderes Augenmerk verdient die Option [.guihint]#Secret environment variables,# da sie keine originäre Robot-Framework-Funktion ist.
Sie können hier geheime Umgebungsvariablen setzen, gedacht für Passwörter im Zusammenspiel mit der Robot-Framework-Bibliothek "CryptoLibrary".
Die hier gesetzten Variablen tauchen nicht in Logs auf, werden allerdings im Klartext in die {CMK}-Konfigurationsdateien auf den jeweiligen Test-Hosts geschrieben.

.Geheime Passwörter für die CryptoLibrary
image::robotmk_scheduler_06b.png[alt="Option für geheime Umgebungsvariablen im Robotmk-Scheduler."]

//// 
// Translation - end

At the end of the suite configuration, there are three largely self-explanatory options.
[.guihint]#Execute plan as a specific user# allows Robotmk to be executed in the context of a specific user account.
Background: By default, Robotmk is executed in the context of the {CMK} agent (link:https://learn.microsoft.com/en-us/windows/win32/services/localsystem-account[LocalSystem account^]), which has no authorization to access the desktop.
Here a user can be specified who must be permanently logged in to a desktop session and who has access to graphical desktop applications accordingly.

With [.guihint]#Assign plan/test result to piggyback host# the results of the plan/test can be assigned to another host.
For example, if Robot Framework is testing the ordering process of an online store, the results can be assigned to the corresponding web server.

Each test run produces data that is stored under `C:\ProgramData\checkmk\agent\robotmk_output\working\suites\`.
By default, results from the last 14 days are retained, but you should bear in mind that large volumes of data can quickly accumulate here.
At least 500 kilobytes of data are generated per run -- with more complex test suites and embedded screenshots, for example, this can quickly add up to several megabytes of data.
Depending on the execution interval, the size of the report and your documentation requirements, you should intervene in such a situation.

.Automatic cleanup of the large volume of generated data
image::robotmk_scheduler_07.png[alt="Options for user context, host assignment and automatic cleanup"]

Once here, you can now create further plans in this plan group or further plan groups.

At the end there are two more options, which in turn relate to the complete Robotmk scheduler configuration.

[.guihint]#RCC profile configuration# allows you to specify proxy servers and hosts to be excluded.

[.guihint]#Grace period before scheduler starts# can also be very useful: The scheduler starts together with the {CMK} agent before the desktop logon -- which, of course, means that any tests on the desktop must fail.
The start can be manually delayed using a grace period.

.A grace period prevents failures
image::robotmk_scheduler_08.png[alt="Options for proxy server and a grace period for the scheduler start."]

This completes the configuration and you can bake a new xref:wato_monitoringagents#bakery[agent with the plug-in] and then roll it out, manually or via the xref:agent_deployment#[automatic agent updates].

==== Data in the agent output

The output in the agent is quite extensive:
error messages, status, configuration and test data are transmitted in several sections.
The latter can be found in the `robotmk_suite_execution_report` section, here is an abbreviated excerpt:

.mysite-robot-host-agent.txt
[{json}]
----
<<<robotmk_suite_execution_report:sep(0)>>>
{
    "attempts": [
        {
            "index": 1,
            "outcome": "AllTestsPassed",
            "runtime": 20
        }
    ],
    "rebot": {
        "Ok": {
            "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n
			<robot generator=\"Rebot 6.1.1 (Python 3.10.12 on win32)\" 
			generated=\"20240319 16:23:19.944\" 
			rpa=\"true\" 
			schemaversion=\"4\">\r\n<suite id=\"s1\" 
			name=\"Mybot\" 
			source=\"C:\\robots\\mybot\">\r\n<suite id=\"s1-s1\" 
			name=\"Tests\" 
			source=\"C:\\robots\\mybot\\tests.robot\">\r\n<test id=\"s1-s1-t1\" 
			name=\"Mytest\" 
			line=\"6\">\r\n<kw 
			name=\"Sleep\" 
			library=\"BuiltIn\">\r\n<arg>3 Seconds</arg>\r\n<doc>Pauses the test executed for the given time.</doc>\r\n<msg 
			timestamp=\"20240319 16:23:02.936\" 
			level=\"INFO\">Slept 3 seconds</msg>\r\n<status 
			status=\"PASS\" 
			starttime=\"20240319 16:23:00.934\" 
			endtime=\"20240319 16:23:02.936\"/>"
        }
    },
    "suite_id": "mybot",
    "timestamp": 1710861778
}
...
"html_base64":"PCFET0NUWVBFIGh0bWw+DQo8aHRtbCBsYW ...
----

Two areas are of particular interest here.
Firstly, `rebot`: The `rebot` tool has produced the actual status report for Robot Framework from several partial results (hence re-bot).
Secondly, the last line `html_base64`: The HTML reports from Robot Framework are then base64-encoded.
Screenshots taken via tests are also transferred in this way -- the output/data volume in the agent can be correspondingly extensive.


==== Data in monitoring

As soon as the Robotmk scheduler and the test suite have been run, the xref:glossar#service_discovery[service discovery] will produce three new services: 

.The newly discovered Robotmk services
image::robotmk_scheduler_09.png[alt="Robotmk-Services im Monitoring"]

The service [.guihint]#RMK Scheduler Status# exists once and immediately after deployment.
The services for plans and tests, here [.guihint]#RMK MyApplication_mybot Plan# and [.guihint]#RMK MyApplication_mybot Test: /Test: My Test#, are added to the monitoring as soon as the associated suites have been run for the first time.


[#serviceconfig]
=== Configuring service rules

==== Creating a rule for the plan status

Reminder: Maximum runtimes for plans were defined in the agent rule above.
These runtimes can be evaluated with the [.guihint]#Robotmk plan# rule.
For example, you can set the service to {CRIT} when 90 percent of all calculated timeouts have been reached.

.Threshold values for status changes based on runtimes
image::robotmk_service_suite_status_01.png[alt="Configuration dialog for threshold values for runtimes of test suites."]

In the [.guihint]#Conditions# box, there is the option of restricting the rule to specific plans.

.Optional restriction to certain plans
image::robotmk_service_suite_status_02.png[alt="Dialog with restriction to the test suite 'mybot'."]


==== Creating a rule for the test status

Additional data can also be retrieved for individual tests in the test suites via the [.guihint]#Robotmk test# rule.
Here you will again find the option to monitor runtimes, both for tests and keywords.
The monitoring of keywords is a {CMK}-specific function.
Therefore, the suite-internal status in the Robot Framework report could also be `OK` because the test suite was processed within the maximum permitted runtime -- in {CMK}, however, {WARN} or {CRIT}, because a status change takes place at, for example, 80 percent of this maximum permitted runtime.

In addition, the [.guihint]#Enable metrics for high-level keywords# option can be used to generate metrics for higher-level keywords.
This is particularly useful if your tests are organized in such a way that the higher-level keywords describe the 'what' and the lower-level keywords describe the 'how' -- this gives you more abstract evaluations.

In this example, the threshold values for the maximum runtime of a test are 2 and 4 seconds.
You will see the effects below in the chapter xref:#monitoring[Robotmk in monitoring].

.Monitoring can be expanded using keyword metrics
image::robotmk_service_test_status_01.png[alt="Rule for monitoring keywords with example values."]

Once again, there is an explicit filter option in the [.guihint]#Conditions# box, here for individual tests.

.Optional restriction to certain tests
image::robotmk_service_test_status_02.png[alt="Dialog with option to restrict to tests."]


[#monitoring]
=== Robotmk in monitoring

In monitoring, you will find services for the status of the Robotmk scheduler as well as the individual plans and tests -- even if you have not created any separate service rules.


==== Scheduler status

The service [.guihint]#RMK Scheduler Status# is {OK} if the scheduler is running and has successfully built the execution environments.

.RCC was able to build the environments -- in just one second
image::robotmk_monitorng_scheduler.png[alt="Status of the scheduler in monitoring."]

Here in the image you can see the note [.guihint]#Environment build took 1 second.#
One second to build a virtual Python environment with Pip and Robot Framework?
This is possible because RCC is clever: files that have already been downloaded are reused and a new build is only carried out after changes have been made in `conda.yaml`.
The first build would have taken 30 seconds or more.


==== Plan status

The status of a plan is reflected in a service named by application name and suite, for example [.guihint]#RMK MyApplication_mybot Plan#.

.The execution of a plan -- especially relevant for administrators
image::robotmk_monitorng_suite.png[alt="Status of the test suite in monitoring."]


==== Test status

The evaluation of the tests is where it gets really interesting.
In the image you can now see the effect of the threshold values set above for the runtime of tests -- here the 2 seconds for the {WARN} status.
As the `Sleep 3 Seconds` instruction in the test itself already ensures a longer runtime, this service must go to {WARN} here, although the test was successful.
The fact that the test was successful is shown by the Robot Framework report, which you can access via the icon:icon_log[Alt="Log-Icon."] log icon.

.Results of a specific suite -- especially relevant for developers
image::robotmk_monitorng_test.png[alt="Status of the test in monitoring."]

The report now clearly shows that the test and test suite have run successfully.

.The Robot Framework log, here in optional dark mode
image::robotmk_monitorng_report_01.png[alt="Robot Framework report for 'Mybot' test suite."]

At the bottom of the data you can also see the individual keywords, here for example `Log ${MYVAR}` together with the value `My value` set in {CMK} for `MYVAR`.

.The log file can be expanded down to the smallest details
image::robotmk_monitorng_report_02.png[alt="Robot Framework report at keyword level."]


==== Dashboards

Of course, you can build your own dashboards as usual -- but you can also find two built-in dashboards under [.guihint]#Monitor > Synthetic Monitoring#.

.The complete {CMK} Synthetic Monitoring at a glance (shortened)
image::robotmk_dashboard_01.png[alt="Robotmk dashboard in the web interface."]

//// 
// Translation - begin

*Voraussetzung:* Damit Dashboards funktionieren, muss die xref:inventory#[HW/SW-Inventur] auf den betroffenen Hosts aktiviert sein.


[#managedrobots]
== Managed Robots
Bislang sind wir von einem Szenario ausgegangen, in dem die Test-Suiten bereits auf den Test-Hosts bereitstehen.
Mit dem Feature [.guihint]#Managed robots# lassen sich Robots jedoch auch zentral auf dem {CMK}-Server verwalten und per {CMK}-Agenten verteilen.
Die ganze Konfiguration kennen Sie bereits von der obigen Vorgehensweise zu bereits existierenden Robots über die Regel [.guihint]#Robotmk scheduler (Windows|Linux).#
Zusätzlich geben Sie lediglich die Archiv-Datei (siehe unten) mit dem gepackten Robot an.
Hier im Bild sehen Sie das Upload-Feld für den Robot, darunter unter [.guihint]#Plan Settings# dieselben Optionen wie im Scheduler.
Achten Sie oben auf den Namen unter [.guihint]#Properties.#
Dieser ist obligatorisch, da der Robot später über diesen Namen im Scheduler konfiguriert wird.

image::robotmk_managed_robots_robot.png[alt="Konfiguration eines gemanagten Robots."]

Um einen solchen [.guihint]#Managed robot# einzusetzen, wird abermals die Regel [.guihint]#Robotmk scheduler (Windows|Linux)# genutzt.
Aber statt hier die Ausführung des Robots zu planen, geben Sie unter [.guihint]#Sequence of plans# einfach nur den gewünschten, vorkonfigurierten Robot an.
Bei Bedarf können Sie die Plan-Konfiguration des vorkonfigurierten Robots für diesen Einsatz hier dennoch anpassen.
In der Praxis beschränkt sich das Feature also meist darauf, die bekannte Konfiguration auszulagern und Robot-Archivdateien per Agent verteilen zu lassen.

image::robotmk_managed_robots_scheduler.png[alt="Konfiguration des Schedulers mit einem gemanagten Robot."]

Der Agent bringt die angegebenen Archive schließlich auf die gewünschten Hosts und legt sie im Agentenverzeichnis unterhalb von `robomk_output/managed` ab, wo sie dann entpackt und schlussendlich ausgeführt werden.

=== Robot-Archiv erstellen
Grundsätzlich könnten Sie einfach das komplette Robot-Verzeichnis mit den Standarddateien (`robot.yaml, conda.yaml, test.robot`) archivieren -- unter Windows als ZIP, unter Linux als tar.gz.

Allerdings werden solche Tests häufig per Git verwaltet und folglich finden sich regelmäßig Dateien, die nicht mit verteilt werden sollen -- typischerweise verwaltet über eine gitignore-Datei.
Als Hilfestellung für saubere Archive, hier zwei kleine Skripte für Windows und Linux, die Archive ohne die zu ignorierenden Dateien erstellen.
Bitte verstehen Sie diese Skripte lediglich als Hilfestellung und testen Sie die Funktionsweise für Ihr System vorab.

Windows:

[{shell}]
----
C:\robots\myrobot> 
$FolderName=(Get-Item .).Name
cp -r . "$env:TEMP\"
rm -r "$env:TEMP\$FolderName\$(git ls-files --others --ignored --exclude-standard)"
Compress-Archive "$env:TEMP\$FolderName" "../$FolderName.zip" -Force
rm -r -fo $env:TEMP\$FolderName
----

// ML: Original von Simon: $folderName=(Get-Item .).Name; mkdir "$env:TEMP\$folderName"; git ls-files --cached --others --exclude-standard | % { cp $_ "$env:TEMP\$folderName" -Recurse -Force }; Compress-Archive "$env:TEMP\$folderName" "../$folderName.zip" -Force; rm -r -fo $env:TEMP\$folderName

Linux:

[{shell}]
----
user@host:~/robots/myrobot$>
folder_name=$(basename "$PWD") && \
temp_dir=$(mktemp -d)/"$folder_name" && \
mkdir -p "$temp_dir" && \
git ls-files --cached --others --exclude-standard | xargs -I{} cp --parents "{}" "$temp_dir" && \
tar -czf "../$folder_name.tar.gz" -C "$(dirname "$temp_dir")" "$folder_name" && \
rm -rf "$(dirname "$temp_dir")"
----


[#kpi]
== Monitoring von Key Performance Indicators (KPI)
Oben haben Sie bereits gesehen, dass sich die Laufzeiten von High-Level-Keywords als Teil eines Tests mit überwachen lassen.
Sie können aber auch beliebige Keywords als einzelne Services ins Monitoring holen.
Sinnvoll ist das vor allem für hoch abstrahierende Nutzer-Keywords, die ihrerseits mehrere einfache (Standard-)Keywords wie `Click` oder `Log` aufrufen -- also im Grunde als _Funktionen_ genutzt werden.
Für die Service-Erkennung stehen Ihnen zwei Varianten zur Verfügung: Muster in {CMK} und Marker in den Test-Suiten.

Für die _Muster-basierte Erkennung_ werden die gewünschten Keywords als reguläre Ausdrücke per {CMK}-Regel hinterlegt.

Für die _Marker-basierte Erkennung_ werden Marker direkt vor die Keywords in den Tests selbst geschrieben.
Die Verarbeitung dieser Marker läuft über eine Robotmk-eigene Bibliothek.

Egal wie die Keyword-Daten ins Monitoring kommen, dort müssen Sie über die Service-Regel [.guihint]#Robotmk KPI monitoring# konfiguriert werden.

[#kpipattern]
=== Variante 1: Erkennung via Muster

Für diese Variante müssen Sie keinerlei Veränderungen an Ihren Tests selbst vornehmen.
Öffnen Sie einfach die Regel [.guihint]#Robotmk KPI discovery# und tragen Sie die zu überwachenden Keywords als reguläre Ausdrücke oder ganz konkrete Namen ein.

.Konfiguration von Keywords als separate Services
image::robotmk_kpi_pattern.png[alt="Konfiguratin von Keywords als separate Services für Robotmk."]

*Achtung:* Wenn der reguläre Ausdruck auf mehrere Keywords desselben Tests matcht, wird nur ein Keyword erkannt und dessen Service-Status geht auf {UNKNOWN} (weil {CMK} freilich nicht weiß, welcher Treffer denn gemeint ist).

[#kpimarker]
=== Variante 2: Erkennung via Marker

Für die Erkennung via Marker müssen Sie folgende Schritte durchführen:

. Robotmk-Bibliothek installieren
. Robotmk-Bibliothek in der Suite importieren
. Marker-Keyword vor relevante Keywords setzen

Für die Installation muss die `conda.yaml` von oben mit `robotframework-robotmklibrary` erweitert werden.
Änderungen gegenüber der obigen Suite sind gelb unterlegt:

.C:\robots\mybot\conda.yaml
[{file},highlight=9]
----
channels:
  - conda-forge

dependencies:
  - python=3.10.12
  - pip=23.2.1
  - pip:
     - robotframework==7.0
     - robotframework-robotmklibrary
----

Die Test-Suite `tests.robot` muss um die Bibliothek (im Bereich `Settings`) sowie einen Marker erweitert werden.
KPIs werden sich dabei häufig auf individuelle Nutzer-Keywords beziehen, daher hier eine Erweiterung um das Keyword `Foobar` (das lediglich das Standard-Keyword `Log` aufruft und seinerseits vom Testfall `My Test` aufgerufen wird).


.C:\robots\mybot\tests.robot
[{file},highlight=3;13-18]
----
*** Settings ***
Documentation       Template robot main suite.
Library             RobotmkLibrary

*** Variables ***
${MYVAR}    Hello Checkmk!

*** Test Cases ***
My Test
    Log      ${MYVAR}
    Sleep    3
    Log      Done.
    Monitor Subsequent Keyword Runtime  discover_as=My user keyword
    Foobar
	
*** Keywords ***
Foobar
    Log    The foo barred!

----

Das Robotmk-Keyword `Monitor Subsequent Keyword Runtime` ist der Marker, um ({CMK} an zu triggern) das folgende Keyword (Foobar), zu überwachen; genauer gesagt dessen Laufzeit.
Über das optionale Argument `discover_as`` lässt sich hier ein individueller Name für den Service im Monitoring setzen -- das Keyword `Foobar` taucht folglich im Monitoring als Service namens [.guihint]#My user keyword# auf.

Der große Vorteil gegenüber der Muster-basierten Erkennung: Ein und dasselbe Keyword lässt sich auch mehrfach innerhalb eines Tests ganz explizit monitoren.

Hier das obige Beispiel, erweitert um zwei `Foobar`-Aufrufe:

.C:\robots\mybot\tests.robot
[{file},highlight=13-18]
----
*** Settings ***
Documentation       Template robot main suite.
Library             RobotmkLibrary

*** Variables ***
${MYVAR}    Hello Checkmk!

*** Test Cases ***
My Test
    Log      ${MYVAR}
    Sleep    3
    Log      Done.
    Monitor Subsequent Keyword Runtime  discover_as=My user keyword
    Foobar
    Monitor Subsequent Keyword Runtime  discover_as=Foobar_2
    Foobar
    Monitor Subsequent Keyword Runtime  discover_as=Foobar_3
    Foobar
	

*** Keywords ***
Foobar
    Sleep    3
    Log    The foo barred!

----

Die drei Aufrufe des Keywords `Foobar` würden folglich als `My user keyword`, `Foobar_2` und `Foobar_3` im Monitoring auftauchen.

=== Service-Regel konfigurieren
Egal über welche der beiden Varianten die Keywords ins Monitoring kommen, der nächste Schritt ist immer die Konfiguration der Auswertung: Ab welcher Laufzeit sollen die Services auf {WARN} beziehungsweise {CRIT} gehen?
Dazu legen Sie in der Regel [.guihint]#Robotmk KPI monitoring# die entsprechenden Level fest.

.Service-Regel für die Auswertung von Keywords
image::robotmk_kpi_service_rule.png[alt="Service-Regel für die Auswertung von Keywords."]

=== Keywords im Monitoring
Die Keyword-Services tauchen im Monitoring unter einem dieser beiden Muster auf:

. Musterbasiert: [.guihint]#RMK MyApplication_mybot Test: /Test: My Test KPI (cmk): Foobar#
. Markerbasiert: [.guihint]#RMK MyApplication_mybot Test: /Test: My Test KPI (rf): Foobar#

Der Unterschied liegt also lediglich in der Herkunftsangabe in Klammern direkt vor dem Keyword.

.Muster- und Marker-basierte Keywords im Monitoring
image::robotmk_kpi_monitoring.png[alt="Muster- und Marker-basierte Keywords im Monitoring."]

Für das obige Bild mit zwei Foobar-Keyword-Services musste die Suite noch etwas erweitert werden:

.C:\robots\mybot\tests.robot
[{file},highlight=14-16;23-26]
----
*** Settings ***
Documentation       Template robot main suite.
Library             RobotmkLibrary

*** Variables ***
${MYVAR}    Hello Checkmk!

*** Test Cases ***
My Test
    Log      ${MYVAR}
    Sleep    3
    Log      Done.
    Foobar
    Monitor Subsequent Keyword Runtime  discover_as=Foobar
    Barfoo
	

*** Keywords ***
Foobar
    Sleep    3
    Log    The foo barred!

Barfoo
    Sleep    11
    Log    The End of Barfoo

----

Die beiden Keywords `Foobar` und `Barfoo` tauchen beide unter dem Namen [.guihint]#Foobar# im Monitoring auf, sind aber unterscheidbar durch die Herkunftsangabe in Klammern.

Das Beispiel mit *zwei* unterschiedlichen Keywords, die unter dem gleichen Namen geführt werden, dient vor allem der Verdeutlichung der Herkunftsangaben.

Wie oben bereits erwähnt: Der eigentliche Anwendungszweck von `discover_as` liegt darin, *ein* Keyword mehrmals in einem Test aufzurufen und unterschiedlich zu benennen. 


// MFS: Prepare for translation

== Offline-Modus für Test-Umgebungen/RCC
Standardmäßig kümmert sich RCC um den Aufbau der Umgebungen, indem es die YAML-Konfiguration ausliest und die entsprechenden Pakete und Abhängigkeiten aus dem Netz herunterlädt.

Was aber, wenn die Hosts, auf denen die Tests laufen sollen, keinen oder sehr eingeschränkten Internetzugriff haben?

{CMK}, genauer gesagt der Robotmk Scheduler, kann hier weiterhelfen und RCC-Umgebungen auch ohne Internetverbindung aufbauen.
Die Kurzversion: Die Umgebungen werden vorab auf einem beliebigen Rechner gebaut und anschließend wahlweise per ZIP-Archiv oder von einem Remote-Server verteilt.

Wie genau die beiden Wege funktionieren, lesen Sie unten.
Für das Verständnis braucht es allerdings ein wenig RCC-Wissen – und da müssen wir etwas ausholen: Einerseits, um die technischen RCC-Interna zu erläutern, andererseits um zu erklären, warum wir nicht (wie üblich) diesbezüglich auf den Hersteller verweisen.

[#rccbackground]
=== RCC-Exkurs

==== RCC-Historie
Woher kommt das Tool?
RCC wurde ursprünglich von der Firma Robocorp (inzwischen: Sema4.ai) entwickelt.
Das Geschäftsmodell von Sema4.ai ist eine cloudbasierte Plattform, in der Kunden ihre Skripte zur Automatisierung von Geschäftsprozessen betreiben können.
RCC bildet dabei den Unterbau, um sowohl lokal beim Kunden als auch in der Cloud immer exakt gleiche virtuelle Umgebungen zu bekommen.

Bei {CMK} setzen wir RCC für einen anderen Use Case ein: Hier sollen Ihre Robot-Framework-Skripte sowohl auf Ihrem lokalen (Entwicklungs-)Rechner als auch auf den Robotmk-Test-Hosts (Windows oder Linux) laufen können.

Im Zuge des Aufkaufs von Robocorp durch Sema4.ai 2024 wurde RCC umlizenziert und ist nunmehr proprietäre Software.
Leider ist das nicht sonderlich transparent abgelaufen -- daher auch dieser kleine Exkurs.

Die Variante, die mit {CMK} ausgeliefert wird, baut auf der letzten offenen RCC-Version auf und wird von uns gepflegt.
Von daher ist der RCC-Fork mittlerweile integrativer Bestandteil von {CMK} wird hier auch dokumentiert — soweit für den Einsatzzweck in Checkmk relevant.

Noch etwas schwieriger wird es mit RCC Remote Server, dem Tool, das für die Verteilung der RCC-Umgebungen verantwortlich ist.
Dieses ist nämlich lediglich ein Bestandteil von RCC, der erst beim Kompilieren entsteht, kein eigenständiges Produkt.
Daher gab es seitens Robocorp nie eine wirkliche Dokumentation abseits eines ganz speziellen Einsatzes für die Robocorp-Plattform.

==== RCC-Interna
Für das Verständnis sollten Sie einige Begriffe und Konzepte verstehen.

[cols="15,20,~",options="header"]
|===
|Begriff |Erklärung |Anmerkung

|Catalog
|Blueprint für Umgebungen
|Vorlagen für den Bau virtueller Umgebungen

|Hololib 
|Sammlung verfügbarer Catalogs
|Hololib ist ein Speicher für Blueprints, in dem jede einzigartige Datei nur ein mal gespeichert wird - und sich für die Erzeugung von mehreren Spaces nutzen lässt.

|Space
|Instanz einer Umgebung
|Aus einem Catalog können mehrere Spaces hervorgehen

|(Shared) Holotree
|Sammlung verfügbarer Spaces
|(Shared) Holotree ist ein Speicher für Spaces, in dem jede einzigartige Datei nur ein mal gespeichert wird - und für mehrere Spaces zur Verfügung steht.


|`ROBOCORP_HOME`
|Umgebungsvariable
|Pfad, unter dem RCC Hololib und Holotree speichert; standardmäßig `%HOME%/Appdata/Local/robocorp/`unter Windows und `~/.robocorp` unter Linux.

|`ROBOCORP_HOME` - in {CMK}
|Abgesicherte Variante mit beschränkten Schreibzugriff 
|Pfad, unter dem {CMK}-RCC Hololib und Holotree speichert; unterhalb von `C:\robotmk\rcc_home` beziehungsweise `/opt/robotmk/rcc_home/`

|Holotree Path
|Absoluter Pfad, unterhalb von `ROBOCORP_HOME`
|Unter diesem Pfad werden Hololib-Blueprints zu Holotree-Spaces kompiliert; muss auf Quell- und Ziel-Rechner einer Umgebung identisch sein.

|rccremote
|Server zur Bereitstellung von Katalogen.
|Wird in der Regel über den Container  RCCRemote-Docker betrieben.

|===

==== ROBOCORP_HOME
`ROBOCORP_HOME` benötigt einen etwas genaueren Blick.
Diese Umgebungsvariable bestimmt den Pfad, unter dem RCC Hololib und Holotree speichert.
Alle Binärdateien innerhalb der Hololib, also der Vorlagensammlung, werden unterhalb eines absoluten Pfads kompiliert -- dem so genannten `holotree path`, ein Unterordner von `ROBOCORP_HOME`.
// ML: @AH please also translate the following two comments - just in case ...
// ML: Folgender Satz ist nur sehr schwer verständlich - aber vielleicht relevant für Quelltextleser ;) 
// Warum? Weil die Binärdateien beim Erstellen von Spaces aus Katalogen von der Hololib in den Holotree wandern, von wo sie entsprechend ausgeführt werden.
Das heißt auch: Auf den Test-Hosts, auf denen die Robots später laufen, müssen dieselben Pfade zur Verfügung stehen wie auf dem Rechner, auf dem Sie die Robots anlegen.

In diesem Zusammenhang ebenfalls relevant: Nutzer-Kontext.
Der Robotmk-Scheduler wird unter Windows standardmäßig als Unterprozess des {CMK}-Agenten ausgeführt und läuft im Kontext *SYSTEM.*
Unter Linux läuft der Scheduler unter dem gleichen Nutzer wie der Agent, also *root.*

Sollen die Nutzer-Kontexte nun geändert werden, verhalten sich Windows und Linux unterschiedlich.
*Windows:* Der Scheduler-Nutzer *SYSTEM* kann nicht geändert werden, allerdings lässt sich über die Option [.guihint]#Execute plan as a specific user# ein Nutzer für die Ausführung einzelner Robots/Pläne setzen.
*Linux:* Über die Regel [.guihint]#Customize agent package (UNIX)# und deren Option [.guihint]#Customize user# lässt sich der Nutzer für den Agenten ändern; dafür ist es hier nicht möglich, einzelne Robots/Pläne in anderen Kontexten laufen zu lassen.

In {CMK} erlaubt sich der Robotmk-Scheduler noch eine zusätzliche Sicherheitsmaßnahme für RCC: Um sicherzustellen, dass auch wirklich nur Scheduler und manuell gesetzte Nutzer Schreibzugriff auf `ROBOCORP_HOME` haben, muss hier ein ganz bestimmter Pfad gesetzt werden -- entsprechend obiger Tabelle plus eine weitere Hierarchieebene für den gewünschten Nutzerkontext (wie das in der Praxis aussieht sehen Sie unten).
Dies verhindert, dass böswillige Dateien Einzug in Hololib/Holotree finden, also Code Injection (in aller Kürze: Würde `ROBOCORP_HOME` auf dem Entwicklungsrechner auf etwa `C:\foobar` gesetzt und würde dieses Verzeichnis auf den Test-Hosts bereits existieren und Malware enthalten, könnte diese ausgeführt werden).

[#ziparchive]
=== Variante 1: ZIP-Archive

Die Praxis ist weitaus einfacher als die technischen Hintergründe -- insbesondere bei der Arbeit mit einem Katalog als ZIP-Archiv (beziehungsweise tar.gz-Archiv unter Linux).
Im Grunde bauen Sie nur den Katalog unter Angabe der `ROBOCORP_HOME`-Variable, exportieren ihn als Archiv und verteilen dieses dann manuell.
Folgend der Weg im Detail.
Die Pfade in folgenden Beispielen beschränken sich auf Windows -- lediglich wenn Linux andere Kommandos erfordert, geben wir diese explizit an.

==== ROBOCORP_HOME setzen
Den Katalog, also die Vorlage für konkret umgesetzte Umgebungen (Spaces), können Sie auf einem beliebigen Rechner erstellen.

Setzen Sie zunächst im Terminal `ROBOCORP_HOME`.

Unter *Windows:*

Für die Headless-Ausführung als SYSTEM-Nutzer:

[{shell}]
----
C:\robots> set ROBOCORP_HOME=C:\robotmk\rcc_home\current_user
----
	
Für die Robots, die Desktop-Zugriff und einen entsprechenden Nutzer benötigen:

[{shell}]
----
C:\robots> set ROBOCORP_HOME=C:\robotmk\rcc_home\HarryHirsch
----
	
Unter *Linux:*

Für die Headless-Ausführung als Standard-Nutzer:

[{shell}]
----
user@host:~$ export ROBOCORP_HOME=/opt/robotmk/rcc_home/current_user
----

Für die Robots, die Desktop-Zugriff und einen entsprechenden Nutzer benötigen:

[{shell}]
----
user@host:~$ export ROBOCORP_HOME=/opt/robotmk/rcc_home/HarryHirsch
----
	
Anschließend können Sie Ihr Bot-Verzeichnis betreten und die Umgebung/den Katalog bauen:

[{shell}]
----
C:\robots> cd myrobot
C:\robots\myrobot> rcc holotree vars
----

	
==== ZIP-Katalog erstellen
Nun muss der Katalog als ZIP exportiert werden.
Prüfen Sie zunächst, ob ein Hololib-Katalog mit dem korrekten Holotree-Pfad existiert.
Dazu benötigen Sie den Hash der _conda.yaml:_

[{shell}]
----
C:\robots\myrobot> rcc holotree hash conda.yaml

Blueprint hash for [conda.yaml] is #296bd91e514e7d1d#
----

Lassen Sie sich anschließend alle verfügbaren Hololib-Kataloge anzeigen (Ausgabe gekürzt):

[{shell}]
----
C:\robots\myrobot> rcc holotree catalogs

Blueprint         Platform       Dirs    Files    Size     Relocate  Holotree path             
---------         --------       ------  -------  -------  --------  -------------
.#296bd91e514e7d1d# windows_amd64     358     4895     123M        28  c:\ProgramData\robocorp\ht
...
----


Wenn sich der Hash in der Liste wiederfindet, können Sie exportieren:

[{shell}]
----
C:\robots\myrobot> rcc holotree export -r robot.yaml --zipfile myrobot-env.zip
----

==== ZIP-Katalog ausrollen
Das Ausrollen des gezippten Katalogs ist simpel: Kopieren Sie das Archiv händisch auf den Test-Host, beispielsweise nach `C:\robotmk\holotrees\myrobot-env.zip`.

Setzen Sie entsprechend in der Regel [.guihint]#Robotmk Scheduler (Windows|Linux)# (beziehungsweise in [.guihint]#Managed robots#) die Option [.guihint]#Environment dependency handling# auf [.guihint]#Load from ZIP file# und geben Sie den gewünschten Pfad zum gezippten Katalog an, hier also `C:\robotmk\holotrees\myrobot-env.zip`.
Bitte nicht verwechseln, dieser Pfad hat nichts mit dem _holotree path_ zu tun!
Er dient nur als Ablage für die zu importierenden Hololib-Katalog-ZIPs.

Wenn später der Scheduler startet, importiert er sämtliche Hololib-Katalog-ZIPs und baut aus diesen Vorlagen die Spaces, also die letztlich tatsächlich genutzen Umgebungen.
Statt also sämtliche Abhängigkeiten per pip und Conda aus dem Internet herunterzuladen, wird lediglich ein Archiv entpackt -- was nicht nur offline, sondern auch deutlich fixer ist.

image::robotmk_rcc_offline_dependency_handling.png[alt="Angaben zur Handhabung eines gezippten Katalogs."]

Und nur, um Missverständnissen vorzubeugen: Die Robots selbst müssen natürlich nach wie vor schon auf dem Test-Host bereit stehen oder als Managed Robot ausgebracht werden, hier geht es rein um die Umgebungen!

[#rccremote]
=== Variante 2: RCCRemote-Server
Gleich vorweg: RCCRemote ist kein eigenständiges Tool, Sie werden dazu keine eigene Dokumentation oder auch nur eine Produktseite seitens Robocorp/Sema4 finden.
Der Remote-Server ist lediglich Teil von RCC und wird beim Kompilieren von RCC mitgebaut.
Betrieben wird er in der Regel per Container.
Für den Container-Betrieb gibt es mittlerweile ein Projekt auf den GitHub-Seiten von Elabit, dem Entwickler des ursprünglichen Robotmk-Plugins, namens link:https://github.com/elabit/rccremote-docker[RCCRemote-Docker.^]
RCCRemote und RCCRemote-Docker sind jedoch nicht Teil von {CMK} Synthetic Monitoring und *nicht vom {CMK}-Support gedeckt!*

Kataloge für diesen Distributionsweg lassen sich auf zwei Wegen erstellen: Für Windows wie Linux lassen sich als ZIP exportierte Kataloge (siehe oben) verwenden.
Ausschließlich für Linux besteht zudem die Möglichkeit, die Kataloge direkt *im RCCRemote-Docker-Container* zu bauen, womit sich händisches Eingreifen komplett erledigt.

Wie Sie RCCRemote-Docker aufsetzen, mit Zertifikaten umgehen und Kataloge importieren, können Sie auf den link:https://github.com/elabit/rccremote-docker[Projektseiten^] nachlesen.

Die Konfiguration auf {CMK}-Seite ist nun wieder -- typisch -- ganz trivial: Die Option [.guihint]#Environment dependency handling# wird dieses mal auf [.guihint]#Fetch from RCC remote server# gesetzt und mit der Adresse des Servers versorgt.

image::robotmk_rcc_offline_dependency_handling_2.png[alt="Angabe zur Handhabung von RCCRemote."]

Eine letzte Einstellung fehlt noch, je nachdem, ob Ihr RCCRemote-Server ein selbstsigniertes oder ein CA-signiertes Zertifikat einsetzt.
In beiden Fällen müssen Sie in der Regel [.guihint]#Robotmk scheduler (Windows|Linux)# die Option [.guihint]#RCC profile configuration# auf [.guihint]#Custom profile# setzen.

Bei einem selbstsignierten Zertifikat genügt es, das Häkchen bei [.guihint]#Validate TLS certificates# nicht zu setzen.

image::robotmk_rcc_offline_tls_self.png[alt="Inaktive TLS-Validierung für selbst signierte Zertifikate."]

Handelt es sich um ein CA-signiertes Zertifikat, muss die Option hingegen aktiviert und das Zertifikat der signierenden Stelle unter [.guihint]#Root CA# hinterlegt werden (im PEM-Format).

image::robotmk_rcc_offline_tls_ca.png[alt="Hinterlegtes Zertifikat der CA."]


//// 
// Translation - end


[#troubleshooting]
== Troubleshooting

=== Scheduler reports `No Data`

If the scheduler does not receive any data, building the environment probably did not work.
A common reason for this are network problems, for example, due to which certain dependencies cannot be loaded.
In this case, take a look at the corresponding log file under `C:\ProgramData\checkmk\agent\robotmk_output\working\environment_building`.


=== Environment building fails: `post-install script execution`

This is a particularly interesting error that you might encounter on fresh Windows systems.
The `conda.yaml` can also contain instructions that are to be executed after the installation of the dependencies -- for example, the initialization of the Robot Framework browser.
Python commands should therefore be executed here.
By default, Windows 11 has aliases for `python.exe` and `python3.exe` that refer to the Microsoft Store.
You must deactivate these aliases under 'Settings/Aliases for app execution'.


[#files]
== Files and directories
	
[cols="30,~",options="header"]
|===
|File path |Description
|`C:\ProgramData\checkmk\agent\robotmk_output\working\suites\` |Log files and results of the suites
|`C:\ProgramData\checkmk\agent\robotmk_output\working\environment_building` |Log files for building virtual environments
|`C:\ProgramData\checkmk\agent\robotmk_output\working\rcc_setup` |Messages of the RCC execution
|`C:\ProgramData\checkmk\agent\logs\robotmk_scheduler_rCURRENT.log` |Log file of the agent plug-in
|`C:\ProgramData\checkmk\agent\bin\` |`rcc.exe` and `robotmk_scheduler.exe`
|`C:\ProgramData\checkmk\agent\plugins\` |Agent plug-in `robotmk_agent_plugin.exe`
|===

//// 
// Translation - begin

=== Linux
	
[cols="~,45",options="header"]
|===
|Pfad |Bedeutung
|`/var/lib/check_mk_agent/robotmk/scheduler/plans` |Log-Dateien und Ergebnisse der Suites
|`/var/lib/check_mk_agent/robotmk/scheduler/environment_building` |Log-Dateien zum Aufbau virtueller Umgebungen
|`/var/lib/check_mk_agent/robotmk/scheduler/rcc_setup` |Meldungen der RCC-Ausführung
|`/usr/lib/check_mk_agent/robotmk/` |`rcc` und `robotmk_scheduler`
|`/usr/lib/check_mk_agent/plugins/` |Agentenplugin `robotmk_agent_plugin`
|`/var/lib/check_mk_agent/robotmk/scheduler/managed/` |Ausführungsort for Managed Robots
|`/usr/lib/check_mk_agent/managed_robots/` |Ablageort für Managed-Robots-Archive
|===

*Achtung:* Unter Linux legt der Robotmk-Scheduler keine eigene Log-Datei an (unter Windows die `robotmk_scheduler_rCURRENT.log`), sondern protokolliert via Agent und Syslog.
Der zugehörige Befehl:

[{shell}]
----
user@host:~$ journalctl -xu robotmk-scheduler-daemon.service
----

////
// Translation - end
