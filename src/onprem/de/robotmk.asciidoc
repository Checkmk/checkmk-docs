// -*- coding: utf-8 -*-
// IGNORE + Entwicklungs MyApp1 MyApplication_mybot Windows|Linux rf ×
// NONASCII
// SKIPCOMMITS 2025-09-16
include::global_attr.adoc[]
= {CMK} Synthetic Monitoring mit Robotmk
:revdate: 2025-07-03
:title: {CMK} Synthetic Monitoring mit Robotmk
:description: {CMK} Synthetic Monitoring simuliert Nutzerverhalten auf Basis von Robot Framework. Lesen Sie hier, wie Sie Robotmk-Tests in Ihr Monitoring integrieren.

{related-start}
xref:wato_monitoringagents#[Monitoring-Agenten]
xref:agent_deployment#[Automatische Agenten-Updates]
{related-end}


[#intro]
== Synthetisches Monitoring mit Robot Framework

{cee-only} {CMK} Synthetic Monitoring ist in den kommerziellen {CMK}-Editionen verfügbar, benötigt jedoch eine link:https://checkmk.com/request-quote/synthetic-monitoring[zusätzliche Subskription.^]
Sie können die Funktion allerdings mit bis zu drei Tests kostenlos und ohne Zeitbegrenzung testen.

Mit {CMK} können Sie Ihre eigene Infrastruktur sehr genau überwachen -- bis hin zur Frage, ob ein bestimmter Service, beispielsweise ein Webserver, ordentlich läuft.
Wird Ihre Website über einen Cloud-Service von Dritten betrieben, werden Sie keinen Zugriff auf den Service selbst haben, können aber über einen HTTP-Check prüfen, ob die Website erreichbar ist.
Aber was sagt das über die Nutzererfahrung aus? Dass ein Online-Shop erreichbar ist, heißt ja noch nicht, dass die Navigation, Bestellprozesse und dergleichen reibungslos funktionieren.

An dieser Stelle setzt das {CMK} Synthetic Monitoring an.
Mit dem Plugin Robotmk bietet {CMK} echtes End-to-End-Monitoring, also die Überwachung laufender Anwendungen aus Sicht der Nutzer.
Das eigentliche Testen übernimmt dabei die Open-Source-Software link:https://robotframework.org/[Robot Framework^] -- in deren Trägerverein auch die {comfull} Mitglied ist.

Mit der Automationssoftware lässt sich Nutzerverhalten komplett automatisieren, um beispielsweise Bestellprozesse in Online-Shops Klick für Klick nachzustellen.
Das Besondere an Robot Framework: Tests werden nicht in einer vollwertigen Programmiersprache geschrieben, sondern über einfach zu verwendende Keywords definiert, wie `Open Browser` oder `Click Button`.
So genügt ein `Open Browser checkmk.com` zum Aufrufen der {CMK}-Website.
Mehrere Testfälle werden dann in sogenannten Test-Suites zusammengefasst (in Form einer `.robot`-Datei).

Robotmk kann nun diese Robot-Framework-Test-Suites verteilen, auf den Hosts triggern und ihre Ausführung und Resultate als Services in {CMK} überwachen.
In der {CMK}-Weboberfläche finden Sie dann Status, zugehörige Performance-Graphen sowie die Original-Auswertungen von Robot Framework selbst.


=== Komponenten

Für dieses End-to-End-Monitoring spielen allerhand Komponenten zusammen, daher hier ein kurzer Überblick.


==== {CMK}-Server

{CMK} Synthetic Monitoring wird über Robotmk realisiert, das ein Agentenplugin als Datensammler nutzt und den Robotmk-Scheduler (auf dem überwachten Host) für das Triggern von Robot-Framework-Projekten.
Aktiviert und konfiguriert wird das synthetische Monitoring über die Regel [.guihint]#Robotmk Scheduler#.
Hier legen Sie fest, welche Test-Suites ausgeführt werden sollen und wie exakt Robot Framework diese starten soll -- zusammengefasst in einem _Plan._
Einmal verteilt, sorgt der Robotmk-Scheduler auf dem Ziel-Host für die planmäßige Ausführung Ihrer Robot-Framework-Suites.

Im Monitoring bekommen Sie letztlich mehrere neue Services: [.guihint]#RMK Scheduler Status# zeigt den Status des Schedulers selbst, also ob Test-Suites erfolgreich gestartet werden konnten.
Hinzu kommen Services für alle konfigurierten Test-Pläne (etwa [.guihint]#RMK MyApp1 Plan#) und einzelnen Tests aus Test-Suites (etwa [.guihint]#RMK MyApp1 Test#).
Zu den Services der einzelnen Tests gehören auch die originalen Robot-Framework-Berichte.

Dann gibt es noch zwei optionale Service-Regeln: [.guihint]#Robotmk plan# und [.guihint]#Robotmk test# sorgen für die Feineinstellung der Plan- und Test-Services -- beispielsweise um Statuswechsel bei bestimmten Laufzeiten zu erwirken.

Zu guter Letzt existieren noch zwei Regeln zum _KPI-Monitoring:_
KPI steht für Key Performance Indicator und meint in diesem Kontext einzelne Keywords.
Über die Regel [.guihint]#Robotmk KPI discovery# lassen sich Keywords als separate Services ins Monitoring holen und über [.guihint]#Robotmk KPI monitoring# entsprechend auswerten.
Wie genau das Keyword-Monitoring funktioniert, zeigen wir unten in einem separaten Kapitel.

Etwas abseits der normalen Regeln gibt es im Bereich [.guihint]#Setup# noch das Feature [.guihint]#Managed robots.#
Die Kurzversion: Robots, die auf dem {CMK}-Server verwaltet und via {CMK}-Agent verteilt werden -- für Details steht abermals ein eigenes Kapitel zur Verfügung.

.Die Robotmk-Regeln in {CMK}
image::robotmk_services_menu.png[alt="Robotmk-Regeln im Setup-Menü."]


==== Testmaschine

Die Robot-Framework-Test-Suites können Sie sowohl auf einem Windows- (ab Windows 10 beziehungsweise Server 2019) als auch Linux-Host bereitstellen.
Für die Ausführung benötigt Robot Framework Zugriff auf deren Abhängigkeiten (Python, Bibliotheken, Treiber für die Browser-Automation und so weiter).
Diese Konfiguration ist unabhängig von {CMK} und kann deklarativ in einem portablen Paket abgelegt werden.
Dies übernimmt das Open-Source-Kommandozeilenwerkzeug link:https://github.com/robocorp/rcc[RCC.^] 
Dieses baut anhand Ihrer Konfigurationsdateien im YAML-Format virtuelle Python-Umgebungen samt Abhängigkeiten und Robot Framework selbst.
Der als Hintergrundprozess laufende Robotmk-Scheduler stößt diesen Bau an und sorgt anschließend selbst für die Ausführung der Tests.

Ein solches _RCC-Automationspaket_ mit der Paketkonfiguration (`robot.yaml`), der Definition der Ausführungsumgebung (`conda.yaml`) und den Test-Suites (`tests.robot`) wird auch _Roboter_ genannt.
RCC und der Scheduler werden immer mit dem {CMK}-Agenten verteilt, das Automationspaket nur optional, kann aber auch schon auf dem Test-Host vorhanden sein.

Der große Vorteil von RCC: Der ausführende Test-Host selbst benötigt keine konfigurierte Python-Umgebung.

Der Agent selbst wird nur für die Übertragung von Ergebnissen, Protokollen und Screenshots benötigt.
Dies ermöglicht auch die Überwachung sehr lange laufender oder lokal sehr ressourcenintensiver Suites – vorausgesetzt, Ihr Test-Host verfügt über entsprechende Kapazitäten.

Ein Wort noch zu den Betriebssystemen der Test-Hosts -- Windows und Linux verhalten sich nämlich minimal unterschiedlich.
Insbesondere weichen freilich die gesetzten Pfade ab; in den folgenden Beispielen führen wir nur Windows-Pfade an (sofern nicht wirklich explizite Pfade benötigt werden).
Für den Fall, dass RCC offline arbeiten muss, gibt es zudem Unterschiede bezüglich Nutzerkontext des Robotmk-Schedulers und der nötigen Befehle -- hier gehen wir natürlich explizit auf beide Systeme ein.

Und auch wenn es nicht direkt mit {CMK} zu tun hat:
Die link:https://robotframework-browser.org/[Browser-Bibliothek von Robot Framework^] nutzt Playwright -- und Playwright läuft nicht auf allen von {CMK} unterstützten Linux-Systemen.
Beachten Sie die entsprechenden link:https://playwright.dev/docs/intro#system-requirements[Systemvoraussetzungen^] (wobei Node.js in unserem Fall von RCC bereitgestellt wird).

Die Systemvoraussetzungen für die Testmaschine:

- CPU: mindestens 4 Kerne, empfohlen 8 Kerne
- RAM: 8 Gigabyte, empfohlen 16 Gigabyte
- Internetzugriff (sofern die Pakete heruntergeladen werden sollen)
- Für webbasierte Tests (Robot Framework Browser Library, basiert auf Playwright) Debian 12/13, Ubuntu 22.04/24.04


[#ruleconfig]
== Test-Suites überwachen mit Robotmk

Im Folgenden zeigen wir, wie Sie eine Test-Suite ins Monitoring aufnehmen.
Als Beispiel dient dazu eine simple Hello-World-Suite, die lediglich zwei Strings ausgibt und dazwischen kurz wartet.
Eine Einführung in Robot Framework ist hier freilich nicht das Thema, ein kurzer Blick in das Automationspaket und die Demo-Test-Suite muss aber sein, damit Sie sehen, welche Daten wo im Monitoring landen.

Das Beispiel läuft auf Basis von RCC, so dass der Windows-Host nicht extra konfiguriert werden muss.
Die `rcc.exe` wird mit dem Agenten verteilt und findet sich unter `C:\ProgramData\checkmk\agent\bin\`.
Die Beispiel-Suite können Sie als ZIP-Datei link:https://github.com/Checkmk/robotmk-examples/blob/main/templates/minimal.zip[über GitHub^] herunterladen.
Das Verzeichnis der Suite:

.C:\robots\mybot\
[{file}]
----
conda.yaml
robot.yaml
tests.robot
----

[TIP]
====
RCC kann grundsätzlich auch Test-Suites auf Basis etlicher anderer Programmiersprachen verarbeiten, für den Einsatz in {CMK} muss es aber die Deklaration nach Robot Framework sein.
====

Das Suite-Dateiverzeichnis beinhaltet nun zwei wichtige Dateien:
Die Deklaration der für die Ausführung benötigten Umgebung in der Datei `conda.yaml` und die eigentlichen Tests in der Datei `tests.robot` (die Suite).
Die Datei `robot.yaml` ist für den Einsatz in {CMK} nicht relevant, wird aber von RCC benötigt.

Der Vollständigkeit halber, hier ein kurzer Blick in die Datei `robot.yaml`:

.C:\robots\mybot\robot.yaml
[{yaml}]
----
tasks:
  task1:
    # (task definitions are not required by Robotmk, but expected by RCC to be compatible with other Robocorp features)
    shell: echo "nothing to do"

environmentConfigs:
  - conda.yaml

artifactsDir: output 
----

Zu Beginn legt `tasks` fest, welche Aufgaben, sprich Tests, überhaupt ausgeführt werden sollen.
Allerdings wird dieser Part zwar von RCC formal vorausgesetzt, von Robotmk jedoch nicht benötigt.

[TIP]
====
Robot Framework unterscheidet zwischen Tests und Tasks, die für Automatisierungen stehen.
Allerdings werden beide exakt gleich verwendet.
====

Im Bereich `environmentConfigs` wird dann lediglich auf die `conda.yaml` verwiesen, die sich um die eigentliche Umgebung kümmert.

Für die Umgebung werden in diesem Fall lediglich die Abhängigkeiten Python, Pip und Robot Framework (kompatibel bis Version 7.1) installiert.
Im Monitoring taucht der Umgebungsbau später als [.guihint]#RCC environment build status# auf.
Nur wenn die Umgebung erfolgreich gebaut wird, können auch die Tests abgearbeitet und folglich überwacht werden.

.C:\robots\mybot\conda.yaml
[{yaml}]
----
channels:
  - conda-forge

dependencies:
  - python=3.10.12
  - pip=23.2.1
  - pip:
     - robotframework==7.1
----

Die eigentliche Test-Suite sieht nun wie folgt aus:

.C:\robots\mybot\tests.robot
[{file}]
----
*** Settings ***
Documentation       Template robot main suite.

*** Variables ***
${MYVAR}    Hello Checkmk!

*** Test Cases ***
My Test
    Log      ${MYVAR}
    Sleep    3
    Log      Done.

----

Hier wird also lediglich der Wert der Variablen `MYVAR` ausgegeben, dann 3 Sekunden gewartet und abschließend `Done` ausgegeben.
Den Wert der Variablen können Sie später in der {CMK}-Weboberfläche setzen -- ansonsten wird der hier gesetzte Standardwert `Hello Checkmk!` genutzt.

[TIP]
====
Sie können diese Test-Suite manuell ausführen.
Dafür muss der Agent samt RCC bereits installiert sein (oder Sie laden die RCC-Binary selbst herunter).
Navigieren Sie zunächst in Ihr Test-Suite-Dateiverzeichnis, in dem auch die `tests.robot` liegt.
Starten Sie dann die RCC-Shell mit `C:\ProgramData\checkmk\agent\bin\rcc.exe task shell`.
Daraufhin wird die in der `conda.yaml` definierte virtuelle Umgebung gebaut.
Anschließend starten Sie die Suite mit `robot tests.robot`.
====

Und genau diese Ausführung übernimmt der Robotmk-Scheduler, sobald das Agentenplugin aktiv ist.


[#agentconfig]
=== Regel für das Agentenplugin konfigurieren

Den Robotmk-Scheduler finden Sie unter [.guihint]#Setup > Agent rules > Robotmk scheduler (Windows).#
Da die Regel recht umfangreich ist, hier zunächst ein Blick auf die noch leere Konfiguration:

.Konfiguration des Agentenplugins
image::robotmk_scheduler_00.png[alt="Leere Robotmk-Scheduler-Regel."]

Zunächst benötigt der Scheduler die Angabe des Basisverzeichnisses, in dem all Ihre Robot-Framework-Projekte, also Test-Suites, liegen.
Tragen Sie diesen beliebigen, absoluten Pfad unter [.guihint]#Base directory of Robot Framework projects# ein, beispielsweise `C:\robots`.

.Basisverzeichnis für alle Robot-Framework-Projekte
image::robotmk_scheduler_01.png[alt="Pfad für Test-Suites."]

Mit [.guihint]#Parallel running sequences of plans# folgt nun ein {CMK}-eigenes Konzept.

Zur Erklärung müssen wir zunächst eine Hierarchieebene tiefer gehen: Hier sehen Sie den Punkt [.guihint]#Sequence of plans.#
Ein jeder Plan legt fest, welche Suites mit welchen Parametern ausgeführt werden sollen.
Und Robot Framework arbeitet diese Suites dann nacheinander ab.
Der Grund ist simpel: In der Praxis geht es manchmal um Tests, die auf dem Desktop ausgeführt werden, und da könnten sich mehrere Test-Suites gleichzeitig in die Quere kommen (sich gegenseitig „die Maus klauen“).
Bis hierhin haben Sie also Robot-Framework-typisch *eine* Sequenz mit mehreren Plänen.

Die [.guihint]#Parallel running sequences of plans# sind nun eine Kapselung für mehrere solcher Sequenzen -- und werden selbst parallel ausgeführt.
Auch hier ist der Grund simpel: So können Test-Suites, die eben nicht auf den Desktop angewiesen sind, ohne Verzögerung in eigenen Plänen ausgeführt werden -- wie zum Beispiel die hier im Artikel eingesetzte Test-Suite.

Wieder zurück zum Dialog: Die einzige explizite Einstellung ist das Ausführungsintervall, das Sie unter [.guihint]#Sequence execution interval# setzen.

.Intervall für die (parallele) Ausführung von Sequenzen
image::robotmk_scheduler_02.png[alt="Ausführungsintervall für Sequenzen."]

[IMPORTANT]
====
Die Pläne in einer Sequenz haben natürlich selbst eine gewisse Laufzeit, bestimmt durch den Timeout einer einzelnen Ausführung und die maximale Anzahl wiederholter Ausführungen im Falle fehlgeschlagener Tests. 
Das Ausführungsintervall der Sequenz muss folglich größer sein als die Summe der maximalen Laufzeiten aller Pläne in der Sequenz.
Die maximale Laufzeit einer Sequenz berechnet sich wie folgt: [.guihint]#Limit per attempt# × (1 + [.guihint]#Maximum number of re-executions#).
====

Nun geht es an die Konfiguration eines ersten Plans.
Unter [.guihint]#Application name# können Sie einen beliebigen Namen eingeben.
Dieser Name muss nicht eindeutig sein!
Sinnvoll ist hier der Name der zu überwachenden Anwendung, beispielsweise `OnlineShop` oder hier im Beispiel schlicht `MyApplication`.
Nun kann es natürlich vorkommen, dass eben dieser Online-Shop mehrfach getestet wird, sei es durch andere Test-Suites oder dieselbe Test-Suite mit unterschiedlichen Parametern.
Um in solchen Fällen trotz identischer Namen dennoch eine Eindeutigkeit in den Ergebnissen zu erzielen, gibt es das Feld [.guihint]#Variant.#
Wird die Anwendung `OnlineShop` etwa einmal auf Deutsch und einmal auf Englisch getestet (über entsprechende Parameter), könnten Sie hier entsprechende Kürzel verwenden.
Im Monitoring gibt es dann Ergebnisse für `OnlineShop_de` und `OnlineShop_en.`

Notwendig ist hingegen die Angabe unter [.guihint]#Relative path to test suite file or folder.#
Die Pfadangabe ist relativ zum oben angegebenen Basisverzeichnis, also beispielsweise `mybot\test.robot` für `C:\robots\`.
Alternativ kann hier auch ein Verzeichnis (mit mehreren `robot`-Dateien) angegeben werden, dann wäre es schlicht `mybot`. 

.Sequenz für die Ausführung von Suiten 
image::robotmk_scheduler_03.png[alt="Bezeichnung und Pfad der Suite."]

Weiter geht es mit der [.guihint]#Execution configuration.#
Unter [.guihint]#Limit per attempt# legen Sie fest, wie lange eine Test-Suite maximal laufen darf -- pro Versuch.
Mit [.guihint]#Robot Framework re-executions# können Sie nun Robot Framework anweisen, Test-Suites bei fehlgeschlagenen Tests komplett oder inkrementell zu wiederholen.
Wenn die einzelnen Tests einer Test-Suite unabhängig voneinander sind, bietet sich die inkrementelle Strategie an, um Zeit zu sparen.
Testet die Test-Suite hingegen eine logische Abfolge, etwa "Login > Aufruf Produktseite > Produkt in den Warenkorb > Checkout", muss die Test-Suite natürlich komplett neu abgearbeitet werden.
Am Ende gibt es immer nur ein Ergebnis.

Bei kompletten Wiederholungen werden für das Endergebnis nur in sich abgeschlossene Suite-Ergebnisse berücksichtigt: Schlägt ein Test bei der letzten Wiederholung fehl, wird die Test-Suite als Fehlschlag gewertet.
Bei inkrementellen Wiederholungen setzt sich das Endergebnis aus den besten Teilergebnissen zusammen: Laufen einige Tests erst im dritten Anlauf erfolgreich durch, wird auch das Endergebnis als Erfolg gewertet.
Zur Erinnerung: Durch die Kombination aus Versuchen und maximalen Laufzeiten aller Pläne einer Sequenz wird deren minimales Ausführungsintervall bestimmt.

.Fehlgeschlagene Tests/Suiten können wiederholt werden
image::robotmk_scheduler_04.png[alt="Konfiguration von Ausführungslaufzeiten und -wiederholungen."]

Standardmäßig ist die Ausführung via RCC unter [.guihint]#Automated environment setup (via RCC)# aktiviert, für die Sie zwei Werte eintragen müssen.
Zum einen benötigt RCC die Angabe, wo die Datei `robot.yaml` liegt.
Deren primärer Zweck ist der Verweis auf die Datei `conda.yaml`, die für den Aufbau der Python-Umgebung verantwortlich ist, also die Installation von Python und Abhängigkeiten.
Diese Angabe ist relativ zum Basisverzeichnis, das Sie oben unter [.guihint]#Relative path to test suite file or folder# gesetzt haben.
Die YAML-Dateien können durchaus in Unterverzeichnissen gespeichert werden, Best-Practice ist aber das oberste Suite-Verzeichnis.
Für das obige Basisverzeichnis `C:\robot\` und das Suite-Verzeichnis `C:\robot\mybot` ist es entsprechend `mybot\robot.yaml`.

Beim folgenden Zeitlimit für den Bau der Python-Umgebung sollten Sie bedenken, dass bisweilen größere Datenmengen heruntergeladen und eingerichtet werden müssen.
Insbesondere für die benötigten Browser fallen hier schnell einige Hundert Megabytes an -- allerdings nur beim ersten Durchlauf.
RCC baut Umgebungen nur dann neu auf, wenn sich der Inhalt der `conda.yaml` geändert hat.

.Zeitlimit für den Aufbau virtueller Umgebungen
image::robotmk_scheduler_05.png[alt="RCC-Konfiguration der Suite."]

Unter [.guihint]#Robot Framework parameters# haben Sie die Möglichkeit, einige der Kommandozeilenparameter von Robot Framework (die auch der Befehl `robot --help` anzeigt) sowie Umgebungsvariablen zu nutzen.
Sollten Sie weitere Parameter nutzen wollen, hilft die Option [.guihint]#Argument files.#
Eine hier angegebene Datei kann beliebige robot-Parameter beinhalten.
Weitere Informationen über die einzelnen Parameter bekommen Sie über die Inline-Hilfe.

Für unser Beispielprojekt wird lediglich die Option [.guihint]#Variables# aktiviert und eine Variable `MYVAR` mit dem Wert `My Value` gesetzt.
Sie erinnern sich an den Befehl `Log ${MYVAR}` oben in der Datei `tests.robot`?
Dies ist die zugehörige Referenz.

.Einige Optionen des `robot`-Befehls
image::robotmk_scheduler_06.png[alt="Kommandozeilenparameter von Robot Framework."]

Besonderes Augenmerk verdient die Option [.guihint]#Secret environment variables,# da sie keine originäre Robot-Framework-Funktion ist.
Sie können hier geheime Umgebungsvariablen setzen, gedacht für Passwörter im Zusammenspiel mit der Robot-Framework-Bibliothek `CryptoLibrary`.
Die hier gesetzten Variablen tauchen nicht in Logs auf, werden allerdings im Klartext in die {CMK}-Konfigurationsdateien auf den jeweiligen Test-Hosts geschrieben.

.Geheime Passwörter für die CryptoLibrary
image::robotmk_scheduler_06b.png[alt="Option für geheime Umgebungsvariablen im Robotmk-Scheduler."]

Am Ende der Suite-Konfiguration gibt es noch drei weitgehend selbsterklärende Optionen.

Die erste Option gibt es exklusiv für Windows-Hosts.
[.guihint]#Execute plan as a specific user# ermöglicht es, Robotmk im Kontext eines bestimmten Nutzerkontos auszuführen.
Hintergrund: Standardmäßig wird Robotmk im Kontext des {CMK}-Agenten ausgeführt (link:https://learn.microsoft.com/de-de/windows/win32/services/localsystem-account[LocalSystem-Konto^]), der keine Berechtigung für den Zugriff auf den Desktop hat.
Hier kann nun ein Nutzer angegeben werden, der permanent an einer Desktop-Sitzung angemeldet sein muss und entsprechend Zugriff auf grafische Desktop-Anwendungen hat.

Aber nicht zu voreilig: Browser bilden hier eine Ausnahme!
Diese können headless laufen und Webseiten rendern.
Das Häkchen für einen spezifischen Nutzer sollten Sie wirklich nur setzen, wenn eine dedizierte Desktop-Anwendung abseits von Browsern gestartet wird -- nicht zuletzt aus Sicherheitsgründen.

Mit [.guihint]#Assign plan/test result to piggyback host# lassen sich die Ergebnisse des Plans/Tests einem anderen Host zuweisen.
Testet Robot Framework zum Beispiel den Bestellprozess eines Online-Shops, ließen sich die Ergebnisse so dem zugehörigen Webserver zuweisen.

Jeder Testdurchlauf produziert Daten, die unter `C:\ProgramData\checkmk\agent\robotmk_output\working\suites\` abgelegt werden.
Standardmäßig werden die Ergebnisse der letzten 14 Tage behalten, allerdings sollten Sie bedenken, dass sich hier schnell große Datenberge auftürmen.
Pro Durchlauf fallen mindestens knapp 500 Kilobytes Daten an -- mit komplexeren Test-Suites und beispielsweise eingebetteten Screenshots können es aber auch schnell einige Megabyte sein.
Je nach Ausführungsintervall, Größe des Reports und Anforderungen an Ihre Dokumentation sollten Sie hier eingreifen.

.Automatisches Aufräumen der vielen anfallenden Daten
image::robotmk_scheduler_07.png[alt="Optionen für Nutzerkontext, Host-Zuweisung und automatische Aufräumarbeiten."]

Hier angelangt, könnten Sie nun weitere Pläne in dieser Sequenz oder weitere Sequenzen erstellen.

Am Ende warten noch zwei Optionen, die sich wiederum auf die komplette Robotmk-Scheduler-Konfiguration beziehen.

[.guihint]#RCC profile configuration# erlaubt die Angabe von Proxy-Servern sowie davon auszunehmende Hosts.

Sehr nützlich kann auch [.guihint]#Grace period before scheduler starts# sein: Der Scheduler startet zusammen mit dem {CMK}-Agenten noch vor der Desktop-Anmeldung -- was freilich dazu führt, dass etwaige Tests auf dem Desktop fehlschlagen müssen.
Über eine Vorlaufzeit lässt sich der Start manuell verzögern.

.Eine Vorlaufzeit verhindert Fehlschläge
image::robotmk_scheduler_08.png[alt="Optionen für Proxy-Server und eine Vorlaufszeit für den Scheduler-Start."]

Damit ist die Konfiguration abgeschlossen und Sie können einen neuen xref:wato_monitoringagents#bakery[Agenten mit dem Plugin backen] und anschließend verteilen, manuell oder über die xref:agent_deployment#[automatischen Agenten-Updates.]


==== Daten in der Agentenausgabe

Die Ausgabe im Agenten ist recht umfangreich:
In mehreren Sektionen werden Fehlermeldungen, Status, Konfiguration und Testdaten übermittelt.
Letztere finden sich in der Sektion `robotmk_suite_execution_report`, hier ein stark gekürzter Auszug:

.mysite-robot-host-agent.txt
[{file}]
----
<<<robotmk_suite_execution_report:sep(0)>>>
{
    "attempts": [
        {
            "index": 1,
            "outcome": "AllTestsPassed",
            "runtime": 20
        }
    ],
    "rebot": {
        "Ok": {
            "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n
			<robot generator=\"Rebot 6.1.1 (Python 3.10.12 on win32)\" 
			generated=\"20240319 16:23:19.944\" 
			rpa=\"true\" 
			schemaversion=\"4\">\r\n<suite id=\"s1\" 
			name=\"Mybot\" 
			source=\"C:\\robots\\mybot\">\r\n<suite id=\"s1-s1\" 
			name=\"Tests\" 
			source=\"C:\\robots\\mybot\\tests.robot\">\r\n<test id=\"s1-s1-t1\" 
			name=\"Mytest\" 
			line=\"6\">\r\n<kw 
			name=\"Sleep\" 
			library=\"BuiltIn\">\r\n<arg>3 Seconds</arg>\r\n<doc>Pauses the test executed for the given time.</doc>\r\n<msg 
			timestamp=\"20240319 16:23:02.936\" 
			level=\"INFO\">Slept 3 seconds</msg>\r\n<status 
			status=\"PASS\" 
			starttime=\"20240319 16:23:00.934\" 
			endtime=\"20240319 16:23:02.936\"/>"
        }
    },
    "suite_id": "mybot",
    "timestamp": 1710861778
}
...
"html_base64":"PCFET0NUWVBFIGh0bWw+DQo8aHRtbCBsYW ...
----

Interessant sind hier vor allem zwei Bereiche.
Zum einen `rebot`: Das Tool `rebot` hat den eigentlichen Statusbericht für Robot Framework aus gegebenenfalls mehreren Teilergebnissen (daher auch re-bot) produziert.
Zum anderen die letzte Zeile `html_base64`: Danach folgen die HTML-Berichte von Robot Framework base64-kodiert.
Auch Screenshots, die über Tests angefertigt werden, werden auf diese Weise übertragen -- entsprechend umfangreich kann die Ausgabe/Datenmenge im Agenten werden.


==== Daten im Monitoring

Sobald der Robotmk-Scheduler und die Test-Suite durchgelaufen sind, wird die xref:glossar#service_discovery[Service-Erkennung] drei neue Services hervorbringen: 

.Die neu erkannten Robotmk-Services
image::robotmk_scheduler_09.png[alt="Robotmk-Services im Monitoring."]

Der Service [.guihint]#RMK Scheduler Status# existiert einmalig und unmittelbar nach der Verteilung.
Die Services für Pläne und Tests, hier [.guihint]#RMK MyApplication_mybot Plan# und [.guihint]#RMK MyApplication_mybot Test: /Test: My Test,# kommen ins Monitoring, sobald die zugehörigen Suites ein erstes Mal durchgelaufen sind.


[#serviceconfig]
=== Service-Regeln konfigurieren

==== Regel für Plan-Status anlegen

Zur Erinnerung: In der Agentenregel oben wurden maximale Laufzeiten für Pläne festgelegt.
Mit der Regel [.guihint]#Robotmk plan# lassen sich diese Laufzeiten auswerten.
So können Sie den Service etwa auf {CRIT} setzen, wenn 90 Prozent aller zusammengerechneten Timeouts erreicht werden.

.Schwellwerte für Statuswechsel  aufgrund von Laufzeiten
image::robotmk_service_suite_status_01.png[alt="Konfigurationsdialog für Grenzwerte für Laufzeiten von Test-Suites."]

Im Kasten [.guihint]#Conditions# gibt es die Möglichkeit, die Regel auf bestimmte Pläne zu beschränken.

.Optionale Beschränkung auf bestimmte Pläne
image::robotmk_service_suite_status_02.png[alt="Dialog mit Beschränkung auf die Test-Suite 'mybot'."]


==== Regel für Test-Status anlegen

Auch für einzelne Tests in den Test-Suites lassen sich weitere Daten ins Monitoring holen, über die Regel [.guihint]#Robotmk test.#
Hier finden Sie wieder die Möglichkeit, Laufzeiten zu überwachen, sowohl von Tests als auch von Keywords.
Die Überwachung von Keywords ist dabei eine {CMK}-eigene Funktion.
Daher könnte auch der Suite-interne Status im Robot-Framework-Bericht `OK` sein, weil die Test-Suite innerhalb der maximal erlaubten Laufzeit verarbeitet wurde -- in {CMK} jedoch {WARN} oder {CRIT}, weil schon bei zum Beispiel 80 Prozent dieser maximal erlaubten Laufzeit ein Statuswechsel stattfindet.

Zudem können über die Option [.guihint]#Enable metrics for high-level keywords# Metriken für übergeordnete Keywords erzeugt werden.
Nützlich ist dies insbesondere dann, wenn Ihre Test so organisiert sind, dass die übergeordneten Keywords das „Was“ beschreiben und die darunter liegenden Keywords das „Wie“ -- so bekommen Sie abstraktere Auswertungen.

Hier im Beispiel liegen die Schwellwerte für die maximale Laufzeit eines Tests bei 2 und 4 Sekunden.
Die Auswirkungen werden Sie unten im Kapitel xref:#monitoring[Robotmk im Monitoring] sehen.

.Über Keyword-Metriken lässt sich das Monitoring ausbauen
image::robotmk_service_test_status_01.png[alt="Regel zum Überwachen von Keywords mit Beispielwerten."]

Abermals gibt es im Kasten [.guihint]#Conditions# eine explizite Filtermöglichkeit, hier für einzelne Tests.

.Optionale Beschränkung auf bestimmte Tests
image::robotmk_service_test_status_02.png[alt="Dialog mit Option zur Beschränkung auf Tests."]


[#monitoring]
=== Robotmk im Monitoring

Im Monitoring finden Sie Services für den Status des Robotmk-Schedulers sowie der einzelnen Pläne und Tests -- natürlich auch, wenn Sie keine separaten Service-Regeln angelegt haben.


==== Scheduler-Status

Der Service [.guihint]#RMK Scheduler Status# ist {OK}, wenn der Scheduler anläuft und erfolgreich die Ausführungsumgebungen bauen konnte.

.RCC konnte die Umgebungen aufbauen -- in nur einer Sekunde
image::robotmk_monitorng_scheduler.png[alt="Status des Schedulers im Monitoring."]

Hier im Bild sehen Sie den Hinweis [.guihint]#Environment build took 1 second.#
Eine Sekunde, um eine virtuelle Python-Umgebung mit Pip und Robot Framework aufzubauen?
Das geht, weil RCC clever ist: Bereits heruntergeladene Dateien werden wiederverwendet, und neu gebaut wird nur nach Änderungen in der `conda.yaml`.
Der erste Bau hätte hier eher 30 oder mehr Sekunden gedauert.


==== Plan-Status

Der Status eines Plans wird in einem Service wiedergegeben, der nach Applikationsnamen und Suite benannt ist, beispielsweise [.guihint]#RMK MyApplication_mybot Plan.#

.Die Ausführung eines Plans -- vor allem relevant für Administratoren
image::robotmk_monitorng_suite.png[alt="Status der Test-Suite im Monitoring.",fullscreen=1]


==== Test-Status

Wirklich interessant wird es bei der Auswertung der Tests.
Im Bild sehen Sie nun die Auswirkung der oben gesetzten Schwellwerte für die Laufzeit von Tests -- hier die 2 Sekunden für den Zustand {WARN}.
Da im Test selbst die Anweisung `Sleep 3 Seconds` schon für eine längere Laufzeit sorgt, muss dieser Service hier auf {WARN} gehen, obwohl der Test erfolgreich verlaufen ist.
Dass der Test erfolgreich verlaufen ist, zeigt der Bericht von Robot Framework, den Sie über das icon:icon_log[Alt="Log-Icon."] Log-Symbol bekommen.

.Ergebnisse einer konkreten Suite -- vor allem relevant für Entwickler
image::robotmk_monitorng_test.png[alt="Status des Tests im Monitoring.",fullscreen=1]

Der Bericht zeigt nun klar und deutlich, dass Test und Test-Suite erfolgreich durchgelaufen sind.

.Der Robot-Framework-Log, hier im optionalen Dark-Mode
image::robotmk_monitorng_report_01.png[alt="Robot-Framework-Bericht für Test-Suite 'Mybot'."]

Ganz unten in den Daten sehen Sie auch die einzelnen Keywords, hier zum Beispiel `Log ${MYVAR}` samt dem in {CMK} für `MYVAR` gesetzten Wert `My value`.

.Die Log-Datei lässt sich bis auf kleinste Details ausklappen
image::robotmk_monitorng_report_02.png[alt="Robot-Framework-Bericht auf Ebene der Keywords."]


==== Dashboards

Natürlich können Sie sich wie gewohnt eigene Dashboards bauen -- unter [.guihint]#Monitor > Synthetic Monitoring# finden Sie aber auch zwei eingebaute Dashboards.

.Das komplette {CMK} Synthetic Monitoring im Überblick (gekürzt)
image::robotmk_dashboard_01.png[alt="Robotmk-Dashboard in der Weboberfläche.",fullscreen=1]

*Voraussetzung:* Damit Dashboards funktionieren, muss die xref:inventory#[HW-/SW-Inventur] auf den betroffenen Hosts aktiviert sein.


[#managedrobots]
== Managed Robots

Bislang sind wir von einem Szenario ausgegangen, in dem die Test-Suiten bereits auf den Test-Hosts bereitstehen.
Mit dem Feature [.guihint]#Managed robots# lassen sich Robots jedoch auch zentral auf dem {CMK}-Server verwalten und per {CMK}-Agenten verteilen.

Die ganze Konfiguration kennen Sie bereits von der obigen Vorgehensweise zu bereits existierenden Robots über die Regel [.guihint]#Robotmk scheduler (Windows|Linux).#

Zusätzlich geben Sie lediglich die Archiv-Datei (siehe unten) mit dem gepackten Robot an.
Hier im Bild sehen Sie das Upload-Feld für den Robot, darunter unter [.guihint]#Plan Settings# dieselben Optionen wie im Scheduler.
Achten Sie oben auf den Namen unter [.guihint]#Properties.#
Dieser ist obligatorisch, da der Robot später über diesen Namen im Scheduler konfiguriert wird.

.Der Robot selbst wird einfach als Archiv übergeben
image::robotmk_managed_robots_robot.png[alt="Konfiguration eines gemanagten Robots."]

Um einen solchen [.guihint]#Managed robot# einzusetzen, wird abermals die Regel [.guihint]#Robotmk scheduler (Windows|Linux)# genutzt.
Aber statt hier die Ausführung des Robots zu planen, geben Sie unter [.guihint]#Sequence of plans# einfach nur den gewünschten, vorkonfigurierten Robot an.
Bei Bedarf können Sie die Plan-Konfiguration des vorkonfigurierten Robots für diesen Einsatz hier dennoch anpassen.
In der Praxis beschränkt sich das Feature also meist darauf, die bekannte Konfiguration auszulagern und Robot-Archivdateien per Agent verteilen zu lassen.

.Der gemanagte Robot [.guihint]#mybot_managed# wird mit der Standard-Plan-Konfiguration geplant
image::robotmk_managed_robots_scheduler.png[alt="Konfiguration des Schedulers mit einem gemanagten Robot."]

Der Agent bringt die angegebenen Archive schließlich auf die gewünschten Hosts und legt sie im Agentenverzeichnis unterhalb von `robomk_output/managed` ab, wo sie dann entpackt und schlussendlich ausgeführt werden.


=== Robot-Archiv erstellen

Grundsätzlich könnten Sie einfach das komplette Robot-Verzeichnis mit den Standarddateien (`robot.yaml, conda.yaml, test.robot`) archivieren.

Allerdings werden solche Tests häufig per Git verwaltet und folglich finden sich regelmäßig Dateien, die nicht mit verteilt werden sollen -- typischerweise verwaltet über eine `gitignore`-Datei.
Als Hilfestellung für saubere Archive folgen hier zwei kleine Skripte für Windows und Linux, die Archive ohne die zu ignorierenden Dateien erstellen.
Verstehen Sie diese Skripte lediglich als Hilfestellung und testen Sie die Funktionsweise für Ihr System vorab.

[.tabs]
====
Windows::
+
--
[{powershell}]
----
PS C:\robots\myrobot> $FolderName = (Get-Item .).Name
PS C:\robots\myrobot> git archive --format=zip -o "../$FolderName.zip" HEAD
----

--
Linux::
+
--
[{shell}]
----
user@host:~/robots/myrobot$ FolderName="pass:[$](basename "$(pwd)")" && \
    git archive --format=zip -o "../${FolderName}.zip" HEAD
----
--
====



[#kpi]
== Monitoring von Key Performance Indicators (KPI)

Oben haben Sie bereits gesehen, dass sich die Laufzeiten von High-Level-Keywords als Teil eines Tests mit überwachen lassen.
Sie können aber auch beliebige Keywords als einzelne Services ins Monitoring holen.
Sinnvoll ist das vor allem für hoch abstrahierende Nutzer-Keywords, die ihrerseits mehrere einfache (Standard-)Keywords wie `Click` oder `Log` aufrufen -- also im Grunde als _Funktionen_ genutzt werden.
Für die Service-Erkennung stehen Ihnen zwei Varianten zur Verfügung: Muster in {CMK} und Marker in den Test-Suiten.

Für die _Muster-basierte Erkennung_ werden die gewünschten Keywords als reguläre Ausdrücke per {CMK}-Regel hinterlegt.

Für die _Marker-basierte Erkennung_ werden Marker direkt vor die Keywords in den Tests selbst geschrieben.
Die Verarbeitung dieser Marker läuft über eine Robotmk-eigene Bibliothek.

Egal wie die Keyword-Daten ins Monitoring kommen, dort müssen sie über die Service-Regel [.guihint]#Robotmk KPI monitoring# konfiguriert werden.


[#kpipattern]
=== Variante 1: Erkennung via Muster

Für diese Variante müssen Sie keinerlei Veränderungen an Ihren Tests selbst vornehmen.
Öffnen Sie einfach die Regel [.guihint]#Robotmk KPI discovery# und tragen Sie die zu überwachenden Keywords als reguläre Ausdrücke oder ganz konkrete Namen ein.

.Konfiguration von Keywords als separate Services
image::robotmk_kpi_pattern.png[alt="Konfiguratin von Keywords als separate Services für Robotmk."]

*Achtung:* Wenn der reguläre Ausdruck auf mehrere Keywords desselben Tests matcht, wird nur _ein_ Keyword erkannt und dessen Service-Status geht auf {UNKNOWN} (weil {CMK} freilich nicht weiß, welcher Treffer denn gemeint ist).


[#kpimarker]
=== Variante 2: Erkennung via Marker

Für die Erkennung via Marker müssen Sie folgende Schritte durchführen:

. Robotmk-Bibliothek installieren.
. Robotmk-Bibliothek in der Suite importieren.
. Marker-Keyword vor relevante Keywords setzen.

Für die Installation muss die `conda.yaml` von oben mit `robotframework-robotmklibrary` erweitert werden.
Änderungen gegenüber der obigen Suite sind gelb unterlegt:

.C:\robots\mybot\conda.yaml
[{yaml},highlight=9]
----
channels:
  - conda-forge

dependencies:
  - python=3.10.12
  - pip=23.2.1
  - pip:
     - robotframework==7.0
     - robotframework-robotmklibrary
----

Die Test-Suite `tests.robot` muss um die Bibliothek (im Bereich `Settings`) sowie einen Marker erweitert werden.
KPIs werden sich dabei häufig auf individuelle Nutzer-Keywords beziehen, daher hier eine Erweiterung um das Keyword `Foobar` (das lediglich das Standard-Keyword `Log` aufruft und seinerseits vom Testfall `My Test` aufgerufen wird).


.C:\robots\mybot\tests.robot
[{file},highlight=3;13-18]
----
*** Settings ***
Documentation       Template robot main suite.
Library             RobotmkLibrary

*** Variables ***
${MYVAR}    Hello Checkmk!

*** Test Cases ***
My Test
    Log      ${MYVAR}
    Sleep    3
    Log      Done.
    Monitor Subsequent Keyword Runtime  discover_as=My user keyword
    Foobar
	
*** Keywords ***
Foobar
    Log    The foo barred!

----

Das Robotmk-Keyword `Monitor Subsequent Keyword Runtime` ist der Marker, um ({CMK} anzuweisen) das folgende Keyword (`Foobar`) zu überwachen; genauer gesagt dessen Laufzeit.
Über das optionale Argument `discover_as` lässt sich hier ein individueller Name für den Service im Monitoring setzen -- das Keyword `Foobar` taucht folglich im Monitoring als Service namens [.guihint]#My user keyword# auf.

Der große Vorteil gegenüber der Muster-basierten Erkennung: Ein und dasselbe Keyword lässt sich auch mehrfach innerhalb eines Tests ganz explizit überwachen.

Hier das obige Beispiel, erweitert um zwei `Foobar`-Aufrufe:

.C:\robots\mybot\tests.robot
[{file},highlight=13-18]
----
*** Settings ***
Documentation       Template robot main suite.
Library             RobotmkLibrary

*** Variables ***
${MYVAR}    Hello Checkmk!

*** Test Cases ***
My Test
    Log      ${MYVAR}
    Sleep    3
    Log      Done.
    Monitor Subsequent Keyword Runtime  discover_as=My user keyword
    Foobar
    Monitor Subsequent Keyword Runtime  discover_as=Foobar_2
    Foobar
    Monitor Subsequent Keyword Runtime  discover_as=Foobar_3
    Foobar
	

*** Keywords ***
Foobar
    Sleep    3
    Log    The foo barred!

----

Die drei Aufrufe des Keywords `Foobar` würden folglich als `My user keyword`, `Foobar_2` und `Foobar_3` im Monitoring auftauchen.


=== Service-Regel konfigurieren

Egal über welche der beiden Varianten die Keywords ins Monitoring kommen, der nächste Schritt ist immer die Konfiguration der Auswertung:
Ab welcher Laufzeit sollen die Services auf {WARN} beziehungsweise {CRIT} gehen?
Dazu legen Sie in der Regel [.guihint]#Robotmk KPI monitoring# die entsprechenden Level fest.

.Service-Regel für die Auswertung von Keywords
image::robotmk_kpi_service_rule.png[alt="Service-Regel für die Auswertung von Keywords."]


=== Keywords im Monitoring

Die Keyword-Services tauchen im Monitoring unter einem dieser beiden Muster auf:

. Muster-basiert: [.guihint]#RMK MyApplication_mybot Test: /Test: My Test KPI (cmk): Foobar#
. Marker-basiert: [.guihint]#RMK MyApplication_mybot Test: /Test: My Test KPI (rf): Foobar#

Der Unterschied liegt also lediglich in der Herkunftsangabe in Klammern direkt vor dem Keyword.

.Muster- und Marker-basierte Keywords im Monitoring
image::robotmk_kpi_monitoring.png[alt="Muster- und Marker-basierte Keywords im Monitoring."]

Für das obige Bild mit zwei Foobar-Keyword-Services musste die Suite noch etwas erweitert werden:

.C:\robots\mybot\tests.robot
[{file},highlight=14-16;23-26]
----
*** Settings ***
Documentation       Template robot main suite.
Library             RobotmkLibrary

*** Variables ***
${MYVAR}    Hello Checkmk!

*** Test Cases ***
My Test
    Log      ${MYVAR}
    Sleep    3
    Log      Done.
    Foobar
    Monitor Subsequent Keyword Runtime  discover_as=Foobar
    Barfoo
	

*** Keywords ***
Foobar
    Sleep    3
    Log    The foo barred!

Barfoo
    Sleep    11
    Log    The End of Barfoo

----

Die beiden Keywords `Foobar` und `Barfoo` tauchen beide unter dem Namen [.guihint]#Foobar# im Monitoring auf, sind aber unterscheidbar durch die Herkunftsangabe in Klammern.

Das Beispiel mit *zwei* unterschiedlichen Keywords, die unter dem gleichen Namen geführt werden, dient vor allem der Verdeutlichung der Herkunftsangaben.

Wie oben bereits erwähnt: Der eigentliche Anwendungszweck von `discover_as` liegt darin, *ein* Keyword mehrmals in einem Test aufzurufen und unterschiedlich zu benennen. 


== Offline-Modus für Test-Umgebungen/RCC

Standardmäßig kümmert sich RCC um den Aufbau der Umgebungen, indem es die YAML-Konfiguration ausliest und die entsprechenden Pakete und Abhängigkeiten aus dem Netz herunterlädt.

Was aber, wenn die Hosts, auf denen die Tests laufen sollen, keinen oder sehr eingeschränkten Internetzugriff haben?

{CMK}, genauer gesagt der Robotmk-Scheduler, kann hier weiterhelfen und RCC-Umgebungen auch ohne Internetverbindung aufbauen.
Die Kurzversion: Die Umgebungen werden vorab auf einem beliebigen Rechner gebaut und anschließend wahlweise per ZIP-Archiv oder von einem Remote-Server verteilt.

Wie genau die beiden Wege funktionieren, lesen Sie unten.
Für das Verständnis braucht es allerdings ein wenig RCC-Wissen – und da müssen wir etwas ausholen: Einerseits, um die technischen RCC-Interna zu erläutern, andererseits um zu erklären, warum wir nicht (wie üblich) diesbezüglich auf den Hersteller verweisen.


[#rccbackground]
=== RCC-Exkurs

==== RCC-Historie

Woher kommt das Tool?
RCC wurde ursprünglich von der Firma Robocorp (inzwischen: Sema4.ai) entwickelt.
Das Geschäftsmodell von Sema4.ai ist eine cloudbasierte Plattform, in der Kunden ihre Skripte zur Automatisierung von Geschäftsprozessen betreiben können.
RCC bildet dabei den Unterbau, um sowohl lokal beim Kunden als auch in der Cloud immer exakt gleiche virtuelle Umgebungen zu bekommen.

Bei {CMK} setzen wir RCC für einen anderen Use Case ein: Hier sollen Ihre Robot-Framework-Skripte sowohl auf Ihrem lokalen (Entwicklungs-)Rechner als auch auf den Robotmk-Test-Hosts (Windows oder Linux) laufen können.

Im Zuge des Aufkaufs von Robocorp durch Sema4.ai 2024 wurde RCC umlizenziert und ist nunmehr proprietäre Software.
Leider ist das nicht sonderlich transparent abgelaufen -- daher auch dieser kleine Exkurs.

Die Variante, die mit {CMK} ausgeliefert wird, baut auf der letzten offenen RCC-Version auf und wird von uns gepflegt.
Von daher ist der RCC-Fork mittlerweile integrativer Bestandteil von {CMK} und wird hier auch dokumentiert — soweit für den Einsatzzweck in {CMK} relevant.

Noch etwas schwieriger wird es mit RCC Remote Server, dem Tool, das für die Verteilung der RCC-Umgebungen verantwortlich ist.
Dieses ist nämlich lediglich ein Bestandteil von RCC, der erst beim Kompilieren entsteht, kein eigenständiges Produkt.
Daher gab es seitens Robocorp nie eine wirkliche Dokumentation abseits eines ganz speziellen Einsatzes für die Robocorp-Plattform.


==== RCC-Interna

Für das Verständnis sollten Sie einige Begriffe und Konzepte kennen:

[cols="15,20,~",options="header"]
|===
|Begriff |Erklärung |Anmerkung

|Catalog
|Blueprint für Umgebungen
|Vorlagen für den Bau virtueller Umgebungen

|Hololib 
|Sammlung verfügbarer Catalogs
|Hololib ist ein Speicher für Blueprints, in dem jede einzigartige Datei nur ein mal gespeichert wird -- und sich für die Erzeugung von mehreren Spaces nutzen lässt.

|Space
|Instanz einer Umgebung
|Aus einem Catalog können mehrere Spaces hervorgehen

|(Shared) Holotree
|Sammlung verfügbarer Spaces
|(Shared) Holotree ist ein Speicher für Spaces, in dem jede einzigartige Datei nur ein mal gespeichert wird -- und für mehrere Spaces zur Verfügung steht.

|`ROBOCORP_HOME`
|Umgebungsvariable
|Pfad, unter dem RCC Hololib und Holotree speichert; standardmäßig `%HOME%/Appdata/Local/robocorp/` unter Windows und `~/.robocorp` unter Linux.

|`ROBOCORP_HOME` -- in {CMK}
|Abgesicherte Variante mit beschränkten Schreibzugriff 
|Pfad, unter dem {CMK}-RCC Hololib und Holotree speichert; unterhalb von `C:\robotmk\rcc_home` beziehungsweise `/opt/robotmk/rcc_home/`

|Holotree Path
|Absoluter Pfad, unterhalb von `ROBOCORP_HOME`
|Unter diesem Pfad werden Hololib-Blueprints zu Holotree-Spaces kompiliert; muss auf Quell- und Ziel-Rechner einer Umgebung identisch sein.

|RCCRemote
|Server zur Bereitstellung von Katalogen.
|Wird in der Regel über den Container  RCCRemote-Docker betrieben.

|===


==== ROBOCORP_HOME

`ROBOCORP_HOME` benötigt einen etwas genaueren Blick.
Diese Umgebungsvariable bestimmt den Pfad, unter dem RCC Hololib und Holotree speichert.
Alle Binärdateien innerhalb der Hololib, also der Vorlagensammlung, werden unterhalb eines absoluten Pfads kompiliert -- im sogenannten `holotree path`, einem Unterordner von `ROBOCORP_HOME`.
Das heißt auch: Auf den Test-Hosts, auf denen die Robots später laufen, müssen dieselben Pfade zur Verfügung stehen wie auf dem Rechner, auf dem Sie die Robots anlegen.

In diesem Zusammenhang ebenfalls relevant: Nutzer-Kontext.
Der Robotmk-Scheduler wird unter Windows standardmäßig als Unterprozess des {CMK}-Agenten unter dem LocalSystem-Konto (im Kontext `SYSTEM`) ausgeführt.
Unter Linux läuft der Scheduler unter dem gleichen Nutzer wie der Agent, also `root`.
Sollen die Nutzer-Kontexte nun geändert werden, verhalten sich Windows und Linux unterschiedlich.

*Windows:* Der Scheduler-Nutzer `SYSTEM` kann nicht geändert werden, allerdings lässt sich über die Option [.guihint]#Execute plan as a specific user# ein Nutzer für die Ausführung einzelner Robots/Pläne setzen.

*Linux:* Über die Regel [.guihint]#Customize agent package (Unix)# und deren Option [.guihint]#Customize user# lässt sich der Nutzer für den Agenten ändern; dafür ist es hier nicht möglich, einzelne Robots/Pläne in anderen Kontexten laufen zu lassen.

In {CMK} erlaubt sich der Robotmk-Scheduler noch eine zusätzliche Sicherheitsmaßnahme für RCC:
Um sicherzustellen, dass auch wirklich nur Scheduler und manuell gesetzte Nutzer Schreibzugriff auf `ROBOCORP_HOME` haben, muss hier ein ganz bestimmter Pfad gesetzt werden -- entsprechend obiger Tabelle plus eine weitere Hierarchieebene für den gewünschten Nutzerkontext (wie das in der Praxis aussieht, sehen Sie unten).
Dies verhindert, dass böswillige Dateien Einzug in Hololib/Holotree finden, also Code Injection (in aller Kürze: Würde `ROBOCORP_HOME` auf dem Entwicklungsrechner auf etwa `C:\foobar` gesetzt und würde dieses Verzeichnis auf den Test-Hosts bereits existieren und Malware enthalten, könnte diese ausgeführt werden).


[#ziparchive]
=== Variante 1: ZIP-Archive

Die Praxis ist weitaus einfacher als die technischen Hintergründe -- insbesondere bei der Arbeit mit einem Katalog als ZIP-Archiv (beziehungsweise tar.gz-Archiv unter Linux).
Im Grunde bauen Sie nur den Katalog unter Angabe der `ROBOCORP_HOME`-Variable, exportieren ihn als Archiv und verteilen dieses dann manuell.
Folgend der Weg im Detail.
Die Pfade in folgenden Beispielen beschränken sich auf Windows -- lediglich wenn Linux andere Kommandos erfordert, geben wir diese explizit an.


==== ROBOCORP_HOME setzen

Den Katalog, also die Vorlage für konkret umgesetzte Umgebungen (Spaces), können Sie auf einem beliebigen Rechner erstellen.

Setzen Sie zunächst im Terminal `ROBOCORP_HOME`.

Unter *Windows:*

Für die Headless-Ausführung unter dem LocalSystem-Konto:

[{cmd}]
[.copybutton]
----
C:\robots> set ROBOCORP_HOME=C:\robotmk\rcc_home\current_user
----
	
Für die Robots, die Desktop-Zugriff und einen entsprechenden Nutzer benötigen:

[{cmd}]
[.copybutton]
----
C:\robots> set ROBOCORP_HOME=C:\robotmk\rcc_home\HarryHirsch
----
	
Unter *Linux:*

Für die Headless-Ausführung als Standard-Nutzer:

[{shell}]
----
{c-user} export ROBOCORP_HOME=/opt/robotmk/rcc_home/current_user
----

Für die Robots, die Desktop-Zugriff und einen entsprechenden Nutzer benötigen:

[{shell}]
----
{c-user} export ROBOCORP_HOME=/opt/robotmk/rcc_home/HarryHirsch
----
	
Anschließend können Sie Ihr Bot-Verzeichnis betreten und die Umgebung/den Katalog bauen:

[{cmd}]
[.copybutton]
----
C:\robots> cd myrobot
C:\robots\myrobot> rcc holotree vars
----

	
==== ZIP-Katalog erstellen

Nun muss der Katalog als ZIP exportiert werden.
Prüfen Sie zunächst, ob ein Hololib-Katalog mit dem korrekten Holotree-Pfad existiert.
Dazu benötigen Sie den Hash der `conda.yaml`:

[{cmd}]
[.copybutton]
----
C:\robots\myrobot> rcc holotree hash conda.yaml

Blueprint hash for [conda.yaml] is #296bd91e514e7d1d#
----

Lassen Sie sich anschließend alle verfügbaren Hololib-Kataloge anzeigen (Ausgabe gekürzt):

[{cmd}]
[.copybutton]
----
C:\robots\myrobot> rcc holotree catalogs

Blueprint         Platform       Dirs    Files    Size     Relocate  Holotree path             
---------         --------       ------  -------  -------  --------  -------------
.#296bd91e514e7d1d# windows_amd64     358     4895     123M        28  c:\ProgramData\robocorp\ht
...
----
// ML: @MFS - guck doch mal bitte, wie sich der Blueprint ohne den . vorne einfärben lässt - ohne macht der Komisches.

Wenn sich der Hash in der Liste wiederfindet, können Sie exportieren:

[{cmd}]
[.copybutton]
----
C:\robots\myrobot> rcc holotree export -r robot.yaml --zipfile myrobot-env.zip
----


==== ZIP-Katalog verteilen

Das Verteilen des gezippten Katalogs ist simpel:
Kopieren Sie das Archiv händisch auf den Test-Host, beispielsweise nach `C:\robotmk\holotrees\myrobot-env.zip`.

Setzen Sie entsprechend in der Regel [.guihint]#Robotmk Scheduler (Windows|Linux)# (beziehungsweise in [.guihint]#Managed robots#) die Option [.guihint]#Environment dependency handling# auf [.guihint]#Load from ZIP file# und geben Sie den gewünschten Pfad zum gezippten Katalog an, hier also `C:\robotmk\holotrees\myrobot-env.zip`.
Bitte nicht verwechseln, dieser Pfad hat nichts mit dem `holotree path` zu tun!
Er dient nur als Ablage für die zu importierenden Hololib-Katalog-ZIPs.

.Ablageort für gezippte Hololib-Kataloge (Vorlagen zum Bauen von Umgebungen) 
image::robotmk_rcc_offline_dependency_handling.png[alt="Angaben zur Handhabung eines gezippten Katalogs."]

Wenn später der Scheduler startet, importiert er sämtliche Hololib-Katalog-ZIPs und baut aus diesen Vorlagen die Spaces, also die letztlich tatsächlich genutzten Umgebungen.
Statt also sämtliche Abhängigkeiten per pip und Conda aus dem Internet herunterzuladen, wird lediglich ein Archiv entpackt -- was nicht nur offline, sondern auch deutlich fixer ist.

Und nur, um Missverständnissen vorzubeugen: Die Robots selbst müssen natürlich nach wie vor schon auf dem Test-Host bereit stehen oder als Managed Robots ausgebracht werden, hier geht es rein um die Umgebungen!


[#rccremote]

=== Variante 2: RCCRemote-Server

Gleich vorweg: RCCRemote ist kein eigenständiges Tool, Sie werden dazu keine eigene Dokumentation oder auch nur eine Produktseite seitens Robocorp/Sema4 finden.
Der Remote-Server ist lediglich Teil von RCC und wird beim Kompilieren von RCC mitgebaut.
Betrieben wird er in der Regel per Container.
Für den Container-Betrieb gibt es mittlerweile ein Projekt auf den GitHub-Seiten von Elabit, dem Entwickler des ursprünglichen Robotmk-Plugins, namens link:https://github.com/elabit/rccremote-docker[RCCRemote-Docker.^]
RCCRemote und RCCRemote-Docker sind jedoch nicht Teil von {CMK} Synthetic Monitoring und *nicht vom {CMK}-Support gedeckt!*

Kataloge für diesen Distributionsweg lassen sich auf zwei Wegen erstellen: Für Windows wie Linux lassen sich als ZIP exportierte Kataloge (siehe oben) verwenden.
Ausschließlich für Linux besteht zudem die Möglichkeit, die Kataloge direkt im _RCCRemote-Docker-Container_ zu bauen, womit sich händisches Eingreifen komplett erledigt.

Wie Sie RCCRemote-Docker aufsetzen, mit Zertifikaten umgehen und Kataloge importieren, können Sie auf den link:https://github.com/elabit/rccremote-docker[Projektseiten^] nachlesen.

Die Konfiguration auf {CMK}-Seite ist nun wieder -- typisch -- ganz trivial: Die Option [.guihint]#Environment dependency handling# wird dieses Mal auf [.guihint]#Fetch from RCC remote server# gesetzt und mit der Adresse des Servers versorgt.

.RCCRemote-Docker kann Kataloge via Netzwerk liefern
image::robotmk_rcc_offline_dependency_handling_2.png[alt="Angabe zur Handhabung von RCCRemote."]

Eine letzte Einstellung fehlt noch, je nachdem, ob Ihr RCCRemote-Server ein selbst-signiertes oder ein CA-signiertes Zertifikat einsetzt.
In beiden Fällen müssen Sie in der Regel [.guihint]#Robotmk scheduler (Windows|Linux)# die Option [.guihint]#RCC profile configuration# auf [.guihint]#Custom profile# setzen.

Bei einem selbst-signierten Zertifikat genügt es, das Häkchen bei [.guihint]#Validate TLS certificates# nicht zu setzen:

.TLS-Zertifikate müssen nicht zwangsläufig validiert werden
image::robotmk_rcc_offline_tls_self.png[alt="Inaktive TLS-Validierung für selbst signierte Zertifikate."]

Handelt es sich um ein CA-signiertes Zertifikat, muss die Option hingegen aktiviert und das Zertifikat der signierenden Stelle unter [.guihint]#Root CA# hinterlegt werden (im PEM-Format):

.CA-signierte TLS-Zertifikate werden wie üblich per Angabe der Root CA validiert
image::robotmk_rcc_offline_tls_ca.png[alt="Hinterlegtes Zertifikat der CA."]


[#troubleshooting]
== Troubleshooting

=== Scheduler meldet `No Data`

Wenn der Scheduler keinerlei Daten bekommt, hat der Bau der Umgebung vermutlich nicht funktioniert.
Ein häufiger Grund dafür sind Netzwerkprobleme, aufgrund derer zum Beispiel bestimmte Abhängigkeiten nicht geladen werden können.
Schauen Sie in diesem Fall in die zugehörige Log-Datei unter `C:\ProgramData\checkmk\agent\robotmk_output\working\environment_building` beziehungsweise `/var/lib/check_mk_agent/robotmk/scheduler/environment_building`.


=== Environment Building schlägt fehl: `post-install script execution`

Dies ist ein besonders interessanter Fehler, der Ihnen auf frischen Windows-Systemen begegnen könnte.
In der `conda.yaml` können auch Anweisungen hinterlegt werden, die nach der Installation der Abhängigkeiten ausgeführt werden sollen -- beispielsweise die Initialisierung des Robot-Framework-Browsers.
Hier sollen also Python-Befehle ausgeführt werden.
Nun hat Windows 11 standardmäßig Aliasnamen für `python.exe` und `python3.exe` vorgegeben, die auf den Microsoft-Store verweisen.
Diese Aliasnamen müssen Sie unter `Einstellungen/Aliase für App-Ausführung` deaktivieren.

[#files]
== Dateien und Verzeichnisse

=== Windows
	
[cols="~,45",options="header"]
|===
|Pfad |Bedeutung
|`C:\ProgramData\checkmk\agent\robotmk_output\working\plans\` |Log-Dateien und Ergebnisse der Suites
|`C:\ProgramData\checkmk\agent\robotmk_output\working\environment_building` |Log-Dateien zum Aufbau virtueller Umgebungen
|`C:\ProgramData\checkmk\agent\robotmk_output\working\rcc_setup` |Meldungen der RCC-Ausführung
|`C:\ProgramData\checkmk\agent\log\robotmk_scheduler_rCURRENT.log` |Log-Datei des Agentenplugins
|`C:\ProgramData\checkmk\agent\bin\` |`rcc.exe` und `robotmk_scheduler.exe`
|`C:\ProgramData\checkmk\agent\plugins\` |Agentenplugin `robotmk_agent_plugin.exe`
|===

=== Linux
	
[cols="~,45",options="header"]
|===
|Pfad |Bedeutung
|`/var/lib/check_mk_agent/robotmk/scheduler/plans` |Log-Dateien und Ergebnisse der Suites
|`/var/lib/check_mk_agent/robotmk/scheduler/environment_building` |Log-Dateien zum Aufbau virtueller Umgebungen
|`/var/lib/check_mk_agent/robotmk/scheduler/rcc_setup` |Meldungen der RCC-Ausführung
|`/usr/lib/check_mk_agent/robotmk/` |`rcc` und `robotmk_scheduler`
|`/usr/lib/check_mk_agent/plugins/` |Agentenplugin `robotmk_agent_plugin`
|`/var/lib/check_mk_agent/robotmk/scheduler/managed/` |Ausführungsort for Managed Robots
|`/usr/lib/check_mk_agent/managed_robots/` |Ablageort für Managed-Robots-Archive
|===

*Achtung:* Unter Linux legt der Robotmk-Scheduler keine eigene Log-Datei an (unter Windows die `robotmk_scheduler_rCURRENT.log`), sondern protokolliert via Agent und Syslog.
Der zugehörige Befehl:

[{shell}]
----
{c-user} journalctl -xu robotmk-scheduler-daemon.service
----
