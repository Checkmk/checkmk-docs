// -*- coding: utf-8 -*-
// IGNORE %
include::global_attr.adoc[]
= Scheduled downtimes
:revdate: 2024-03-12
:title: Scheduled downtimes
:description: Scheduled downtimes must be taken into account in monitoring. How scheduled downtimes can be mapped in {CMK} can be found here.

{related-start}
xref:commands#[Commands]
xref:notifications#[Notifications]
xref:timeperiods#[Time periods]
{related-end}


[#mode]
== Mode of operation

IT-operations distinguish between two types of outage: planned and unplanned.
The monitoring system initially cannot know if a detected outage was planned or not.
With the concept of _scheduled downtimes_ the system can be informed of a host’s or service’s planned outages
by defining a scheduled downtime for the corresponding object.
If a host or service is in such a scheduled downtime, it has the following effects:

* In the xref:glossar#view[views], an icon appears next to the affected hosts and services:
Hosts and services are marked with a icon:icon_downtime[alt="Icon for displaying a scheduled downtime."] guiding cone.
If a host with all its services is sent to downtime, the services get the icon:icon_derived_downtime[alt="Icon for displaying a derived scheduled downtime for a service."] icon with server and small guiding cone.
In the xref:history[history], started downtimes are marked with icon:icon_alert_downtime[alt="Icon for displaying a started scheduled downtime."] and finished downtimes with icon:icon_alert_downtimestop[alt="Icon for displaying a finished scheduled downtime."].

* Problem notifications are deactivated during the downtime.

* The affected hosts/services are not identified as having a problem in the xref:user_interface#overview[[.guihint]#Overview#].

* Scheduled downtimes are specially taken into account in the xref:availability#[availability analysis].

* For information a special notification will be triggered at the start and end of a scheduled downtime.


[#enter]
== Entering scheduled downtimes

Defining scheduled downtimes is achieved via xref:commands#[commands].
All actions pertaining to scheduled downtimes are available here in a single box:

ifdef::onprem[]
.The dialog for defining a scheduled downtime in the commercial editions
endif::[]
image::basics_downtimes_schedule.png[alt="Dialog for defining a scheduled downtime."]

The [.guihint]#Comment# field must always be filled out.
You can include a URL, such as `\https://www.example.com` in this field, which will be replaced by a clickable link.
There are multiple ways to define the time range --
from the simple [.guihint]#2 hours#, which defines the downtime as starting *from now*, to the entry of an explicit time range where a future downtime can also be defined.


[#scheduled]
=== Regularly scheduled downtimes

ifdef::onprem[]
{cee-only}
endif::[]
Some maintenance is performed regularly -- a once-weekly automatic restart of a server, for example.
Manually entering a scheduled downtime for each occasion would be time-consuming.
If you would only like to silence the xref:notifications#[notifications], you could configure xref:timeperiods#[time periods] and the [.guihint]#Notification period for hosts# and [.guihint]#Notification period for services# rule sets.
These have various restrictions however 
-- one important restriction being that global configuration permissions are required for setting time periods.

ifdef::onprem[]
For this purpose the commercial editions offer the concept of automatic, periodically-recurring, scheduled downtimes.
endif::[]
ifdef::saas[]
For this purpose {CE} offers the concept of automatic, periodically-recurring, scheduled downtimes.
endif::[]
These can be set in two different ways.


==== Setting using a command

The first way is via the [.guihint]#Repeat# option.

image::basics_downtimes_periodic.png[alt="Select the recurrence period."]

With this you select the period when the downtime should repeat.
Enter the *first* occurrence via [.guihint]#Start# and [.guihint]#End#.
The period is calculated from the start time entered here.
The following options are available:

[cols="30,~"]
|===

|[.guihint]#never# |The downtime is not repeated, i.e. only executed once (default setting).
|[.guihint]#hour# |The downtime repeats hourly at the same time.
|[.guihint]#day# |Daily, at the same time every day.
|[.guihint]#week# |Recurs every seven days on the same weekday and time of day as on the first occasion.
|[.guihint]#second week# |Same as for weekly, but every 14 days.
|[.guihint]#fourth week# |Same as for weekly, but now every 28 days.
|[.guihint]#same nth weekday (from beginning)# |This allows you to implement monthly recurrences based on the day of the week.
So, for example, if the start date is the second Monday in the month, then a downtime will be scheduled for the second Monday in every subsequent month.
|[.guihint]#same nth weekday (from end)# |Similar to the previous option, except that it is calculated from the end of the month -- for example "every last Friday in the month".
|[.guihint]#same day of the month# |In this case the weekday is irrelevant.
Here the date in the month is used.
So, if the start date is the 5th, the downtime will be scheduled to occur on the 5th of each month.
|===


==== Setting using rules

An elegant alternative method for the configuration of periodic scheduled downtimes is to define them using xref:glossar#rule[rules].
With xref:glossar#host_tag[host tags] you can define things such as e.g.,
_Every production Windows server has a scheduled downtime every Sunday from 22:00 to 22:10._

You can in fact achieve almost the same results by using the host search to find all the affected servers, and then entering the scheduled downtime via a command.
But this functions only with *existing* servers.

If in the future a new host is added to the monitoring it will not be covered by this entry.
However, if you work with rules this will not be a problem.
A further advantage with rules is that the maintenance policy can be altered very easily at a later date -- simply by modifying the rules.

The rules for recurring scheduled downtimes can be found under [.guihint]#Setup > Hosts > Host monitoring rules > Recurring downtimes for hosts#
respectively [.guihint]#Setup > Services > Service monitoring rules > Recurring downtimes for services#.

image::basics_downtimes_recurring_rule.png[alt="Defining a regular scheduled downtime using a rule."]


[#advanced_options]
=== Advanced options

In addition to the regular scheduled downtimes just described, there are other options for defining scheduled downtimes.
These can be found in the [.guihint]#Advanced options#:

image::basics_downtimes_advanced.png[alt="The advanced options for scheduled downtimes."]

ifdef::onprem[]
The option [.guihint]#Only for hosts: Set child hosts in downtime# is useful for routers and switches, but also for virtualization hosts, for example.
endif::[]
ifdef::saas[]
The option [.guihint]#Only for hosts: Set child hosts in downtime# is useful for virtualization hosts, for example.
endif::[]
In this way {CMK} will also automatically set a scheduled downtime on all directly-connected hosts, and also on indirectly-connected hosts via the host in question (if [.guihint]#Include indirectly connected hosts (recursively)# is selected).

With the [.guihint]#Only start downtime if host/service goes DOWN/UNREACH...# option the scheduled downtime does not begin automatically at a nominated time, rather first when a real problem status appears for the host.
This option is useful when, e.g., you know that a host will enter a {DOWN} state for a few minutes, but the exact time of the event cannot be predicted.

Example:
You define a scheduled downtime as being from 14:00 to 16:00, and activate the option [.guihint]#Only start downtime if host/service goes DOWN/UNREACH...# with a duration of 30 minutes.
At 14:00 the scheduled downtime will not activate, but will be in a standby position.
As soon as the host enters a {DOWN} or {UNREACH} state, the scheduled downtime  will begin and the blue pause icon will appear.
This will remain so for the duration of the time nominated in the option, regardless of the actual status of the host, and if need be beyond the end-time specified for the downtime.

image::basics_downtimes_flexible.png[alt="Setting a flexible scheduled downtime."]

Therefore with flexible scheduled downtimes the start/end time is only the time window in which the scheduled downtime can begin.
If no problem status occurs within this time window the scheduled downtime will simply be skipped.
These conditions of course also apply for services.


[#activate]
== Activating scheduled downtimes

Click on [.guihint]#On service: Schedule downtime# or [.guihint]#On host: Schedule downtime# to activate the settings you have just defined for the relevant services or hosts.

If you have just scheduled downtimes for services, for example in the [.guihint]#Services of Host# view, you can also click on [.guihint]#Schedule downtime on host# to ensure that the scheduled downtimes do not relate to the services, but instead directly to the associated host.

image::basics_downtimes_schedule_host.png[alt="Confirmation that the scheduled downtime should actually be applied to the host."]


[#edit_remove]
== Editing and removing scheduled downtimes

Scheduled downtimes have their own view in {CMK} -- this is accessed via [.guihint]#Monitor > Overview > Scheduled downtimes#:

image::basics_downtimes_editdowntimes.png[alt="View of scheduled downtimes."]

As in every view, you can narrow the selection with a icon:icon_filter[alt="Icon for displaying the filter bar."] filter.
ifdef::onprem[]
With the icon:icon_commands[alt="Icon for displaying a command."] commands, in this view you can remove one or more downtime(s), and even alter them retroactively (only in the commercial editions), e.g., if the times need to be extended when the downtime is proving to be longer than anticipated.
endif::[]
ifdef::saas[]
With the icon:icon_commands[alt="Icon for displaying a command."] commands, in this view you can remove one or more downtime(s), and even alter them retroactively, e.g., if the times need to be extended when the downtime is proving to be longer than anticipated.
endif::[]

image::basics_downtimes_editdowntimes.png[alt="Editing a scheduled downtime."]


[#history]
== History

The [.guihint]#Monitor > History > Downtime history# view does not display the current scheduled downtimes, rather their histories -- thus all events with which a scheduled downtime began or ended (with a natural end or via a remove command).

image::basics_downtimes_downtimes_history.png[alt="Overview of past scheduled downtimes."]


[#availability]
== Scheduled downtimes and availability

As mentioned at the beginning, scheduled downtimes have an effect when evaluating the xref:availability#[availability analysis].
By default all scheduled downtimes are calculated in their own ‘pot’ and shown in the [.guihint]#Downtime# column.

image::basics_downtimes_availability_list.png[alt="Availability analysis of the hosts."]

Precisely how scheduled downtimes are to be assessed can be defined via [.guihint]#Availability > Change computation options#:

image::basics_downtimes_availability_option.png[alt="Selection for taking scheduled downtimes into account.", width=50%, align=center]

[cols="30,~"]
|===

|[.guihint]#Honor scheduled downtimes# |Scheduled downtimes are included in the availability graphs and displayed as a separate column.
This is the standard.
|[.guihint]#Exclude scheduled downtimes# |Scheduled downtimes are ignored completely when calculating the 100{nbsp}%.
All availability percentages therefore refer only to the remaining times, in order to answer the question:
_What percentage of non-maintenance time was the object available?_
|[.guihint]#Ignore scheduled downtimes# |Scheduled downtimes will not be factored in -- only the object’s actual states are relevant.
|===

Under [.guihint]#Phases# there is the additional [.guihint]#Treat phases of UP/OK as non-downtime# option.
If this is selected, times in which an object is undergoing maintenance but is still {OK} or {UP} at the same time are *not* treated as scheduled downtimes.
Thus only the scheduled time that resulted in a *real* outage will be included in the calculations.
