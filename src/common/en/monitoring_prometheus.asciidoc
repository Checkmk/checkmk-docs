// -*- coding: utf-8 -*-
// IGNORE kube
include::global_attr.adoc[]
= Integrating Prometheus
:revdate: 2024-04-12
:title: Integrating Prometheus
:description: Prometheus can be integrated into {CMK} to monitor fast-moving container environments.

{related-start}
link:https://checkmk.com/integrations[Catalog of Check Plug-ins]
xref:monitoring_kubernetes#[Monitoring Kubernetes]
{related-end}


== Introduction

=== Background and motivation

You may be wondering why you should even integrate Prometheus into {CMK} at all -- therefore we would like to make an important note at this point:
Our integration of Prometheus is aimed at all of our users who already use Prometheus.
By integrating Prometheus into {CMK}, we can close the gap that has opened up here so that you do not have to continuously check two monitoring systems.

This enables you to correlate the data from the two systems, accelerate any error analysis and, at the same time and facilitate communication between {CMK} and Prometheus users.
So {CMK} remains as your "single pane of glass".


==== Finally, context again

As a most pleasant side benefit of this integration, it is likely that your metrics from Prometheus automatically receive a meaningful context thanks to {CMK}.
For example, while Prometheus correctly shows you the amount of main memory used, you do not have to take any extra manual steps in {CMK} to find out how much of the total available memory this is.
As banal as this example may be, it shows at which points {CMK} makes monitoring easier -- even in some of the smallest details.


=== Exporter or PromQL

The integration of the most important exporters for Prometheus is provided via a xref:glossar#special_agent[special agent].
The following exporters for Prometheus are available:

* link:https://checkmk.com/integrations?tags=cadvisor[cAdvisor (Container Advisor)^]
* link:https://github.com/prometheus/node_exporter/blob/master/README.md[Node Exporter^]

If we do not support the exporter you need, experienced Prometheus users also have the option of sending self-defined queries to Prometheus directly via {CMK}.
This is performed using Prometheus' own xref:promQL[query language, PromQL].


== Setting up the integration

=== Creating a host

Since the concept of hosts in Prometheus simply doesn't exist, first create a place that gathers the desired metrics.
This host forms the central point of contact for the special agent, and this then later distributes the delivered data to the correct hosts in {CMK}.
To do this, create a new host using [.guihint]#Setup > Hosts > Hosts > Add host#.

image::prometheus_hostname.png[]

If the specified host name cannot be resolved by the {CMK} server, enter the IP address under which the Prometheus server can be reached.

Make all other settings for your environment and confirm your selection with [.guihint]#Save & view folder#.

=== Creating a rule for Prometheus

Before {CMK} can find metrics from Prometheus, you must first set up the special agent using the [.guihint]#Prometheus# rule set.
You can find this via [.guihint]#Setup > Agents > VM, cloud, container#.
There are several options for customizing the connection of your Prometheus server's web front end, regardless of which exporter you want to use.

* [.guihint]#URL server address#:
Specify the URL of your Prometheus server here, including all necessary ports.
Do not include the protocol here, as it selectable below.

* [.guihint]#Authentication#:
If a login is required, enter the access data here.

* [.guihint]#Protocol#:
After installation the web front end is provided via HTTP.
If you have secured the access with HTTPS, change the protocol here accordingly.

You can see the default values in the following screenshot:

image::prometheus_connection_details.png[]


[#node_exporter]
==== Integration using Node Exporter

If, for example, you now want to integrate the hardware components of a so-called [.guihint]#Scrape Targets# from Prometheus, use the Node Exporter.
Select [.guihint]#Add new Scrape Target#, and from the drop-down menu that opens, select [.guihint]#Node Exporter#:

image::prometheus_ruleset_exporter.png[]

Here you can select which hardware or which operating system instances are to be queried by the Node Exporter.
You always have the option to deselect information if you do not want to retrieve it.
The services created in this way use the same check plug-ins as are used for other Linux hosts.
This means that their behavior is identical to those already familiar, so without needing to adapt to something new you can quickly configure thresholds, or work with graphs.

Normally the agent will try to automatically assign the data to the hosts in {CMK}, and likewise also for the host in {CMK} that fetches the data.
However, if in the data from the Prometheus server neither the IP address, the FQDN, nor localhost are present,
use the [.guihint]#Explicitly map Node Exporter host# option to specify which host from the Prometheus server data is to be assigned to the Prometheus host in {CMK}.


[#cadvisor]
==== Integration using cAdvisor

The cAdvisor exporter enables the monitoring of Docker environments, and returns metrics.

Via the menu [.guihint]#Entity level used to create {CMK} piggyback hosts# you can determine whether and how the data from Prometheus should be collected in an ready-aggregated form.
You can choose from the following three options:

* [.guihint]#Container - Display the information on container level#
* [.guihint]#Pod - Display the information for pod level#
* [.guihint]#Both - Display the information for both, pod and container, levels#

Select either [.guihint]#Both# or [.guihint]#Container#, and also define the name under which hosts are created for your containers.
The following three options are available for the naming.
The option [.guihint]#Short# is the default:

* [.guihint]#Short - Use the first 12 characters of the docker container ID#
* [.guihint]#Long - Use the full docker container ID#
* [.guihint]#Name - Use the name of the container#

image::prometheus_cadvisor_names.png[]

Note that your selection here affects the automatic creation and deletion of hosts according to your xref:dcd_cadvisor[dynamic host configuration].

With [.guihint]#Monitor namespaces matching# you have the possibility to limit the number of monitored objects.
All namespaces that are not covered by the regular expressions will then be ignored.


[#promQL]
==== Integration via PromQL

As already mentioned, with the help of the special agent it is also possible to send requests to your Prometheus servers via PromQL.
Select [.guihint]#Service creation using PromQL queries > Add new Service#.
Use the [.guihint]#Service name# field to determine what the new service should be called in {CMK}.

Next, select [.guihint]#Add new PromQL query# and use the [.guihint]#Metric label# field to specify the name of the metric to be imported into {CMK}.
Now enter your query in the field [.guihint]#PromQL query#.
It is important that this query may only return a *single* value.

image::prometheus_ruleset_promql.png[]

In this example, Prometheus is queried about the number of running and blocked processes.
In {CMK} these processes and the two metrics -- [.guihint]#Running# and [.guihint]#Blocked# -- are then combined in a service called [.guihint]#Processes#.

You can also assign thresholds to these metrics.
To do this, activate [.guihint]#Metric levels# and then choose between [.guihint]#Lower levels# or [.guihint]#Upper levels#.
Note that these always specify floating point numbers, but of course they also refer to metrics that return integers only.


==== Assigning a rule to the Prometheus host

Finally, explicitly assign this rule to the host you just created and confirm with [.guihint]#Save#.

image::prometheus_ruleset_explicit_host.png[]


=== Service discovery

Now that you have configured the special agent, it is time to run a xref:glossar#service_discovery[service discovery] on the Prometheus host.

image::prometheus_discovery.png[]


[#dcd]
== Dynamic host configuration

=== General configuration

{cee-only}
Monitoring Kubernetes clusters is probably one of the most common tasks that Prometheus performs.
To ensure an integration of the sometimes very short-lived containers, which are orchestrated via Kubernetes and monitored with Prometheus -- also in {CMK} without great effort -- the commercial editions offer the setup of a xref:dcd#[dynamic host configuration].
The data from the individual containers is forwarded as xref:glossar#piggyback[piggyback] data to {CMK}.

Now create a new connection using [.guihint]#Setup > Hosts > Hosts > Dynamic host management > Add connection#, select [.guihint]#Piggyback data# as the connector type, and use [.guihint]#Add new element# to define the conditions under which new hosts should be created dynamically.

Consider whether it is necessary for your environment to dynamically delete hosts again when no more data arrives at {CMK} via the piggyback mechanism.
Set the option [.guihint]#Delete vanished hosts# accordingly.


[#dcd_cadvisor]
=== Special feature in interactions with cAdvisor

Containers usually receive a new ID when they are restarted.
In {CMK} the metrics from the host with the old ID are not automatically transferred to the new ID.
In most cases, that would not make any sense.
In the case of containers, however, this can be very useful, as seen in the example above.

If containers are only restarted, you probably do not want to lose their history.
To achieve this, do not create the containers under their IDs, but instead under their names with the [.guihint]#Name - Use the name of the container# option in the xref:cadvisor[Prometheus rule].

In this way, with the [.guihint]#Delete vanished hosts# option in the dynamic host configuration you can still delete containers that no longer exist,
without having to fear that their history will also be lost.
Instead, this will be continued -- by the use of the identical container name -- even if it is actually a different container which uses the same name.
