// -*- coding: utf-8 -*-
// IGNORE %
include::global_attr.adoc[]
= Cluster-Services überwachen
:revdate: 2021-01-25
:title: Cluster-Services überwachen
:description: {CMK} hilft Ihnen dabei, für eine Gruppe vernetzter Hosts mit der gleichen Aufgabe ein Cluster einzurichten und die Cluster-Services für das Monitoring auszuwählen.

{related-start}
xref:hosts_setup#[Verwaltung der Hosts]
xref:agent_windows#[Windows überwachen]
{related-end}


[#intro]
== Einleitung

[#cluster]
=== Cluster, Knoten und Cluster-Services

Bei der Bereitstellung wichtiger und geschäftskritischer Services wie Datenbanken oder Websites für den elektronischen Handel (_E-commerce_) werden Sie sich kaum darauf verlassen, dass der Host, auf dem diese Services laufen, ein langes, stabiles und absturzfreies Leben führen wird.
Stattdessen werden Sie den Ausfall eines Hosts einkalkulieren und dafür sorgen, dass andere Hosts bereitstehen, um bei einem Ausfall die Services unmittelbar zu übernehmen (_failover_),
so dass sich der Ausfall nach außen gar nicht bemerkbar macht.

Eine Gruppe von vernetzten Hosts, die zusammenarbeiten, um die gleiche Aufgabe zu erledigen, wird als Rechnerverbund oder Computer-Cluster oder kürzer als Cluster bezeichnet.
Ein Cluster agiert nach außen als ein System und organisiert nach innen die Zusammenarbeit der Hosts, um die gemeinsame Aufgabe zu erfüllen.

Ein Cluster kann verschiedene Aufgaben übernehmen, zum Beispiel ein HPC-Cluster das Hochleistungsrechnen (_high-performance computing_),
das unter anderem dann eingesetzt wird, wenn Berechnungen viel mehr Speicher benötigen als auf einem Computer verfügbar ist.
//oder ein Programm mehrfach ausgeführt werden muss (normalerweise mit unterschiedlichen Eingabedaten).
Falls das Cluster die Aufgabe hat, für Hochverfügbarkeit (_high availability_) zu sorgen, wird es auch als HA-Cluster bezeichnet.
Um HA-Cluster geht es in diesem Artikel, d.h. wenn wir im Folgenden „Cluster“ schreiben, ist stets ein *HA-Cluster* gemeint.

Ein Cluster bietet einen oder mehrere Services nach außen an: die Cluster-Services, die manchmal auch als „geclusterte Services“ bezeichnet werden.
In einem Cluster werden die Hosts, aus denen es besteht, als Knoten (_nodes_) bezeichnet.
Zu einem bestimmten Zeitpunkt wird jeder Service von genau einem der Knoten bereitgestellt.
Fällt ein Knoten des Clusters aus, werden alle Services, die für die Aufgabe des Clusters essentiell sind, auf einen der verbleibenden Knoten verschoben.

Um ein Failover transparent zu machen, stellen einige Cluster eine eigene Cluster-IP-Adresse zur Verfügung, die manchmal auch als virtuelle IP-Adresse bezeichnet wird.
Die Cluster-IP-Adresse verweist stets auf den aktiven Knoten und steht stellvertretend für das gesamte Cluster.
Im Falle eines Failover geht die IP-Adresse auf einen anderen, bisher passiven Knoten über, der dann zum aktiven Knoten wird.
Dem Client, der mit dem Cluster kommuniziert, kann ein internes Failover egal sein:
Er verwendet unverändert die gleiche IP-Adresse und braucht nicht umzuschalten.

Andere Cluster haben keine Cluster-IP-Adresse.
Ein prominentes Beispiel sind Oracle-Datenbank-Cluster in vielen ihrer Varianten.
Ohne Cluster-IP-Adresse muss der Client eine Liste der IP-Adressen aller Knoten führen, die den Service bereitstellen könnten.
Fällt der aktive Knoten aus, muss der Client dies erkennen und auf denjenigen Knoten umschalten, der den Service nunmehr bereitstellt.


[#monitoring]
=== Das Monitoring eines Clusters

{CMK} ist einer der Clients, der mit dem Cluster kommuniziert.
In {CMK} können alle Knoten eines Clusters eingerichtet und überwacht werden
-- unabhängig davon, wie die Cluster-Software intern den Status der einzelnen Knoten überprüft und, falls notwendig, einen Failover durchführt.

Die meisten Checks, die {CMK} auf den einzelnen Knoten eines Clusters ausführt, befassen sich mit den physischen Eigenschaften der Knoten,
die unabhängig davon sind, ob der Host zu einem Cluster gehört oder nicht.
Beispiele dafür sind CPU-und Speichernutzung, lokale Festplatten, physische Netzwerkschnittstellen usw.
Für die Abbildung der Cluster-Funktion der Knoten in {CMK} ist es aber notwendig, diejenigen Services zu identifizieren, die die Aufgabe des Clusters definieren und gegebenenfalls auf einen anderen Knoten übertragen werden:
die Cluster-Services.

//Nehmen wir an, dass {CMK} die Verfügbarkeit eines bestimmten Cluster-Services prüfen will. Auf welchem Knoten soll es den Service suchen? Wenn das Cluster eine Cluster-IP-Adresse hat, kann {CMK} sich mit dieser verbinden und wird den aktiven Knoten erreichen, auf dem der Service läuft. Ohne eine Cluster-IP-Adresse wird es komplizierter, da {CMK} von allen Knoten des Clusters Daten abrufen muss, um denjenigen zu finden, auf dem der Service läuft und der damit der aktive Knoten ist.

{CMK} hilft Ihnen dabei, die Cluster-Services zu überwachen. Was Sie tun müssen, ist:

. Cluster erstellen
. Cluster-Services auswählen
. Service-Erkennung für alle beteiligten Hosts durchführen

Wie Sie dabei vorgehen, wird im nächsten Kapitel anhand der folgenden Beispielkonfiguration beschrieben:

[{image-border}]
image::cs_example_cluster.png[]

In {CMK} soll ein Windows Failover Cluster als HA-Cluster eingerichtet werden, das aus zwei Knoten mit installiertem Microsoft SQL (MS SQL) Server besteht.
Es handelt sich dabei um ein sogenanntes Aktiv/Passiv-Cluster, das heißt, nur auf einem, dem aktiven Knoten läuft eine Datenbankinstanz.
Der andere Knoten ist passiv und wird nur im Fall eines Failover aktiv, fährt die Datenbankinstanz hoch und ersetzt den ausgefallenen Knoten.
Die Daten der Datenbankinstanz werden nicht auf den Knoten selbst gespeichert, sondern auf einem gemeinsam genutzten Speichermedium,
z.B. einem Storage Area Network (SAN), an das beide Knoten angeschlossen sind.
Die Beispielkonfiguration besteht aus den folgenden Komponenten:

* `mssql-node01` ist der aktive Knoten mit laufender Datenbankinstanz.
* `mssql-node02` ist der passive Knoten.
* `mssql-cluster01` ist das Cluster, dem beide Knoten angehören.

Anders als in diesem Beispiel ist es auch möglich, dass derselbe Knoten in mehreren Clustern enthalten ist.
Im letzten Kapitel erfahren Sie anhand einer abgeänderten Beispielkonfiguration, wie Sie solche überlappenden Cluster konfigurieren.


[#setup]
== Cluster und Cluster-Services einrichten

[#create]
=== Cluster erstellen

In {CMK} werden die Knoten und das Cluster selbst als Hosts erstellt (Knoten-Hosts und Cluster-Hosts), wobei es für einen Cluster-Host einen speziellen Host-Typen gibt.

Vor der Einrichtung eines Cluster-Hosts gibt es folgendes zu beachten:

*  Der Cluster-Host ist ein virtueller Host, der mit Cluster-IP-Adresse konfiguriert werden soll, wenn diese existiert.
In unserem Beispiel gehen wir davon aus, dass der Name des Cluster-Hosts über DNS auflösbar ist.

* Cluster-Hosts können auf die gleiche Art und Weise konfiguriert werden wie „normale“ Hosts, zum Beispiel mit xref:glossar#host_tag[Host-Merkmalen] oder xref:glossar#host_group[Host-Gruppen.]

* Für alle beteiligten Hosts (damit sind stets der Cluster-Host und alle zugehörigen Knoten-Hosts gemeint), müssen die Datenquellen identisch konfiguriert werden,
d.h. insbesondere dürfen nicht einige per {CMK}-Agent und andere per
ifdef::onprem[]
SNMP konfiguriert sein.
endif::[]
ifdef::saas[]
xref:glossar#special_agent[Spezialagent] konfiguriert sein.
endif::[]
{CMK} stellt sicher, dass ein Cluster-Host nur dann erstellt werden kann, wenn diese Voraussetzung erfüllt ist.

ifdef::onprem[]
* In einem xref:distributed_monitoring#[verteilten Monitoring] müssen alle beteiligten Hosts derselben {CMK}-Instanz zugeordnet sein.
endif::[]

* Nicht alle Checks funktionieren in einer Cluster-Konfiguration.
Bei denjenigen Checks, die die Cluster-Unterstützung implementiert haben, können Sie dies in der Manual Page des Plugins nachlesen.
Zu den Manual Pages geht es im Menü [.guihint]#Setup > Services > Catalog of check plug-ins#.

In unserem Beispiel sind die beiden Knoten-Hosts `mssql-node01` und `mssql-node02` bereits als xref:glossar#host[Hosts] angelegt und eingerichtet.
Wie es so weit kommen konnte, können Sie im xref:agent_windows#[Artikel zur Überwachung von Windows-Servern] nachlesen
-- und dort im Kapitel zur Erweiterung des Standard Windows-Agenten mit Plugins, für unser Beispiel den link:https://checkmk.com/de/integrations?tags=mssql[MS SQL Server-Plugins.^]

//*Tipp:* Falls die Hosts in Ordner organisiert sind, vereinfacht es die Einrichtung (bei der Auswahl der Cluster-Services im nächsten Kapitel) wenn sich alle beteiligten Hosts im gleichen Ordner befinden.

Starten Sie die Erstellung des Clusters im Menü [.guihint]#Setup > Hosts > Hosts# und dann im Menü [.guihint]#Hosts > Add cluster#:

image::cs_create_cluster.png[]

Geben Sie als [.guihint]#Host name# `mssql-cluster01` ein und tragen Sie unter [.guihint]#Nodes# die beiden Knoten-Hosts ein.

//Im Kasten [.guihint]#Network Address# können Sie als [.guihint]#IPv4 Address# die Cluster-IP-Adresse (falls verfügbar) eintragen.
//Stellen Sie sicher, dass im Kasten [.guihint]#Data Sources# die gleichen Datenquellen ausgewählt sind wie bei den beiden Knoten-Hosts.

[TIP]
====
Falls Sie es mit einem Cluster ohne Cluster-IP-Adresse zu tun haben, müssen Sie einen nicht ganz komfortablen Umweg gehen:
Sie können im Kasten [.guihint]#Network address# für die [.guihint]#IP address family# den Eintrag [.guihint]#No IP# auswählen.
Um aber zu verhindern, dass der Host im Monitoring auf {DOWN} geht, müssen Sie für diesen das standardmäßig eingestellte „Host check command“ über die gleichnamige Regel ändern:
von [.guihint]#Smart PING# bzw. [.guihint]#PING# auf z.B. den Status eines der Services, die dem Cluster-Host im nächsten Abschnitt zugewiesen werden.
Mehr Informationen zu den Host-Regelsätzen finden Sie im xref:wato_rules#[Artikel über Regeln].
====

Schließen Sie die Erstellung mit [.guihint]#Save & view folder# ab und xref:wato#activate_changes[aktivieren Sie die Änderungen].


[#select_services]
=== Cluster-Services auswählen

{CMK} kann nicht wissen, welche der auf einem Knoten laufenden Services lokale und welche Cluster-Services sind:
Einige Dateisysteme können lokal sein, andere sind möglicherweise nur auf dem aktiven Knoten gemountet.
Ähnliches gilt für Prozesse:
//NTP (Network Time Protocol) Daemon
Während der Windows Dienst „Windows-Zeitgeber“ höchstwahrscheinlich auf allen Knoten läuft, wird eine bestimmte Datenbankinstanz nur auf dem aktiven Knoten verfügbar sein.

Statt {CMK} raten zu lassen, wählen Sie die Cluster-Services mit einer Regel aus.
Ohne Regel werden dem Cluster keine Services zugewiesen.
Für das Beispiel gehen wir davon aus, dass die Namen aller MS SQL Server Cluster-Services mit `MSSQL` beginnen und das Dateisystem des gemeinsam genutzten Speichermediums über das Laufwerk `D:` zugreifbar ist.

Starten Sie mit [.guihint]#Setup > Hosts > Hosts# und klicken Sie den Cluster-Namen an.
Auf der Seite [.guihint]#Properties of host# wählen Sie im Menü [.guihint]#Host > Clustered services#.
Sie landen auf der Seite des Regelsatzes [.guihint]#Clustered services#, auf der Sie eine neue Regel erstellen können.
Dann erhalten Sie die Seite [.guihint]#Add rule: Clustered services#:

image::cs_rule_cs.png[]

Unabhängig davon, ob und wie die Hosts in Ordner organisiert sind:
Achten Sie darauf, dass Sie alle Regeln für Cluster-Services so erstellen, dass sie für die Knoten-Hosts gelten, auf denen die Services laufen.
Für einen Cluster-Host ist eine solche Regel unwirksam.

Im Kasten [.guihint]#Conditions# wählen Sie unter [.guihint]#Folder# den Ordner aus, der die Knoten-Hosts enthält.
Aktivieren Sie [.guihint]#Explicit hosts# und tragen den aktiven Knoten-Host `mssql-node01` und den passiven Knoten-Host `mssql-node02` ein.
Dann aktivieren Sie [.guihint]#Services# und machen dort zwei Einträge:
`MSSQL` für alle MS SQL-Services, deren Namen mit `MSSQL` beginnen und `Filesystem D:` für das Laufwerk.
Die Eingaben werden als xref:regexes#[reguläre Ausdrücke] interpretiert.

Alle Services, die nicht als Cluster-Services definiert sind, werden von {CMK} als lokale Services behandelt.

Schließen Sie die Erstellung der Regel mit [.guihint]#Save# ab und aktivieren Sie die Änderungen.


[#discovery]
=== Service-Erkennung durchführen

Für alle beteiligten Hosts (Cluster- und Knoten-Hosts) muss zum Abschluss eine neue xref:glossar#service_discovery[Service-Erkennung] (_discovery_) durchgeführt werden,
damit alle neu definierten Cluster-Services zuerst bei den Knoten entfernt und dann beim Cluster hinzugefügt werden.

Unter [.guihint]#Setup > Hosts > Hosts# markieren Sie zuerst alle beteiligten Hosts und wählen dann im Menü [.guihint]#Hosts > On Selected hosts > Run bulk service discovery#.
Auf der Seite [.guihint]#Bulk discovery# sollte die erste Option [.guihint]#Add unmonitored services and new host labels# zum gewünschten Ergebnis führen.

Klicken Sie [.guihint]#Start#, um die xref:wato_services#bulk_discovery[Serviceerkennung für viele Hosts] zu beginnen.
Nach erfolgreichem Abschluss, erkennbar an der Meldung `Bulk discovery successful`, verlassen Sie die Seite und aktivieren die Änderungen.

Um herauszufinden, ob die Auswahl der Cluster-Services zum gewünschten Ergebnis geführt hat, können Sie sich alle Services auflisten, die nunmehr dem Cluster zugewiesen sind:
Unter [.guihint]#Setup > Hosts > Hosts# klicken Sie in der Host-Liste beim Eintrag des Cluster-Hosts auf das Symbol icon:icon_services[] zum Bearbeiten der Services.
Auf der folgenden Seite [.guihint]#Services of host# werden unter [.guihint]#Monitored services# alle Cluster-Services aufgelistet:

image::cs_cluster_monitored_services.png[]

Auf der anderen Seite, bei den Knoten-Hosts, fehlen nunmehr genau die zum Cluster verschobenen Services in der Liste der überwachten Services.
Am Knoten-Host finden Sie diese am Ende der Services-Liste im Abschnitt [.guihint]#Monitored clustered services (located on cluster host)#:

image::cs_node_monitored_services.png[]

[TIP]
====
Falls Sie xref:localchecks#[lokale Checks] in einem Cluster ausführen, in dem die Regel [.guihint]#Clustered services# zur Anwendung kommt: Mit dem Regelsatz [.guihint]#Local checks in {CMK} clusters# können Sie das Ergebnis beeinflussen, indem Sie zwischen [.guihint]#Worst state# und [.guihint]#Best state# auswählen.
====


[#auto_discovery]
=== Automatische Service-Erkennung

Wenn Sie die Service-Erkennung automatisch über den xref:wato_services#discovery_auto[Discovery Check] erledigen lassen, müssen Sie eine Besonderheit beachten.
Der [.guihint]#Discovery Check# kann verschwundene Services automatisch löschen.
Wandert ein geclusterter Service aber von einem Knoten zum anderen, könnte er fälschlicherweise als verschwunden registriert und dann gelöscht werden.
Verzichten Sie hingegen auf diese Option, würden wiederum tatsächlich verschwundene Services niemals gelöscht.


[#overlapping]
== Überlappende Cluster

Es ist möglich, dass mehrere Cluster einen oder auch mehrere Knoten gemeinsam nutzen.
Man spricht dann von überlappenden Clustern.
Bei überlappenden Clustern benötigen Sie eine spezielle Regel, um {CMK} mitzuteilen, welche Cluster-Services eines gemeinsam genutzten Knoten-Hosts welchem Cluster zugeordnet werden sollen.

Das prinzipielle Vorgehen beim Einrichten eines überlappenden Clusters werden wir im Folgenden vorstellen,
indem wir das Beispiel des MS SQL Server Clusters von einem Aktiv/Passiv- zu einem Aktiv/Aktiv-Cluster abwandeln:

[{image-border}]
image::cs_example_cluster_overlap.png[]

In dieser Konfiguration ist nicht nur MS SQL Server auf beiden Knoten-Hosts installiert,
sondern auf jedem der beiden Knoten läuft eine eigene Datenbankinstanz.
Beide Knoten greifen auf das gemeinsam genutzte Speichermedium zu, aber auf unterschiedlichen Laufwerken.
Dieses Beispiel realisiert ein zu 100{nbsp}% überlappendes Cluster, da die beiden Knoten beiden Clustern angehören.

Der Vorteil des Aktiv/Aktiv-Clusters besteht darin, dass die verfügbaren Ressourcen der beiden Knoten besser genutzt werden.
Im Fall eines Failovers wird die Aufgabe des ausgefallenen Knotens vom anderen Knoten übernommen, auf dem dann beide Datenbankinstanzen laufen.

Diese Beispielkonfiguration besteht somit aus den folgenden Komponenten:

* `mssql-node01` ist der erste aktive Knoten mit der laufenden Datenbankinstanz `MSSQL Instance1`.
* `mssql-node02` ist der zweite aktive Knoten mit der laufenden Datenbankinstanz `MSSQL Instance2`.
* `mssql-cluster01` und `mssql-cluster02` sind die beiden Cluster, denen beide Knoten angehören.

Den 1. Schritt zur Einrichtung des Aktiv/Passiv-Clusters müssen Sie für ein Aktiv/Aktiv-Cluster nur leicht abwandeln:
Sie erstellen, wie oben beschrieben, das erste Cluster `mssql-cluster01`.
Anschließend erstellen Sie das zweite Cluster `mssql-cluster02` mit denselben beiden Knoten-Hosts.

Im 2. Schritt nutzen Sie zur Auswahl der Cluster-Services statt des allgemeinen Regelsatzes [.guihint]#Clustered services# den speziell für überlappende Cluster geltenden Regelsatz [.guihint]#Clustered services for overlapping clusters#.
Damit definieren Sie in einer Regel die Cluster-Services, die bei den Knoten-Hosts entfernt und dem ausgewählten Cluster zugeschlagen werden.

Für unser Beispiel mit 100{nbsp}% Überlappung benötigen wir zwei dieser Regeln:
Die erste Regel definiert die Cluster-Services der ersten Datenbankinstanz, die standardmäßig auf dem ersten Knoten-Host laufen.
Da im Fall eines Failover diese Cluster-Services auf den zweiten Knoten-Host übertragen werden, weisen wir die Services beiden Knoten-Hosts zu.
Die zweite Regel tut dies analog für das zweite Cluster und die zweite Datenbankinstanz.

Starten wir mit der ersten Regel: Unter [.guihint]#Setup > General > Rule search# suchen Sie den Regelsatz [.guihint]#Clustered services for overlapping clusters# und klicken ihn an.
Erstellen Sie eine neue Regel.
Tragen Sie als [.guihint]#Assign services to the following cluster# das Cluster `mssql-cluster01` ein:

image::cs_rule_cs_overlapping.png[]

Im Kasten [.guihint]#Conditions# wählen Sie unter [.guihint]#Folder# wieder den Ordner aus, der die Knoten-Hosts enthält.
Aktivieren Sie [.guihint]#Explicit hosts# und tragen beide Knoten-Hosts ein.
Dann aktivieren Sie [.guihint]#Services# und machen dort zwei Einträge:
`MSSQL Instance1` für alle MS SQL-Services der ersten Datenbankinstanz und `Filesystem D:` für das Laufwerk:

image::cs_rule_cs_overlapping_conditions.png[]

Schließen Sie die Erstellung der ersten Regel mit [.guihint]#Save# ab.

Erstellen Sie anschließend gleich die zweite Regel, diesmal für das zweite Cluster `mssql-cluster02` und erneut für beide Knoten-Hosts.
Unter [.guihint]#Services# tragen Sie jetzt `MSSQL Instance2` ein für alle MS SQL-Services der zweiten Datenbankinstanz.
Der zweite Knoten-Host, auf dem die zweiten Datenbankinstanz standardmäßig läuft, greift auf sein Speichermedium unter einem anderen Laufwerk zu, im folgenden Beispiel über das `E:` Laufwerk:

image::cs_rule_cs_overlapping_conditions2.png[]

Sichern Sie auch diese Regel und aktivieren Sie dann die beiden Änderungen.

Führen Sie abschließend die Service-Erkennung als 3. und letzten Schritt genauso aus wie oben beschrieben: als [.guihint]#Bulk discovery# für alle beteiligten Hosts, d.h. die beiden Cluster-Hosts und die beiden Knoten-Hosts.

[TIP]
====
Falls mehrere Regeln einen Cluster-Service definieren, hat die spezifischere Regel [.guihint]#Clustered services for overlapping clusters# mit der expliziten Zuordnung zu einem bestimmten Cluster Vorrang vor der allgemeineren Regel [.guihint]#Clustered Services#.
Für die beiden in diesem Artikel vorgestellten Beispiele bedeutet das:
Durch die beiden zuletzt erstellten spezifischen Regeln würde die im ersten Beispiel erstellte allgemeine Regel nie zur Anwendung kommen.
====
