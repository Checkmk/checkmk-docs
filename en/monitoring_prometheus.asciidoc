include::global_attr.adoc[]
= Integrating Prometheus
:revdate: 2021-12-30
:title: Integrating Prometheus
:description: Prometheus can be integrated into {CMK} to monitor fast-moving container environments.

{related-start}
xref:check_plugins_catalog#[Catalog of Check Plug-ins]
xref:monitoring_kubernetes#[Monitoring Kubernetes]
{related-end}


== Introduction

=== Background and motivation

You may be wondering why you should even integrate Prometheus into {CMK} at all -- therefore we would like to make an important note at this point: Our integration of Prometheus is
aimed at all of our users who already use Prometheus. By integrating Prometheus
into {CMK}, we can close the gap that has opened up here so that you do not have to continuously check two monitoring systems.

This enables you to correlate the data from the two systems, accelerate any error
analysis and, at the same time, facilitate communication between {CMK}
and Prometheus users.


==== Finally, context again

As a most pleasant side benefit of this integration, it is likely that your
metrics from Prometheus automatically receive a meaningful context thanks to {CMK}.
For example, while Prometheus correctly shows you the amount of main memory used,
you do not have to take any extra manual steps in {CMK} to find out how much of
the total available memory this is. As banal as this example may be, it shows at
which points {CMK} makes monitoring easier -- even in some of the smallest details.


=== Exporter or PromQL

The integration of the most important exporters for Prometheus is provided via a
xref:datasource_programs#specialagents[special agent]. The following
exporters for Prometheus are available:

* link:https://checkmk.com/de/integrations?tags=cadvisor[cAdvisor (Container Advisor)^]
* link:https://github.com/prometheus/node_exporter/blob/master/README.md[node_exporter^]
* link:https://checkmk.com/check_mk-werks.php?werk_id=10859[kube-state-metrics^]

If we do not yet support the exporter you need, experienced
Prometheus users also have the option of sending self-defined queries to
Prometheus directly via {CMK}. This is performed using Prometheus’ own
xref:monitoring_prometheus#promQL[query language, PromQL].


== Setting up the integration

=== Creating a host

Since the concept of hosts in Prometheus simply doesn’t exist, first create a
place that gathers the desired metrics. This host forms the central point of
contact for the special agent, and this then later distributes the delivered data
to the correct hosts in {CMK}.
To do this, create a new host using the WATO module of the same name.

image::prometheus_hostname.png[]

If the specified host name does not correspond to an FQDN, enter the IP address
at which the Prometheus server can be reached.

Make all other settings for your environment and confirm your selection
with [.guihint]#Save & go to folder#.

=== Create a rule for the Prometheus datasource

Before {CMK} can find metrics from Prometheus, you must first set up the
special agent using the [.guihint]#Prometheus# rule set. You can find this in WATO
via [.guihint]#Setup > Agents > VM, Cloud, Container > Prometheus#.
There are several options for customizing the connection of your Prometheus server's web frontend, regardless of which exporter you want to use. Please note, only the port option has been available prior to version {v20}.

* [.guihint]#Prometheus connection option#: Specify here how the Prometheus server should be contacted. Especially if the server is only accessible via HTTPS, the options [.guihint]#Custom URL# or [.guihint]#Host name# are important and useful, since the certificate rarely includes the IP address.
* [.guihint]#Prometheus web port#: The port only needs to be changed if it differs from the Prometheus server default.
* [.guihint]#Basic authentication#: If a login is required, specify it here.
* [.guihint]#Protocol#: After installation the web frontend is provided via HTTP. If you have secured the access with HTTPS, change the protocol here accordingly.

You can see the default values in the following screenshot:

image::prometheus_connection_details.png[]


[#node_exporter]
==== Integration using Node Exporter

If, for example, you now want to integrate the hardware components of a
so-called _Scrape Target_ from Prometheus, use the so-called Node Exporter.
Select [.guihint]#Add new Scrape Target#, and from the dropdown menu that opens,
select [.guihint]#Node Exporter#:

image::prometheus_ruleset_exporter.png[]

Furthermore, here you can select which hardware or which operating system instances are to be queried by the Node Exporter. 
The services created in this way use the same check plug-ins as are used for other Linux hosts.
This means that their behavior is identical to those already familiar,
so without needing to adapt to something new you can quickly configure
thresholds, or work with graphs.

Normally the agent will try to
automatically assign the data to the hosts in {CMK}, and likewise also for the host in {CMK} that fetches the data.
However, if in the data from the Prometheus server neither the IP address, the FQDN, nor localhost are present, use the [.guihint]#Explicitly map Node Exporter host# option to specify which host from the Prometheus server data is to be assigned to the Prometheus host in {CMK}.


[#cadvisor]
==== Integration using cAdvisor

The cAdvisor exporter enables the monitoring of Docker environments, and returns
metrics on usage and performance data.

Via the selection menu [.guihint]#Entity level used to create {CMK} piggyback hosts#
you can determine whether and how the data from Prometheus should be collected in
an ready-aggregated form. You can choose from the following three options:

* [.guihint]#Both - Display the information for both pod and container levels#
* [.guihint]#Container - Display the information on container level#
* [.guihint]#Pod - Display the information for pod level#

Select either [.guihint]#Both# or [.guihint]#Container#, and also define the name under which
hosts are created for your containers. The following three options are available
for the naming. The option [.guihint]#Short# is the default:

* [.guihint]#Short - Use the first 12 characters of the docker container ID#
* [.guihint]#Long - Use the full docker container ID#
* [.guihint]#Name - Use the container’s name#

image::prometheus_cadvisor_names.png[]

Please note that your selection here affects the automatic creation and deletion
of hosts according to your
xref:monitoring_prometheus#dcd_cadvisor[dynamic host configuration].

To be able to limit the number of monitored objects, with [.guihint]#Monitor namespaces matching# you have the option of limiting the number of monitored objects.
All namespaces which are not covered by the regular expressions will accordingly be ignored.


[#kube_state_metrics]
==== Integration using kube-state-metrics

Within a Kubernetes cluster, deployments, nodes and pods can be queried with
the kube-state-metrics exporter. The mechanics here are largely the same as for
the xref:monitoring_prometheus#node_exporter[Node Exporter], or the
xref:monitoring_prometheus#cadvisor[cAdvisor] described above:
You select the metrics that you want to monitor.
Only by using the [.guihint]#Cluster name# field can you determine the name of the host
under which the data for a cluster should be displayed.

[#promQL]
==== Integration via PromQL

As already mentioned, with the help of the special agent it is also possible to
send requests to your Prometheus servers via PromQL. Enter the port via which Prometheus can
be reached, and select [.guihint]#Service creation using PromQL queries > Add new Service#.
Use the Service Name field to determine what the new service should be called in {CMK}.

Next, select [.guihint]#Add new PromQL query# and use the [.guihint]#Metric label# field to
specify the name of the metric to be imported into {CMK}.
Now enter your query in the field [.guihint]#PromQL query#. It is important that this
query may only return a *single* value.

image::prometheus_ruleset_promql.png[]

In this example, Prometheus is queried about the number of running and blocked
processes. In {CMK} these processes and the two metrics -- [.guihint]#Running# and
[.guihint]#Blocked# -- are then combined in a service called [.guihint]#Processes#.

From version {v20} you can also assign thresholds to these metrics.
To do this, activate [.guihint]#Metric levels# and then
choose between [.guihint]#Lower levels# or [.guihint]#Upper levels#.
Note that these always specify floating point numbers,
but of course they also refer to metrics that return integers only.


==== Assigning a rule to the Prometheus host

Assign this rule explicitly to the host you just created,
and confirm your entries with [.guihint]#Save#.

image::prometheus_ruleset_explicit_host.png[]


=== Service Discovery

Now that you have configured the special agent, it is time to run a
xref:wato_hosts#services[service discovery] on the Prometheus host.

image::prometheus_discovery.png[]


[#dcd]
== Dynamic host configuration

=== General configuration

Monitoring Kubernetes clusters is probably one of the most common tasks that
Prometheus performs. In order to ensure the integration of the sometimes very
short-lived containers, which are orchestrated by Kubernetes and monitored with
Prometheus -- also in {CMK} without great effort -- it is advisable to set up a
xref:dcd#[dynamic host configuration].
The data from the individual containers is forwarded as piggyback data to {CMK}.

Simply create a new connection using [.guihint]#WATO > Hosts > Dynamic config > New connection#,
select [.guihint]#Piggyback data# as the connector type, and use [.guihint]#Add new element# to
define the conditions under which new hosts should be created dynamically.

Please also note whether it is necessary for your environment to dynamically
delete hosts again when no more data arrives at {CMK} via the Piggyback mechanism.
Set the option [.guihint]#Delete vanished hosts# accordingly.


[#dcd_cadvisor]
=== Special feature in interactions with cAdvisor

Containers usually receive a new ID when they are restarted.
In {CMK} the metrics from the host with the old ID are not automatically
transferred to the new ID. In most cases, that wouldn’t make any sense.
In the case of containers, however, this can be very useful, as seen in the
example above. If a container is only restarted, you probably do not want to
lose its history. To achieve this, do not create the containers under their ID,
but instead under their name (option [.guihint]#Name - Use the container’s name# in the
xref:monitoring_prometheus#cadvisor[Prometheus rule]).
In this way, with the [.guihint]#Delete vanished hosts# option in the dynamic host
configuration you can still delete containers that no longer exist,
without having to fear that their history will also be lost.
Instead, this will be continued -- by the use of the identical container
name -- even if it is actually a different container which uses the same name.
