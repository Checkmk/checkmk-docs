// -*- coding: utf-8 -*-
include::global_attr.adoc[]
= Basic principles of monitoring with {CMK}
:revdate: 2021-07-07
:title: Basic principles of monitoring with {CMK} - Understanding {CMK} terms
:description: This article explains basic terms and concepts in {CMK}, such as host, service, user, contact group, notification, time period, scheduled downtime.

{related-start}
xref:hosts_setup#[Host administration]
xref:checkmk_getting_started#[Getting Started with Monitoring]
xref:wato_monitoringagents#[Monitoring agents]
{related-end}


[#states_events]
== States and events

Until now we have been concerned with the installation and implementation of {CMK}.
Now it is time to begin explaining the basic concepts and definitions of monitoring (with {CMK}).

It is important to understand the basic differences between _states_ and _events_ -- and namely for a very practical benefit.
Most classic IT monitoring systems revolve around events.
An event is something that occurs uniquely at a particular time.
A good example would be _error when accessing drive X_.
Typical sources of events are syslog messages, SNMP traps, the Windows Event Log, and log file entries.
Events are quasi-spontaneous (self-generating, asynchronous) occurrences.

In contrast a _state_ describes a sustained situation, e.g.  _drive X is online_.
In order to observe the state of something, the monitoring system must regularly poll it.
As the example shows, in monitoring it is often possible to choose to work with events or with states.

{CMK} can accommodate both states and events, but, where the choice is available, always prioritize _state-based monitoring_.
The reason for this lies in the numerous advantages of this method.
Some of these are:

* An error in the monitoring itself is detected immediately, because it is obviously noticeable when the status query no longer works.
The non-occurrence of a _message_, on the other hand, does not give any certainty whether the monitoring is still working.
* {CMK} itself can control the rate at which states are polled.
There is no risk of an _event storm_ in global error situations.
* Regular checking in a fixed time-frame enables the capturing of xref:glossar#metric[metrics] to record their time history.
* Even in chaotic situations - e.g. a power failure in a data center - one always has a reliable overall status.

One can well say that {CMK}'s state-based monitoring is the _norm_.
For processing events there is also the xref:glossar#ec[Event Console].
This is specialized for the correlation and evaluation of large numbers of events and is seamlessly-integrated into the {CMK} platform.


[#hosts_services]
== Hosts and services

[#hosts]
=== Hosts

Everything in {CMK} revolves around _hosts_ and _services_.
A host can be many things, e.g.:

* A server
* A network device (switch, router, load balancer)
* A measuring device with an IP connection (thermometer, hygrometer)
* Anything else with an IP address
* A cluster of several hosts
* A virtual machine
* A Docker container

In monitoring a host always has one of the following states:

[cols="10,10,~",options="header"]
|===
|State |Color |Meaning 
|{UP} |green |The host is accessible via the network (this generally means that it answers a PING.)
|{DOWN} |red |The host does not answer network inquiries, is not accessible.
|{UNREACH} |orange |The _path_ to the host is currently blocked to monitoring, because a router or switch in the path has failed.
|{PEND} |gray |The host has been newly-included in the monitoring, but never before been polled. Strictly-speaking this is not really a state.
|===

Alongside the state, a host has a number of other attributes that can be configured by the user, e.g.:

* A unique name
* An IP address
* Optional - an alias, that must not be unique
* Optional - one or more _parents_


[#parents]
=== Parents

For the monitoring to be able to determine the {UNREACH} state, it must know which path it can use to contact each individual host.
For this purpose, one or more so-called _parent hosts_ can be specified for each host.
For example, if a server A _as seen from monitoring_ can only be reached via a router B, then B is a parent host of A.
Only _direct_ parents are xref:hosts_structure#parents[configured in {CMK}].
This then results in a tree-like structure with the {CMK} site in the middle (shown here as icon:parent_map_root[alt="Icon for the {CMK} site."]):

image::monitoring_basics_parents.png[alt="Network topology with a configured parent.",width=43%,align=center]

Let's assume that in the network topology example shown above, the hosts _myhost_ and _myhost4_ are no longer reachable.
The failure of _myhost4_ can be explained by the fact that _myhost_ has failed.
Therefore, _myhost4_ is classified as {UNREACH} in the monitoring.
It is simply not possible to clearly determine why {CMK} can no longer reach _myhost4_, and the {DOWN} status would therefore be misleading in some circumstances.
Instead, the {UNREACH} has the effect of suppressing xref:notifications#[notifications] by default.
This is after all the most important task of the parents concept, i.e. the avoidance of mass notifications in the event that an entire dependent network segment becomes unreachable for the monitoring due to an interruption at a single point.

The prevention of false alarms is also served by xref:cmc_differences#no_on-demand_host_checks[feature] of the {CMK} Micro Core (CMC) used in the {CEE}.
Here, the state change for a failed host is held back for a few moments and proceeds only when it is _certain_ that the parent is still reachable.
If, on the other hand, the parent is definitely {DOWN}, the host will switch to {UNREACH} -- without a notification being triggered.

In some cases a host could have multiple parents, for example, when a router is running highly available in a cluster.
It is sufficient for {CMK} to be able to uniquely determine the status of the host when one of these parents is reachable.
Thus, when a host has _multiple_ parents and at least one of these parents is {UP}, the host is considered reachable in the monitoring.
In other words, in such a situation, the host will not automatically switch to the {UNREACH} state.


[#services]
=== Services

A host has a number of _services_.
A service can be anything - please don't confuse this with services in Windows.
A service is any part or aspect of the host that can be {OK}, or not OK.
Naturally the state can only be determined if the host is in {UP} state.

A service being monitored can have the following states:

[cols="10,10,~",options="header"]
|===
|State |Color |Meaning 
|{OK} |green |The service is fully in order. All values are in their allowed range.
|{WARN} |yellow |The service is functioning normally, but its parameters are outside their optimal range.
|{CRIT} |red |The service has failed.
|{UNKNOWN} |orange |The service's status cannot be correctly determined. The monitoring agent has delivered defective data or the element being monitored has disappeared.
|{PEND} |gray |The service has been newly-included and has so far not provided monitoring data.
|===

When determining which condition is 'worse', {CMK} utilizes the following sequence:

{OK} → {WARN} → {UNKNOWN} → {CRIT}


// TK: Translation: New section
////
[#checks]
=== Checks

Ein xref:glossar#check[Check] sorgt dafür, dass ein Host oder ein Service einen Zustand erhält.
Welche Zustände das sein können, ist im vorherigen Kapitel beschrieben.
Services und Checks hängen eng miteinander zusammen.
Daher werden sie manchmal, vielleicht sogar in diesem Handbuch, synonym verwendet, obwohl es doch verschiedene Dinge sind.

Im Setup können Sie sich anzeigen lassen, welches xref:glossar#check_plugin[Check-Plugin] für welchen Service zuständig ist.
Öffnen Sie mit [.guihint]#Setup > Hosts# die Eigenschaften eines Hosts und dann im Menü [.guihint]#Hosts > Service Configuration# die Liste der Services dieses Hosts.
Dann blenden Sie mit [.guihint]#Display > Show plugin names# eine neue Spalte ein, die Ihnen für jeden Service das zuständige Check-Plugin anzeigt:

.Die hier nicht relevante Tabellenspalte [.guihint]#Status detail# haben wir weggelassen
image::monitoring_basics_services_checks.png[]

Wie Sie am Beispiel des Check-Plugins [.guihint]#df# sehen, kann ein Check-Plugin für mehrere Services verantwortlich sein.
Übrigens sind in der eingeblendeten Spalte die Namen der Check-Plugins Links, die Sie zur Beschreibung des Check-Plugins führen.

Der Zusammenhang und die Abhängigkeit von Services und Checks sind auch im Monitoring zu sehen.
In der Service-Liste eines Hosts im Monitoring können Sie feststellen, dass im icon:icon_menu[] Aktionsmenü beim Eintrag [.guihint]#Reschedule# bei einigen Services ein gelber Pfeil steht (icon:icon_reload[]), bei den meisten anderen aber ein grauer Pfeil (icon:icon_reload_cmk[]).
Ein Service mit dem gelben Pfeil basiert auf einem xref:glossar#active_check[aktiven Check:]

image::monitoring_basics_check_mk_service.png[]

Solch ein aktiver Check wird von {CMK} direkt ausgeführt.
Services mit dem grauen Pfeil basieren auf passiven Checks, deren Daten von einem anderen Service, dem Service [.guihint]#Check_MK#, geholt werden.
Dies geschieht aus Gründen der Performance und stellt eine Besonderheit von {CMK} dar.
////


[#host_service_groups]
== Host and service groups

Hosts and services can be grouped for an overview.
In this way a host/service can be in more than one group.
These groups are purely optional and not required for the configuration.

Host groups can be useful when, alongside the folder structure in which the hosts are managed, an additional grouping is desired.
If for example you have built a folder structure according to geographic locations, then it could be useful to have a _Linux server_ host group e.g., that lists all Linux servers regardless of their geographic locations.


[#contacts]
== Contacts and contact groups

xref:glossar#contact[Contacts] and contact groups offer the possibility of assigning persons to hosts and services.
A contact correlates with a user name or web interface.
The correlation with hosts and services does not occur directly however, rather via contact groups.

Firstly, a contact (e.g. `harri`) is assigned to a contact group (e.g. `linux-admins`).
Then hosts - or as required, individual services - can be assigned to the contact group.
In this way users, and likewise hosts and services can be assigned to multiple contact groups.

These assignments are useful for a number of reasons:

. Who is permitted to _view_ something?
. Who is authorized to _configure and control_ which hosts and services?
. Who receives _notifications_ for which problems?

By the way - the user `cmkadmin`, who is automatically defined by the creation of a site, is always permitted to view all hosts and services even when they are not a contact.
This is determined through their role as administrator.


[#users_roles]
== Users and roles

Whereas the persons who are responsible or authorized for a particular host or service are defined through contacts and contact groups, 
their privileges are controlled via _roles_.
{CMK} is supplied with three roles from which further roles can be later derived.
Each role defines a series of rights which may be customized.
The standard roles have the following meanings:

[cols="5,10,~",options="header"]
|===
| |Role |Meaning 
|icon:icon_roles[] |`admin`  |May view all, has all privileges
|icon:icon_roles[] |`user` |May only view that for which he/she is a contact. May manage hosts in folders assigned to him/her. Is not permitted to make global settings.
|icon:icon_roles[] |`guest`  |May view all, but may not configure and may not influence monitoring
|===


== Problems, events and notifications

[#problems]
=== Handled and unhandled problems

{CMK} identifies every host that is not {UP}, and every service that is not {OK} as a _problem_.
A problem can have two states: _unhandled_ and _handled_.
The procedure is that a new problem is first treated as unhandled.
As soon as someone _acknowledges_ (confirms) the problem it is then flagged as handled.
It can also be said that unhandled problems are those which nobody has attended to.
The xref:user_interface#overview[Overview] in the sidebar therefore differentiates the two types of problems:

image::overview_more.png[alt="Overview snapin in Show more mode.",width=50%]

By the way: service problems from hosts that are currently not {UP} are not identified as problems.

Further details about acknowledgments can be found in it's xref:basics_ackn#[own article].


[#notifications]
=== Notifications

When a host's state changes, (e.g. from {OK} to {CRIT}), {CMK} registers a _monitoring event_.
These events may or may not generate a xref:glossar#notification[notification].
{CMK} is so designed that whenever a host or service has a problem, an email is sent to the object's contacts (please note that the `cmkadmin` user, 
by default, is _not_ a contact for any objects).
These can be customized very flexibly however.
Notifications also depend on a number of parameters.
It is simplest when we look at cases for which notifications are _not_ sent.
Notifications are suppressed ...

* ...when notifications have been globally-deactivated in the xref:user_interface#master_control[Master control]
* ...when notifications have been deactivated in the host/service
* ...when notifications have been deactivated for a particular status of the host/service (e.g. no notifications for {WARN})
* ...when the problem affects a service whose host is {DOWN} or {UNREACH}
* ...when the problem affects a host, whose parents are all {DOWN} or {UNREACH}
* ...when for the host/service a _notification period_ has been set that is not currently active
* ...when the host/service is currently xref:flapping[flapping]
* ...when the host/service is currently in a xref:downtimes[scheduled downtime]

If none of these prerequisites for suppressing notifications are satisfied, the monitoring core then creates a notification, 
which in a second step passes through a chain of rules.
In these rules you can define further exclusion criteria, and decide whom should be notified and in what form (email, SMS, etc.)

All particulars concerning notifications can be found in it's xref:notifications#[own article].


[#flapping]
=== Flapping hosts and services

It sometimes happens that a service continuously and quickly changes its condition.
In order to avoid continuous notifications, {CMK} switches such a service into the _flapping_ state.
This is illustrated with the icon:icon_flapping[] icon.
When a service enters a flapping state, a notification will be generated which informs the user of the change, and silences further notifications.
After a suitable time, if no further rapid changes are occurring, and a final (good or bad) status is evident, then the flapping status disappears and normal notifications resume.


[#downtimes]
=== Scheduled downtimes

If you perform maintenance work on a server, device or software, 
you will normally want to avoid potential problem notifications during this time.
In addition, you will probably want to advise your colleagues that problems appearing in monitoring during this time may be temporarily ignored.

For this purpose you can enter a condition of _scheduled downtimes_ on a host or service.
This can can be done directly before starting the work, or in advance.
Scheduled downtimes are illustrated by the icons:

[cols="5,~"]
|===
|icon:icon_downtime[alt="Icon for displaying the scheduled downtime for services."] |The service is in a scheduled downtime.
|icon:icon_derived_downtime[alt="Icon for displaying the scheduled downtime for hosts."] |The host is in a scheduled downtime.
Services whose host is in a downtime are also marked with this icon.
|===

While a host or service has a scheduled downtime:

* No notifications will be sent.
* Problems will not be shown in the [.guihint]#Overview# snapin.

Additionally, when you wish to later document statistics on the availability of hosts and services 
it is a good idea to include scheduled downtimes.
These can be factored into later availability evaluations.


// TK: Translation:
// TK: The following commented out text replaces the 3 chapters, that are still online and follow the commented out text:
// TK: Time periods. Check interval, check attempts and check period. Active and passive checks.
////
[#stale]
=== Veraltete Hosts und Services (Stale)

Wenn Sie eine Weile mit {CMK} gearbeitet haben, kann es passieren, dass in Ihren Host- und Service-Ansichten Spinnennetze angezeigt werden.
Für Services sieht das dann zum Beispiel so aus:

image::monitoring_basics_stale.png[alt="Ansicht zweier Services im Zustand stale."]

Diese Spinnennetze symbolisieren den Zustand veraltet (_stale_).
Sobald es einen veralteten Host oder Service gibt, wird das auch im Snapin xref:user_interface.html#overview[[.guihint]#Overview#] angezeigt, das um die Spalte [.guihint]#Stale# erweitert wird.

Doch was bedeutet der Zustand _stale_ genau?
Generell wird ein Host oder Service als _stale_ gekennzeichnet, wenn {CMK} über eine längere Zeitdauer keine aktuellen Informationen über dessen Zustand mehr bekommt:

* Ein Service wird _stale_:
Fällt ein Agent oder auch nur ein Agentenplugin - aus welchen Gründen auch immer - über längere Zeit aus, so liefert der Agent keine aktuellen Daten mehr für die Auswertung.
Services, deren Zustand von passiven Checks ermittelt wird, können nicht aktualisiert werden, da sie auf die Daten des Agenten angewiesen sind.  
Die Services verbleiben im jeweils letzten Status, werden aber nach Ablauf einer bestimmten Zeit als _stale_ markiert.

* Ein Host wird _stale_:
Liefert das [.guihint]#Host Check Command#, mit dem die Erreichbarkeit des Hosts überprüft wird, keine aktuelle Antwort, behält der Host den letzten ermittelten Zustand bei -- und wird dann aber als _stale_ gekennzeichnet.

Sie können den Zeitraum anpassen, ab wann Hosts und Services _stale_ werden.
Lesen Sie hierzu den Abschnitt über xref:checkinterval[Check-Intervalle.]


[#time_periods]
== Zeiträume (Time periods)

[{image-left}]
image::timeperiods.png[width=8%]

Wöchentlich wiederkehrende Zeiträume kommen an verschiedenen Stellen in der Konfiguration zum Einsatz.
Ein typischer Zeitraum könnte `work hours` heißen und die Zeiten von jeweils 8:00 bis 17:00 Uhr beinhalten, an allen Wochentagen außer Samstag und Sonntag.
Vordefiniert ist der Zeitraum `24X7`, welcher einfach alle Zeiten einschließt.
Zeiträume können auch Ausnahmen für bestimmte Kalendertage enthalten -- z.B. für die bayerischen Feiertage.

Einige wichtige Stellen, an denen Zeiträume zum Einsatz kommen, sind:

* Begrenzung der Zeiten, innerhalb derer benachrichtigt wird (Benachrichtigungszeitraum, _notification period_).
* Begrenzung der Zeiten, innerhalb derer Checks ausgeführt werden (xref:checkperiod[Check-Zeitraum], _check period_).
* Service-Zeiten für die Berechnung von Verfügbarkeiten (Service-Zeitraum, _service period_).
* Zeiten, innerhalb derer bestimmte Regeln in der xref:glossar#ec[Event Console] greifen.

Wie Sie Zeiträume einstellen können, lesen Sie im Artikel xref:timeperiods#[Zeitperioden (Time Periods).]


[#check_period_interval_attempt]
== Check-Zeiträume, Check-Intervalle und Check-Versuche


[#checkperiod]
=== Check-Zeiträume festlegen

Sie können die Zeiträume einschränken, in denen Checks ausgeführt werden.
Dazu dienen die Regelsätze [.guihint]#Check period for hosts#, [.guihint]#Check period for active services# und [.guihint]#Check period for passive Checkmk services.#
Mit diesen Regeln wählen Sie einen der verfügbaren xref:time_periods[Zeiträume] (_time periods_) als Check-Zeitraum (_check period_) aus.


[#checkinterval]
=== Check-Intervalle einstellen

Das Ausführen von Checks geschieht beim zustandsbasierten Monitoring in festen Intervallen.
{CMK} verwendet als Standard für Service-Checks eine Minute, für Host-Checks mit Smart Ping 6 Sekunden.

Mit Hilfe der Regelsätze [.guihint]#Normal check interval for service checks# und [.guihint]#Normal check interval for host checks# kann dies geändert werden:

* Auf einen längeren Wert, um CPU-Ressourcen auf dem {CMK}-Server und dem Zielsystem zu sparen.
* Auf einen kürzeren Wert, um schneller Benachrichtigungen zu bekommen und Messdaten in einer höheren Auflösung einzusammeln.

Kombinieren Sie nun einen Check-Zeitraum mit einem Check-Intervall, so können Sie dafür sorgen, dass ein aktiver Check genau einmal am Tag zu einer ganz bestimmten Zeit ausgeführt wird.
Setzen Sie z.B. das Check-Intervall auf 24 Stunden und den Check-Zeitraum auf 2:00 bis 2:01 Uhr an jedem Tag (also nur eine Minute pro Tag), dann wird {CMK} dafür sorgen, dass der Check auch wirklich in dieses kurze Zeitfenster verschoben wird.

Der Zustand der Services wird außerhalb des festgelegten Check-Zeitraums nicht mehr aktualisiert und diese werden dann mit dem Symbol icon:icon_stale[] als xref:stale[veraltet (_stale_)] gekennzeichnet.
Mit der globalen Einstellung [.guihint]#Staleness value to mark hosts / services stale# können Sie definieren, wie viel Zeit vergehen soll, bis ein Host/Service auf _stale_ geht.
Diese Einstellung finden Sie unter [.guihint]#Setup > General > Global settings > User interface:# 

image::monitoring_basics_staleness.png[alt="Festlegung des Faktors für Staleness."]

Dieser Faktor stellt das n-fache des Check-Intervalls dar.
Ist also Ihr Check-Intervall auf eine Minute (60 Sekunden) eingestellt, so geht ein Service, für den es keine neuen Check-Ergebnisse gibt, nach der 1,5-fachen Zeit, somit nach 90 Sekunden, auf _stale_.


[#max_check_attempts]
=== Check-Versuche anpassen

Mit Hilfe der Check-Versuche (_check attempts_) können Sie Benachrichtigungen bei sporadischen Fehlern vermeiden.
Sie machen einen Check damit quasi weniger sensibel.
Dazu können Sie die Regelsätze [.guihint]#Maximum number of check attempts for host# und [.guihint]#Maximum number of check attempts for service# nutzen.

Sind die Check-Versuche z.B. auf 3 eingestellt, und der entsprechende Service wird {CRIT}, dann wird zunächst noch keine Benachrichtigung ausgelöst.
Erst wenn auch die nächsten beiden Checks ein Resultat liefern, das nicht {OK} ist, steigt die Nummer des aktuellen Versuchs auf 3 und die Benachrichtigung wird versendet.

Ein Service, der sich in diesem Zwischenzustand befindet -- also nicht {OK} ist, aber die maximalen Anzahl der Check-Versuche noch nicht erreicht hat -- hat einen „weichen Zustand“ (_soft state_).
Nur ein „harter Zustand“ (_hard state_) löst eine Benachrichtigung aus.
////


== Time periods

[{image-left}]
image::timeperiods.png[width=8%]

Time periods define regular, weekly-recurring time periods that are used in various positions in the configuration.
A typical time period could be called `work hours` and could contain the time from 8:00 to 17:00 on all weekdays except Saturday and Sunday.
The period `24X7` simply includes all times and is predefined.
Time periods can also include exceptions for particular calendar days - e.g. Bavarian public holidays.

Some important situations which use time periods are:

* Limiting the time during which notifications will be made (notification period)
* Limiting the time during which checks are to be performed (check period)
* Service times for the evaluation of availability (service period)
* Times during which the Event Console applies defined rules

[#checkintervall]
== Check interval, check attempts and check period

The execution of checks occurs at fixed intervals in status-based monitoring.
{CMK} uses one minute as its standard. Every check is therefore performed
once per minute. This can be altered in the configuration:

* To a longer interval in order to save CPU resources on the server and target systems
* To a shorter interval in order to receive notifications more quickly and to collect performance data at a higher resolution.

Through defining a check period other than 24X7, the execution of _active_ checks
can be interrupted in specified time frames. The service's status will
no longer be updated, and will be flagged as _stale_, symbolized by
icon:icon_stale[].

In combination with a long check interval one can ensure that an active check is
performed once per day at a specified time. If you set an interval of e.g. 24
hours and the check period at 02:00 - 02:01 on every day (only one minute
per day), then {CMK} will ensure that the check really will be executed
in this short time frame.

[#max_check_attempts]
With the aid of _max check attempts_ you can
avoid notifications in the case of sporadic errors. In this way you are effectively
making a check less sensitive. If the check attempts are set to e.g. 3, and
the corresponding service becomes {CRIT}, then initially no notification will
be generated. If the next two checks produce a result other than {OK}, the
number of current attempts will increase to 3 and a notification will be sent.

A service that finds itself in this intermediate state - is thus not {OK}, but
has not yet reached its maximum number of attempts - has a _soft state._

== Active and passive checks

If you look at the {CMK} interface you can see that for some services
in the icon:icon_menu[] menu
a  yellow arrow (icon:icon_reload[]) is shown, but a gray arrow
(icon:icon_reload_cmk[]) for most others. The services with the yellow
arrow are _active checks_. These are executed by {CMK} directly.
Services with a gray arrow are those for which the check results are determined
by the active check [.guihint]#Check_MK#. These occur for performance reasons
and illustrate a special feature of {CMK}:

image::monitoring_basics_check_mk_service.png[]

In order that the target system (server, network device, etc.) is not
newly-contacted for every single service, once per interval {CMK} collects
all important data in one pass. From this data, in a single action it
calculates new results for all passive checks. This conserves CPU resources
on both systems and is an important factor that supports {CMK}'s high
performance and scalability.


== Overview of the most important host and service icons

The following table provides a short overview of the most important status icons appearing beside hosts and services:

[cols="5,~"]
|===
|icon:icon_downtime[alt="Icon for displaying the scheduled downtime for services."] |This service is in a scheduled downtime.
|icon:icon_derived_downtime[alt="Icon for displaying the scheduled downtime for hosts."] |This host is in a scheduled downtime.
Services whose host is in a downtime are also marked with this symbol.
|icon:icon_outofnot[] |This host/service is currently outside its notifications period.
|icon:icon_notif_man_disabled[] |Notifications for this host/service are currently disabled.
|icon:icon_disabled[] |Checks for this service are currently disabled.
|icon:icon_stale[] |This host/service has a stale status.
|icon:icon_flapping[] |This host/service has a flapping status.
|icon:icon_ack[] |This host/service has a acknowledged problem.
|icon:icon_comment[] |There is a comment for this host/service
|icon:icon_aggr[] |This host/service is a part of a BI aggregation.
|icon:icon_check_parameters[] |Here you can directly-access the settings for the check parameters.
|icon:icon_logwatch[] |Only for logwatch services: here you can access stored log files.
|icon:icon_pnp[] |Here you can access a time series graph of the measured values.
|icon:icon_inventory[] |This host/service has inventory data. A click on it shows the related view.
|icon:icon_crash[] |This check crashed. Click on it to view and submit a crash report.
|===
