// -*- coding: utf-8 -*-
include::global_attr.adoc[]
= The Event Console
:revdate: 2017-04-25
:title: The Event Console - Processing logs and SNMP traps
:description: Whether syslog, forwarded text logs or traps via SNMP - here you will learn how to process these events in the {CMK} Event Console.

{related-start}
link:monitoring_basics.html[Basic principles of monitoring with {CMK}]
link:wato_rules.html[Host and service parameters]
link:livestatus.html[Retrieving status data via Livestatus]
{related-end}

////
TK: Hints for translation handling
As this article is very long and probably take some time for being newly translated, it still contains at the beginning the old (outdated)English content, just to avoid that an empty article is presented to our readers during the translation time.
So, before you start, please delete first the old English text that follows (until line 2190) 
The new German text follows afterwards - as usual commented out.  
////


include::include_disclaimer_20gui.asciidoc[]

== Introduction

=== Events are not states

So far in this handbook it has always been a matter of the active monitoring of _States_.
Every monitored service will always have one of the states {OK}, {WARN}, {CRIT} or {UNKNOWN}.
Through regular polling the monitoring continuously updates its picture of the current situation.

A quite different type of monitoring is that of working with _Events_.
An example of an event is an ‘Exception’ that occurs in an application.
The application may possibly continue running correctly and still have the ‘OK’
state as before – but _something has happened_.

=== The Event Console

With its *Event Console* (EC) {CMK} has a fully-integrated system for
the monitoring of events from sources such as Syslog, SNMP Traps, Windows Event Logs,
Log Files and user's applications.
With this, not only are events simply used to generate states – they form their
own category, and from {CMK} Version {v14}i2] are even
included in the [.guihint]#Tactical Overview# display.

image::tactical_overview_events.png[width=280]

Internally, events are not processed by the monitoring core, but rather by their
own service – the Event Daemon (`mkeventd`).

The Event Console has an archive in which it can research past events.
However, this is no substitute for a real log archive.
The Event Console's task is to intelligently filter a _limited_ number
of _relevant_ messages from a large stream. It is optimised for simplicity,
robustness and throughput – not for the storage of large data volumes.

Here are a few facts concerning the EC:

* It can receive messages _directly_ per Syslog or SNMP. A configuration of the corresponding Linux system service is thus unnecessary.
* With the aid of the {CMK}-Agents it can also evaluate text-based log files and Windows Event Logs.
* It classifies messages according to a chain of user-defined rules.
* It can correlate, combine, count, annotate and transcribe messages, and also take their chronological contexts into account.
*  It can execute automated actions and send notifications over {CMK} xref:notifications#[Notifications].
*  It is fully integrated into {CMK}'s interface.
*  It is included with every current {CMK}-System and ready for immediate use.



=== Terms and definitions

The Event Console receives *Messages*. A message is a line of text with a sequence
of possible additional attributes – for example, a time stamp, a host name, etc.
If the message is relevant an *Event* with the same attributes will
be directly generated from it, but:

* An event will be created from a message only if an applicable rule exists.
* Rules can alter the text and other attributes of messages.
* Multiple messages can be combined into an event.
* Messages can xref:cancelling[cancel] current events.
* 'Artificial' events can be created if particular messages xref:expect[do not] come.

An event can process through several *Phases*:

[cols="17,~"]
|===

|*open* |The ‘normal’ state: something has occurred which needs attention from the operator.
|*acknowledged* |The problem has been acknowledged – this is analogue to host and service problems in status-based monitoring.
|*counting* |The required count of particular messages has not been reached – the situation is unproblematic. The event will thus not (yet) be reported to the operator.
|*delayed* |An error message has been received, but the Event Console is waiting on an OK-message being received within a defined time. The event will be reported to the operator after this time has expired.
|*closed* |The event has been closed by the operator, or automatically, and is now only in the archive.
|===


In addition, an event has a *State*. To be precise, here the state of the event
itself is not meant, rather it applies to the service or device that sent the message.
Analogous to status-based monitoring, an event will be classified as {OK}, {WARN},
{CRIT} or {UNKNOWN}.


[#setup]
== Setting up the Event Console

Setting up the Event Console is very simple. In fact no initial extra
configuration is required since from Version {v128}
of {CMK} the Event Console is always automatically active.

If you nevertheless want to receive Syslog messages or SNMP-Traps
over the network, you must activate these separately.
The reason for this is that both services respectively need to open a UDP-Port
with a specifically nominated port number. Since only one {CMK}-Instance
can do this per system, reception via the network is deactivated by default.
The port numbers are:

[cols=3]
|===
|Protocol |Port |Service 

|UDP |162 |SNMP Traps
|UDP |514 |Syslog
|TCP |514 |Syslog via TCP
|===


Syslog via TCP is only rarely used, but it has the advantage that the transmission
of messages is assured. With UDP it is never garanteed that packets really arrive.
And neither Syslog nor SNMP Traps provide acknowledgements or a similar protection
against lost messages. In order that you can use Syslog via TCP, the sending
system must of course be also capable of sending messages over this port.

In the {CMK}-Appliance you can activate the reception of Sylog/SNMP-Traps in
the instance configuration. Otherwise simply use `omd config`.
The required setting may be found under [.guihint]#Addons#:

image::ec_omd_config.png[width=300]

In `omd start` it can be seen which external interface your EC has open:

[{shell}]
----
{c-omd} omd start
Starting mkeventd (builtin: [hilite]#syslog-udp,snmptrap#)...OK
Starting Livestatus Proxy-Daemon...OK
Starting mknotifyd...OK
Starting rrdcached...OK
Starting Check_MK Micro Core...OK
Starting dedicated Apache for site stable...OK
Initializing Crontab...OK
----



== First steps with the Event Console

[#first_steps_rules]
=== Rules, rules, rules

At the beginning it was mentioned that the EC serves to ‘fish out’ _relevant_
messages and to issue notifications. It is unfortunately the case that most
messages – regardless of whether they come from Text files, the Windows Event Log
or the Syslog – are pretty unimportant. It is also not much help when messages
have already been classified by their source.

To illustrate: in Syslog and in the Windows Eventlog messages are classified
in a similar way to OK, WARN and CRIT. But what WARN and CRIT actually mean
has been subjectively decided by the respective programmer. And it is not
even clear whether the application producing the message is even important
on this computer. In short: there is no alternative but to define your own
configuration of which messages represent a problem for you, and which can
simply be discarded.

As usual in {CMK} the configuration is achieved using _rules_,
which for every incoming EC message will be processed according to the
‘first match’-principle. The first rule that is applicable to an incoming
message decides the messages's fate. If no rule is applicable the message
will simply be silently discarded.

Since over time and under the conditions a large number of rules can be built
in the EC, the rules are generally organised into _Packets_ there.
The processing takes place packet after packet, and from top to bottom within a packet.
For this reason the sequence of the packets is important.

=== Creating a simple rule

Not surprisingly, the EC's configuration is found in the
setup module [.guihint]#Events > Event Console#. This is delivered empty
 – i.e., it contains no rules. As previously mentioned,
incoming messages will simply be discarded and not logged. The module looks like this:

image::ec_wato_module.png[]

To start, first create a new rule packet with icon:icon_new[] [.guihint]#Add rule pack#:

image::ec_new_rule_pack.png[]

As always, the ID serves as an internal reference and cannot be changed later.
Once saved the first entry will be found in the list of your rule packets:

image::ec_rule_pack_list.png[]

Here, using icon:icon_ec_rules[] you can select this so far empty packet
and create a new rule with icon:icon_new[] [.guihint]#Add rule#.
Simply fill out the first submenu [.guihint]#Rule Properties#:

image::ec_first_rule.png[]

The only essentials here are a unique [.guihint]#Rule-ID# and a description. This ID will
later be found in the log files and it will be saved with the generated events.
It is also very useful to assign the IDs systematically. All other fields are optional.
This apples particularly for the conditions.

Important: The new rule is initially only for testing and for now is applied to
_every_ event. Therefore it is also important that it be later
deleted or deactivated! Otherwise the Event Console will be flooded with every
imaginable message of no earthly use and thus be fairly useless.

==== Activating the changes

As always in {CMK} the changes must first be activated before they can take
effect. This is not a disadvantage, since in this way you can decide precisely
when changes affecting multiple interrelated rules should actually go ‘live’.
You can also use the Rule Simulator in advance to test if everything works.

However, since the events are not processed by the monitoring core,
but rather by their own (`mkeventd`) process, the EC has its own
‘Activate Changes’ which is found directly in the WATO-Modul:

image::ec_activate_changes.png[]

Click on the Link [.guihint]#Pending changes# in the top right corner
and then [.guihint]#Activate on selected sites# to activate the changes.
The Event Console is so constructed that this action proceeds absolutely
_uninterruptedly_. The reception of incoming messages is at all times
assured – thus no messages can be lost.

Only administrators are permitted to activate changes in the EC.
This is controlled using the [.guihint]#Activate changes for event console# xref:wato_user#roles[Permission].

From Version {v14} the activation of changes for the Event Console
is bundled with other changes in WATO and is no longer processed separately.

==== Testing the new rule

To test, you can of course send messages through Syslog or SNMP.
You should also do this later. For a first test the EC's built-in [.guihint]#Event Simulator#
is however more practical:

image::ec_simulator.png[]

Here you have two possibilities: [.guihint]#Try out# evaluates, based on the simulated
message, which rules would match. If you find yourself on the highest level of
the EC's WATO module, the rules Packets will be so marked. Should be you be
within a rule packet the individual rules will be marked. Every packet,
or respectively rule, will be flagged with one of the following three symbols:

[cols=2]
|===

|icon:icon_rulematch[] |This rule is the first to assess the message, and consequently decides its fate.
|icon:icon_rulepmatch[] |This rule would apply, but the message has already been processed by a preceeding rule.
|icon:icon_rulenmatch[] |This rule does not apply. Very practical: When you hover the mouse cursor over the grey ball icon, a pop-up will explain why the rule does not apply.
|===


Clicking on [.guihint]#Generate event# works in almost the same way as [.guihint]#Try out#,
except that with this the message will *really be generated*.
Possible defined xref:actions[Actions] will actually be executed.
The event will in fact appear in the monitoring's list of open events.
The generated message's source text will be visible in the verification:

image::ec_event_generated.png[]

An event generated in this way appears in the Status-GUI in the [.guihint]#Event Console > Events#
view:

image::ec_one_open_event.png[]

==== Creating test messages manually

For a first real test over the network you can simply send a Syslog message from
another Linux computer. Since the protocol is so simple, a special program is not even
required, just use `netcat` or `nc` to simply send the data via UDP.
The UDP-Packet's content consists of a single line of text. When this conforms to
a particular structure the components will be cleanly dissected by the Event Console:

[{shell}]
----
{c-user} echo '<78>Dec 18 10:40:00 myserver123 MyApplication: It happened again.' | nc -w 0 -u 10.1.1.94 514
----

You can just send _anything_. The EC will nevertheless accept it and
simply evaluate it as a message text. Additional information, such as e.g.,
the application, the priority, etc., is of course absent.
To be on the safe side, the status {CRIT} will be assumed:

[{shell}]
----
{c-user} echo 'This is no syslog message' | nc -w 0 -u 10.1.1.94 514
----

Within the {CMK}-Instance on which the EC is running, there is a _named Pipe_
in which you can write the text messages locally using `echo`.
This is a very simple method for tethering a local application, and likewise a facility
for testing the processing of messages:

[{shell}]
----
{c-omd} echo 'Local application says hello' > tmp/run/mkeventd/events
----

Incidentally, here it is also possible to send using the Syslog format,
in order that all of the event's fields can be filled-in cleanly.


[#globalsettings]
=== Event Console global settings

The Event Console has its own global settings which are not found in those of other
modules, rather they are accessed via the link [.guihint]#Settings#
found in the EC-Module's main menu:

image::ec_settings.png[]

The functions of the individual settings can be learned as usual in the online help
icon:icon_help[], and in the respective section of this article.

Access to these settings is protected by the [.guihint]#Configuration of Event Console#
permission which by default is held by the `admin` role.


[#permissions]
=== Permissions

The Event Console also has its own xref:wato_user#roles[Roles and Permissions] section.
We will take a closer look at some of the permissions in the relevant parts
of this article.

image::ec_permissions.png[]


[#operating]
== The Event Console in the operations


=== Event views

Events generated by the Event Console are displayed similarly to hosts and services in
the Status Overview. This display is accessed via the [.guihint]#Event Console > Events# view.
This view can be customised in exactly the same way as with all of the other views.
Displayed events can be filtered, commands executed, etc. If you create new event
views, events and xref:archive[event history] are available as data sources. Detailed information
covering this can be found in the xref:views#[Views] article:

image::ec_open_events_hilites.png[]

Clicking on the Event's ID (here e.g., `27`) will open its details:

image::ec_event_details.png[]

As can be seen, an event has many data fields whose functions will be explained
one at a time in this article.
I would like to briefly touch on the most important fields here:

[cols="25,~"]
|===
|Field |Function 

|[.guihint]#State (severity of event)# |As mentioned in the introduction, every event is classified as {OK}, {WARN}, {CRIT} or {UNKNOWN}. Events with an {OK} status are rather uncommon, since the EC has really been conceived to only filter out _problems_. There are however situations in which an {OK}-Event can make sense.
|[.guihint]#Text/Message of the event# |The event's actual content: A text message.
|[.guihint]#Hostname# |The name of the host that sent the message. It is not essential that the host be one that is actively monitored by {CMK}. If a host with this name really exists in the monitoring, the EC automatically establishes a connection. In such a case the [.guihint]#Host alias#, [.guihint]#Host contacts# and [.guihint]#Host icons# fields are filled out and the host appears in the same style as in the active monitoring.
|[.guihint]#Rule-ID# |The ID of the rule which created this event. Clicking on the ID will directly open the rule's details. Incidentally, the ID will still be retained even if in the meantime the rule itself no longer exists.
|===


As mentioned at the beginning, from Version {v14}i2] of
{CMK} events will be displayed directly in the [.guihint]#Tactical Overview#:

image::tactical_overview_events.png[width=280]

Here three numbers can be seen:

* [.guihint]#Events# – All open and acknowledged events (corresponds to the [.guihint]#Event Console > Events# view).
* [.guihint]#Problems# – only those of which that have one of the {WARN} / {CRIT} / {UNKNOWN} states.
* [.guihint]#Unhandled# – only those of which that have not yet been acknowledged (more on this shortly).


[#commands]
=== Commands and workflow in events

Events will be displayed by a simple workflow analogue to those for hosts and services.
As usual, this is achieved via xref:commands#[commands] – accessed using the small
hammer icon:commands[] icon. With the icon:checkboxes[] checkboxes you can
also execute a command on multiple events simultaneously. As a special feature,
the often-used _‘Archive a single event’_ function is available directly via the
icon:icon_archive_event[] symbol.

For every command there is a xref:wato_user#roles[Permission] in the
[.guihint]#Event Console# section, with which you can control the commands permitted for each role.
For members of the `admin` and `user` roles all commands are activated by default.

image::ec_commands.png[]

The following commands are available:

==== Update & Acknowledge

Using the [.guihint]#Update# button, with a single action you can hang a comment on an event,
nominate a contact person and acknowledge the event.
The [.guihint]#Change contact# field is intentionally a free text. Here you can also enter
things such as telephone numbers. In particular, the field has no effect on the event's
visibility in the GUI – it is purely a comment field.

The [.guihint]#‘Set event to acknowledged’# checkbox leads to an event passing from the
[.guihint]#open# phase to [.guihint]#acknowledged#, and from then on it is considered as
[.guihint]#handled#. This is analogue to the xref:basics_ackn#[acknowledgement] of host
and service problems.

A later execution of the command without the checkbox being selected
_removes_ the acknowledgement.

==== Changing a state

The [.guihint]#Change state# button allows an event to be reclassified manually –
from {CRIT} to {WARN} for example.

==== Executing actions

With the [.guihint]#Custom Actions# you can allow the execution of freely-definable
xref:actions[actions] on events.
Initially only the [.guihint]#Send monitoring notification# action is available.
This sends a {CMK}-notification that will be processed in exactly the same way
as a notification from an actively-monitored service.
This passes through the xref:notifications#[notification rules] and, as appropriate,
generates emails, SMS or whatever has been configured.
More information concerning notifications through the EC will be explained xref:notifications[below].

==== Archiving is almost like deleting

The [.guihint]#Archive event# button finally deletes the event from the open events list.
Since all actions on events – including this deletion – will also be logged in the
xref:archive[Archive], all of this information can be accessed later at any time.
For this reason we don't speak of deletion, rather of archiving.

The archiving of individual events is also easily performed from the event list
by using the icon:icon_archive_event[] symbol.


[#visibility]
=== Visibility of Events

==== The problem of visibility

{CMK} uses the xref:wato_user#contact_groups[Contact groups] for the visibility of
hosts and services in the Status-GUI for normal users.
These are assigned to the hosts and services by WATO by rule or folder configuration.

In the Event Console the situation is so that an assignment of events to
contact groups does not exist at first – since in advance it is not actually known
which messages can even be received at all.
Not even the list of hosts is known, as the sockets for Syslog and SNMP are
accessible from everywhere. For this reason there are a couple of specifics
connected with the visibility in the Event Console:

==== All are permitted to see everything initially

When configuring the xref:wato_user#roles[user roles] the
[.guihint]#Event Console > See all events# permission is given at first.
This is active by default, so that *normal users are also permitted to see all events!*
This is conciously set like this so that if the configuration is faulty
important error messages don't inadvertently fall by the wayside.
The first step to a more precise control of the visibility is therefore the removal
of this permission from the `user` role.

[#hostmatching]
==== Assigning to hosts

So that the visibility of events is as consistent as possible with the rest
of the monitoring, the Event Console attempts as best it can to assign the
hosts from which it receives events to the hosts configured using WATO.
This sounds simple but the details are tricky, as sometimes the host name
information is absent in an event and only the IP-address is known.
In other cases the host name is coded differently to the version in WATO.

In practice, an assignment is processed as follows:

* If no host name has been identified in an event, its IP-Address will be used as the host name.
* The event's host name will then – _without case sensitivity_ – be compared with all host names, host aliases and IP-adresses of hosts in the monitoring.
* If such a host is found its contact contact groups will be adopted for the event and used for controlling the visibility.
* If the host is not *not* found, the contact groups – xref:contactgroups[if configured there] – will be adopted from the rule that generated the event.
* If groups have also not been assigned, the user will only be permitted to see the event if they have the [.guihint]#Event Console > See events not related to a known host# permission.

You can influence the assignment at one position:
If contact groups have been defined in the rule set *and* the host
could be assigned, the assignment normally has priority.

In Version {v128} you can change this with the
[.guihint]#Global settings > User interface > Precedence of contact groups of events#
setting:

image::ec_contact_group_precedence.png[]

From Version {v14}i2], instead of the value in the global option
a setting can be made directly in the rule.
This enables a configuration that varies from case to case:

image::ec_outcome_contact_groups.png[]


=== Troubleshooting

==== Which rule takes effect, and how often?

With the rule packets...

image::ec_pack_hits.png[]

&#8230; as well as with the individual rules...

image::ec_rule_hits.png[]

&#8230; in the [.guihint]#Hits# column you will find the counter for how many times the packet,
or respectively, the rule has been matched to a message.
On the one hand this can aid you in the elimination or repair of ineffective rules,
and on the other hand this count can also be interesting for rules that very often match.
For optimum EC performance these rules should be located at the beginning of
the rule chain if possible. In this way the number of rules that the EC must test
against every single message can be reduced.

The counter can be reset at any time using the [.guihint]#Event Console > Reset counters#
menu entry.

==== Debugging rule evaluation

In the preceeding chapter we saw how to test the evaluation of your rules using the simulator.
Similar information can be received for the runtimes for _all_
messages, if in the xref:globalsettings[Settings for the EC] you switch
the [.guihint]#Debug rule execution# to [.guihint]#on#.

The log file from the Event Console is found under `var/log/mkeventd.log`.
For every rule that is tested but does not take effect, here the reason can be found:

.var/log/mkeventd.log
[{file}]
----
[1481020022.001612] Processing message from ('10.40.21.11', 57123): '<22>Dec  6 11:27:02 myserver123 exim[1468]: Delivery complete, 4 message(s) remain.'
[1481020022.001664] Parsed message:
 application:    exim
 facility:       2
 host:           myserver123
 ipaddress:      10.40.21.11
 pid:            1468
 priority:       6
 text:           Delivery complete, 4 message(s) remain.
 time:           1481020022.0
[1481020022.001679] Trying rule test/myrule01...
[1481020022.001688]   Text:   Delivery complete, 4 message(s) remain.
[1481020022.001698]   Syslog: 2.6
[1481020022.001705]   Host:   myserver123
[1481020022.001725]   did not match because of wrong application 'exim' (need 'security')
[1481020022.001733] Trying rule test/myrule02n...
[1481020022.001739]   Text:   Delivery complete, 4 message(s) remain.
[1481020022.001746]   Syslog: 2.6
[1481020022.001751]   Host:   myserver123
[1481020022.001764]   did not match because of wrong text
----

It goes without saying that such intensive logging should be used with care
and only if necessary – in a more complex environment _a huge volume_ of data can
be generated!


[#rules]
== The whole power of the rules


=== The criteria

The most important part of an EC-rule is of course the _criteria_
[.guihint]#(Matching criteria)#. Only if a message satisfies all of the criteria
in the rule can the actions defined by the rule be executed and the
evaluation of the message completed.

image::ec_matching_criteria.png[]

==== General information on text comparison

For all criteria associated with text fields, the comparison text is
fundamentally treated as a xref:regexes#[regular expression].
The comparison here is always without _without case sensitivity_.
This latter is in fact an exception to what is usual in {CMK}.
This does make the rule's formulation more robust. Even host names in events
are not necessarily consistent in their format if these have not been centrally
configured, but rather configured on each host itself.
This exception therefore makes good sense.

Furthermore, an _Infix match_ can always be used – a verification of the
_containment_ of a search text.
A `pass:[.*]` at the beginning or end of the search text is thus not necessary.

There is however an *exception*:
If *no regular expression* is used to match with the host name, but instead a
*fixed host name*, this will be checked for an *exact* agreement and
*not* for containment. Attention: If the text includes a point '.' it will be
treated as a regular expression and an infix search is enacted. `myhost.de`
will then also match `notmyhostide` for example!

[#matchgroups]
==== Match groups

The concept of xref:regexes#matchgroups[Match groups] in the [.guihint]#Text to match#
field is very important and useful here. This refers to sections of text
that agree when matched with bracketed expressions in regular expressions.

Assume that you wish to monitor the following type of message in a database's log file:

[{file}]
----
Database instance WP41 has failed
----

`WP41` is of course variable and you certainly won't want to have to formulate
a separate rule for every possible instance. Thus in the regular expression you can
use `pass:[.*]` – which represents any character string:

`Database instance .* has failed`

If you now enclose the variable part in parentheses the Event
Console will *note* this exact value when matching for subsequent actions:

`Database instance *(pass:[.*])* has failed`

Following a successful match the first match group will now be set to the
`WP41` value (or whichever instance produced the error).

These match groups can be seen in the rule simulator when you hover the
mouse cursor over the green icons:

image::ec_match_groups_1.png[]

The groups can also be seen in the details for the generated event:

image::ec_match_groups_2.png[]

The match groups can also be used in, among others:

* The rewriting of events (xref:rewriting[Rewriting])
* The automatic cancelling of events (xref:cancelling[Cancelling])
* The counting of messages (xref:counting[Counting])

Here is another tip: There are situations in which a string needs to be grouped
within a regular expression, but through which *no* match group should be created.
This can be achieved by using a `?:` directly following the opening parenthesis.
Example: The `one (pass:[.*]) two (?:.*) three` expression creates only the
`123` match group when matching against `one 123 two 456 three`.

==== IP-Addresses

Here you can match a message to the sender's IPv4-Address.
Enter either an exact address or a network in the
X.X.X.X/Y format – thus, for example, `192.168.8.0/24`, in order to
match all of the addresses in the `192.168.8.`X network.

Please note that the match to the IP-Address only works if the systems being
monitored send directly to the Event Console. If the message is forwarded
by another intermediate syslog server, this intermediate's address will appear
as the sender's address in the message.


[#syslogfacility]
==== Syslog priority and facility

These two fields were originally defined by syslog as standardised information.
Internally, the 8-bit-field is composed of 5 bits for the Facility
(allowing 32 possibilities) and 3 bits for the Priority (8 possibilities).

The 32 predefined Facilities were conceived for something such as an application.
At the time the selection was not made very forward-looking. One of the Facilities,
for example, is `uucp` - a protocol that was rarely used even in
the '90s of the last milleneum.

The fact is however, that every message received via syslog carries one of
the Facilities. These can to some extent be freely assigned, in order to be
able to filter them in a targeted way later. This is quite useful.

The use of facility and priority also has a performance aspect.
When defining a rule that in any event only applies to messages that all have
the same facility or priority, these should be added to the rules as well.
The Event Console can then go around these rules very efficiently when a
message with divergent values is received. The more these filters are used
in rules, fewer rule comparisons will then be required.


==== Inverting matches

The [.guihint]#Negate match: Execute this rule if the upper conditions are not fulfilled# checkbox
causes the rule to take effect precisely when all of the conditions have _not _ been met.
This is actually only useful in conjunction with these two types of rule:

* [.guihint]#Do not peform any action, drop this message, stop processing#
* [.guihint]#Skip this rule pack, continue rule execution with next pack#

For more on the rule packs, see xref:rulepacks[later below].


[#outcome]
=== Outcomes of the rules

==== Rule type: interrupt or generate event

When a rule finds a match it determines what should be done with the message.
This is specified in the [.guihint]#Outcome & Action# menu:

image::ec_outcome.png[]

With [.guihint]#Rule type# the evaluation can be interrupted at this point – completely,
or only the current rule packet.
The first option should be used with a few targeted rules right at the
beginning in order to eliminate a great deal of useless “noise”. The other
options in this menu will then really only be needed to evaluate “normal” rules.


==== Defining the status

The rule decides the event's monitoring status with [.guihint]#State#.
This will generally be {WARN} or {CRIT}. Rules that generate {OK}-Events can be
interesting in exceptional cases in order to show certain events for
purely informational purposes. This can be interesting when used in combination
with an automatic xref:timing[Expiration] of the event.

Alongside the deciding of an explicit state there are two further more dynamic options.
The [.guihint]#(set by syslog)# setting adopts the classification from the syslog-priority.
This however only functions if the message has already been usably classified by the sender.
Messages that are received directly via syslog have one of eight priorities
predefined by RFC – these are indicated as follows:

[cols=4]
|===
|Priority |ID |State |Definition according to Syslog 

|emerg |0 |{CRIT} |The system is unusable
|alert |1 |{CRIT} |Immediate action is required
|crit |2 |{CRIT} |Critical state
|err |3 |{CRIT} |Error
|warning |4 |{WARN} |Warning
|notice |5 |{OK} |Normal, but important information
|info |6 |{OK} |Purely informational
|debug |7 |{OK} |Debugging message
|===


As well as syslog-messages, messages from the Windows eventlog, and messages from
text files that will have already been classified by the {CMK}-Logwatch plug-in on
the target system produce prepared states. SNMP-traps unfortunately don't produce these.

A completely different method is to classify the message yourself according to the
text. This is achieved using the [.guihint]#(set by message text)# setting:

image::ec_state_by_text.png[]

The match with the text configured at this point will be performed only
after [.guihint]#Text to match# and the other rules have been evaluated.
This must therefore not be repeated here.

If none of the configured patterns is found the event takes the {UNKNOWN} state.


==== Service level

The idea behind the Service Level is that within an operation,
every host and service has a specific importance.
With this a concrete service level agreement can then be formulated.
In {CMK} using xref:wato_rules#[Rules] you can assign such levels to your hosts
and services and then, for example, make the notifications or self-defined dashboards
dependent on these.

Since events are at first not necessarily correlated with hosts or Services,
the Event Console likewise allows you to assign a service level to an event
using rules. You can then later filter the event view according to this level.

As standard {CMK} has four predefined levels – 0 (None), 10 (Silver), 20 (Gold)
and 30 (Platinum). This selection can be altered as desired in the
[.guihint]#Global settings > Notifcations > Service levels#. Decisive here is the level's number,
since the levels will be sorted according to these numbers and checked against
the importance as well.

[#contactgroups]
==== Contact groups

The contact groups are also used for the xref:visibility[visibility], and from Version
{v14} also used for event
xref:notifications[Notification]. Here you can assign contact groups explicitly
by using Rule Events. Details for this can be found in the xref:visibility[section on operation].


==== Actions

Actions are very similar to the xref:alert_handlers#[alert handlers] for hosts and services.
Here when opening an event you can allow your own defined script to be executed.
All of the detailed information concerning actions can be found further below in its own
xref:actions[section].


==== Automatic deletion

The automatic deletion (= Archive), which you can specify with
[.guihint]#Delete event immediately after the actions#, ultimately makes an event no
longer visible in the operation. This is then useful if you simply want to
trigger automatic actions or when you wish to only archive particular events for
later research.


[#rewriting]
=== Automatic text rewriting

With [.guihint]#Rewriting#, an EC-rule can automatically rewrite text fields
in a message and add also comments to them. This is configured in its own menu:

image::ec_rewriting.png[]

With the rewriting, the xref:matchgroups[Matchgroups] described above are
particularly important. These allow you to insert elements of the original
message into the new text.
When making the substitutions you can access the groups as follows:

[cols="10,10"]
|===

|\1 |Will be replaced by the original message's _first_ matchgroup.
|\2 |Will be replaced by the original message's _second_ matchgroup (etc.).
|\0 |Will be replaced by the _complete_ original message
|===


In the above screenshot the new message text will be replaced by `Instance \1 has been shut down.`
This will of course only work if the [.guihint]#Text to match# in the *same* rule as the regular search expressions also contains at least one bracket term. An example of such a case would be:

image::ec_rewrite_match.png[]


A few more tips on rewriting:

* The rewriting is done _after_ the matching and _before_ actions are executed.
* Match, rewrite and actions always occur in the same rule. It is not possible to rewrite a message in order to then process it with a later rule.
* The `\1`, `\2`, etc., expressions can be used in all text fields, not just in [.guihint]#Message text#.


[#cancelling]
=== Automatic event cancelling

Some applications or devices are nice enough to send an appropriate OK-message
once they have recovered from a problem.
The EC can be configured so that in such a case the event generated by
the problem can be automatically closed. This is referred to as [.guihint]#Cancelling#.

The following image shows a rule in which messages with the
text `ABC Instance (pass:[.*]) failed` will be searched for.
The expression `(pass:[.*])` allows for any character string that
is captured by one member of a xref:matchgroups[matchgroup].
The expression `ABC Instance (pass:[.*]) recovered` which is configured in
the [.guihint]#Text to cancel event(s)# field in the same rule ensures an automatic
closure of events generated by this rule when an appropriate message is received:

image::ec_cancelling.png[]

The automatic cancellation then functions precisely when:

* a message is received that matches with the text [.guihint]#Text to cancel event(s)#
* The value captured in the `(pass:[.*])` group is _identical_ to the matchgroup that generated the original message
* both messages came from the same host
* it deals with the same application (Field [.guihint]#Application#)

The principle of the matchgroups is very important here. It would not really make
very much sense if the message `ABC Instance TEST recovered` cancelled an
event that was started by the message `ABC Instance PROD failed` would it?

Please don't make the mistake of using the placeholder `\1` in [.guihint]#Text to cancel events(s)#.
This does _not_ work! This placeholder only functions with xref:rewriting[rewriting].


==== Executing actions when cancelling

When cancelling an event you can also allow xref:automatic_actions[actions]
to execute automatically. For this reason it is important to know that when
cancelling an event a number of the event's data fields will be overwritten by values
from the OK-message before the actions are executed!
In these way the OK-message's data is fully available in the action script.
The event's state is also flagged as {OK} during this phase.
In this manner an action script can recognise a cancellation, and you can use the
same script for errors and OK-messages (e.g., when linking to a ticket system).

The following fields will be overwritten with data from an OK-message:

* The message text
* The timestamp
* The time of the last occurrence
* The Syslog-priority

All other fields remain unchanged – including the Event-ID.


==== Cancellation in combination with rewriting

If you work with rewriting and xref:cancelling[cancelling] in the same rule,
you should be cautious when rewriting the host name or the application.
When cancelling, the EC always checks whether the cancellation message corresponds
to the open event's host name and application. If these were to be overwritten however,
the cancellation would never work.

Before a cancellation the Event Console therefore simulates a rewriting of the
host name and application in order to compare the relevant texts.
This is probably also what you would expect.

This behaviour can be made use of if the [.guihint]#Application#-field in the error
message and the subsequent OK-message are not the same!
In such a case simply change the application field to a known fixed value,
which will result in the field being ignored during a cancellation.


==== Cancellation on the basis of the Syslog-priority

There are (unfortunately) situations in which the error's text and OK-message
are absolutely identical. In most such cases the real state is not coded in the text,
rather it is found in the Syslog-priority.

Additionally there is the [.guihint]#Syslog priority to cancel event# option.
Here, for example, enter the range `debug` ... `notice`.
All priorities within this range will normally be evaluated as an OK-state.
When using this option you should _nevertheless_ enter an appropriate text
in the [.guihint]#Text to cancel event(s)# field – otherwise the rule will match to all
OK-messages that apply to the same applications.


[#counting]
=== Counting messages

The ‘Counting of similar messages’ option can be found in the [.guihint]#Counting & Timing# submenu.
The idea is that some messages first become relevant when they
occur _too often_ or _too rarely_.


==== Too frequent messages

Checking for messages that occur too frequently is activated with the
[.guihint]#Count messages in defined interval# option:

image::ec_counting.png[]

In this menu you first enter a time span in “[.guihint]#Time period for counting#” and,
in “[.guihint]#Count until triggered#”, the number of messages to be reached in order
to trigger the opening of an event. As an example, in the above illustration it
can be seen that these values have been set to ten messages per hour.
Of course not just any message will be counted – only those specified for matching
in the rule.

It is also normally not useful to simply count all matching messages,
rather only those triggered by the same ‘cause‘.
In order to be able to control this, there are three check boxes with the title
“[.guihint]#Force separate events for different ...#”. These are predefined to count only
messages that match:

* Host
* Application
* xref:matchgroups[Match groups]

With these you can formulate rules like _“If from the same host,
the same application, and there the same instance more than 10 messages
per hour are received, then...”_. It is thereby also possible that multiple
events can be generated on the basis of the single rule.

If you select, for example, all three check boxes, the counting will be
conducted globally and altogether the rule can open only a single event!

Incidentally, it can actually be sensible to enter a message-count of ‘1’!
With this value you can effectively keep a grip on an ‘event storm’.
If for example, 100 messages of the same type arise within a short time,
by using this value only a single event will however be generated.
In the event's details you will then see:

* The time at which the first message appeared
* The time of the latest message
* The total count of messages accumulated to generate the event

Once the case has been ‘closed’, to specify when subsequent new messages
should open a new event can be decided via two check boxes.
Normally an acknowledgement of an event resets the counter so that subsequent
messages begin a new count. This can be deactivated in the
[.guihint]#‘Continue counting when event is acknowledged’# option.

The [.guihint]#Discontinue counting after time has elapsed# option
(From Version {v14}) ensures that for every comparison
period a separate event will always be opened. In the above example we
have defined a threshold of ten messages per hour. If this option has been
activated, for an already opened event a maximum of one hour's messages
can be accumulated in total. As soon as this time period has expired
(if a sufficient number of messages have been received) a new event will be opened.

If the count is set to ‘1’, for example, and the time interval to one day,
then this message type will open a maximum of one event per day.

The [.guihint]#Algorithm# setting is possibly surprising at first sight.
But seriously, what is actually meant by “ten messages per hour”?
WHICH hour is meant by this? Always full hours during the day?
It can happen that nine messages are received in the last minute of an hour,
and a further nine messages are received in the first minute of the following hour.
This means that eighteen messages will have been received in two minutes,
which is nonetheless fewer than ten per hour, so that the rule will not trigger an event.
That doesn't sound very useful...

Since there is no single solution for this {CMK} provides three different
definitions of what “ten messages per hour” should actually mean:

[cols="20,~"]
|===
|Algorithm |Function 

|[.guihint]#Interval# |The timing interval begins when the first applicable message is received. An event in the [.guihint]#counting# phase will be generated. Should the defined time period expire before the defined count limit is reached the event will be silently deleted. If however the count limit is reached before the time period has expired, then the event will be opened _immediately_ (triggering any possibly configured action).
|[.guihint]#Token Bucket# |This algorithm does not work with fixed time periods, rather it implements a procedure that is often used for Trafficshaping in networks.  Let us assume that ten messages per hour have been configured. That is an average of six per minute. If an applicable message is received, an event in the [.guihint]#counting# phase will be generated and its count set to ‘1’. Every subsequent message will increment this count by one. And every six minutes the counter will be _reduced_ by one – regardless of whether a message has been received or not. If with this procedure the counter returns to zero the event will be deleted.  The trigger will thus be pulled when the _average_ rate that messages are received persistently remains at over ten per hour.
|[.guihint]#Dynamic Token Bucket# |This is a variant of the [.guihint]#Token Bucket# algorithm in which the counter is reduced more slowly as it becomes lower. In the above example the counter with a count of 5 will be reduced every _twelve_ minutes rather than every six.  The result is that message rates that are only just above the permitted rate open an event (and thus create a notification) noticibly quicker.
|===


Which algorithm should you choose then?

* [.guihint]#Interval# is the easiest to understand and is simpler to replicate if you later want to precisely check statistics in the Syslog archive.
* [.guihint]#Token Bucket# is in comparison more intelligent and ‘softer’. It creates fewer anomalies on the margins of intervals.
* [.guihint]#Dynamic Token Bucket# makes a system more reactive and generates alarms more quickly.

Events that have not yet reached the defined count are latently present,
but not automatically visible to the operator.
They are in the [.guihint]#counting# phase. Such events can be made visible in
the Events View with the [.guihint]#Phase# filter:

image::ec_phase_filter_counting.png[width=320]

[#expect]
==== Too rare or absent messages

Just as with the receipt of a particular message, an *absence* can also
indicate a problem. It is possible that a particular job should issue at
least one message per day. Should this message not have been received however,
the job has probably not been run and thus an investigation is urgently needed.

You can configure something like this under
[.guihint]#Counting & Timing > Expect regular messages#:

image::ec_expect_messages.png[]

The same as for the counting submenu – in this case enter a time period within
which the message(s) are expected. Here however, a quite different,
much more suitable algorithm is used. Namely, the time period is always
targeted exactly at defined locations.
So, for example, the [.guihint]#Hour# interval always begins with zero minutes and seconds.
The following options are available:

[cols="25,~"]
|===
|Interval |Orientation 

|[.guihint]#10 seconds# |With a second count divisible by 10
|[.guihint]#minute# |To the full minute
|[.guihint]#5 minutes# |At 0:00, 0:05, 0:10, etc.
|[.guihint]#15 minutes# |At 0:00, 0:15, 0:30, 0:45, etc.
|[.guihint]#hour# |At the start of every full hour
|[.guihint]#day# |Exactly at 00:00, but only in a configurable time zone. With this you can also specify that a message is expected between 12:00 on one day and 12:00 on the following day. If, for example you yourself are located in the [.guihint]#UTC+1# time zone, enter [.guihint]#UTC-11# here.
|[.guihint]#two days# |To begin a full hour. Here you can enter a time zone offset from 0 to 47, which is referenced to 1970-01-01 00:00:00 UTC.
|[.guihint]#week# |At 00:00 on Thursday morning in the time zone UTC, plus the offset in hours. Thursday because the 1.1.1970 – the start of the ‘Epoch’ – was a Thursday.
|===


Why is this all so complicated? The intention is to minimise false alarms.
Is, for example one message per day expected from a backup? There are probably
slight variations in the backup's duration, so that the messages will not be
issued exactly twenty-four hours apart. If a message is expected, for example,
at around midnight plus/minus one or two hours, an interval of from 12:00 to 12:00
is much more robust than from 00:00 to 00:00. This will mean however that a
notification event will be not be generated until 12:00 if the message is absent.


==== Multiple occurrences of the same problem

The [.guihint]#Merge with open event# option is predefined so that if an expected message
repeatedly fails to appear the existing open event will be updated.
As an alternative this can be switched so that multiple new events will be opened.


[#timing]
=== Timing

Under [.guihint]#Counting & Timing# there are two options which can influence the
opening, or respectively the automatic closing of events.

The [.guihint]#Delay event creation# option is useful if you work with
automatic xref:cancelling[cancelling] of events. Set a delay of
5 minutes for example, so that an event generated by an error message
pauses for five minutes in the [.guihint]#delayed# status in the hope that
within this time an OK-message will be received which will automatically
close the event without a cancellation being needed, and thus the event
doesn't impinge on the operation. If this time limit expires the event
will be opened and a possible defined action will be executed:

image::ec_delay.png[width=530]

The [.guihint]#Limit event lifetime# option performs more or less an opposite function.
With this events can be be permitted to close automatically at the end of
a specified time. This is useful, for example, for informative events with
an {OK}-status which should be displayed, but which should not generate
activities in the operation. With the automatic ‘aging’ function you can
be spared the manual deletion of such messages:

image::ec_limit_livetime.png[width=530]

With an acknowledgement the aging will initially be stopped. This behaviour
can however be adjusted using the two check boxes.

[#rulepacks]
=== Rule packs

Rule packs are not just intended to lay things out more clearly, but rather to
considerably simplify the configuration of multiple similar rules and
simultaneously to accelerate evaluations.

Let us assume that you have a set of twenty rules, all of which revolve around
the Windows Event Log [.guihint]#Security#. All of these rules share the condition of
checking for a specific text in the application field (this logfile's name
will be coded as an [.guihint]#Application# in the messages by the EC).
In such a situation, proceed as follows:

. Create a rulepack for these rules.
. Create the 20 rules for [.guihint]#Security# in this pack, or move them here (the selection list [.guihint]#Move to pack...# on the right in the rule table).
. Remove the condition for the application from all of these rules.
. *As the first rule* in the pack, create a rule that allows the event to simply bypass the pack if the application is _not_ [.guihint]#Security#.

This exclusion rule is coded as follows:

* [.guihint]#Matching criteria > Match syslog application (tag)# to `Security`
* [.guihint]#Matching criteria > Invert matching# to [.guihint]#Negate match: Execute this rule if the upper conditions are not fulfilled.#
* [.guihint]#Outcome & action > Rule type# to [.guihint]#Skip this rulepack, continue rule execution with next rulepack#

Every message that does not come from the Security-Log will thus be ‘rejected’
by the first rule in this pack. This not only simplifies the subsequent rules
in this pack, it also accelerates the processing since in most cases checking
will no longer be necessary.


[#actions]
== Executing actions

=== Types of action

The Event Console provides three types of action – which can be executed either
manually, or when opening or xref:cancelling[cancelling] events:

* Executing your own self-coded shell scripts
* Sending your own self-defined emails
* Creation of {CMK}-xref:notifications[notifications]


=== Shell scripts and emails

Emails and scripts must first be defined in the Event
Console's settings. These can be found under [.guihint]#Actions (Emails & Scripts)#:

image::ec_add_action.png[]

==== Executing shell scripts

Create a new action with the [.guihint]#Add new action# button. The following example
shows how to create a simple shell script as an [.guihint]#Execute shell script# type
of action. In the script you can include placeholders such as
`$ID$` or `$HOST$` that will be replaced by real values from
the event before the script is executed. A complete list of the available
placeholders can be found in the icon:icon_help[] online help.

image::ec_define_action.png[]

Please be aware: under some circumstances it is possible that an attacker
could infiltrate commands into scripts using their own content in event texts.
This is particularly so for the `$TEXT$` field.
This is due to the placeholder being substituted *before* the
script is executed.

In future there will be an extension in {CMK} that as an alternative
will enable the values to be delivered via environment variables.
Since these are then evaluated by the shell itself, this risk can be avoided
with correct use. Thus, only utilise the existing variants with placeholders
if you can prevent attackers from infiltrating events.

The example script seen in the screenshot creates the `tmp/test.out` file
in the instance folder, and there writes a text with the concrete values for
the variables from each latest event:

[{file}]
----
cat << EOF > $OMD_ROOT/tmp/test.out
Something happened:

Event-ID: $ID$
Host: $HOST$
Application: $APPLICATION$
Message: $TEXT$
EOF
----

The scripts will be executed in the following environment:

* `/bin/bash` will be used as the interpreter
* The script runs as an instance user with the instance's home folder (e.g. `/omd/sites/mysite`)
* When the script is running processing of further events is paused!

Should your script include waiting times, with the help of
the Linux `at`-spooler you can allow it to run asynchronously.
For this, create the script in its own file `local/bin/myaction`,
and start it with the `at`-command – e.g.:

[{file}]
----
echo "$OMD_ROOT/local/bin/myaction '$HOST$' '$TEXT$' | at now
----


==== Sending emails

The action type [.guihint]#Send email# sends a simple text mail.
This can in fact be indirectly achieved via a script,
for example, by working with the `mail` command
in the command line. The first-mentioned option is however easier.
Please note that placeholders are also allowed in the [.guihint]#Recipient email address#
and [.guihint]#Subject# fields.

image::ec_define_action_email.png[]


[#notifications]
=== Notifications via {CMK}

Alongside the execution of scripts and the sending of (simple) emails,
the EC can perform a third type of action – the sending of notifications
over the {CMK}-xref:notifications#[notifications system].
EC-generated notifications are processed in the same way as the
host and service alarms from the active monitoring.
The advantages over the simple emails as described above are obvious:

* The notifications for active and event-based monitoring are configured together in a central location.
* Functions like xref:notifications#bulk[bulk notifications], HTML-emails and other useful things are available for use.
* User-defined notification rules, cancelling of notifications, and so on, function in the usual way.

The action type [.guihint]#Send monitoring notification# that performs this is
as standard always available for use, and needs no special configuration.

Since events by their very nature are somewhat differerent to ‘normal’
hosts or services, there are a few special characteristics with their
notifications which we will now take a closer look at:

==== Assigning to existing hosts

Events can originate from any host – regardless of whether they are
configured in an active monitoring or not.
The Syslog and SNMP-Port are, after all, open to all hosts in the network.
If a host sends information without having been asked,
the sender address reveals little about the sender itself,
and at first we don't know if we have a file of further information
concerning the host, thus any extended host attributes such as alias,
host attributes, contacts, etc. are at first 'unknown'.
In particular this means that _conditions_ in notification rules
do not not necessarily function as expected.

From Version {v14}, when handling notifications the EC
attempts to find a host in the active monitoring that matches the event.
For this it makes use of the same procedure as with the
xref:visibility[visibility of events]. If such a host can be found,
the following data will be extracted from it:

* The correct spelling of the host's name
* The host alias
* The primary IP-address as configured in {CMK}
* The host tags
* The WATO-folder
* The list of contacts and contact groups

It can thereby happen that the host name in the notification is not
identical to the  host name in the original message. The adaption of this to
conform with that of the active monitoring however simplifies the formulation
of standardised notification rules which contain conditions for the host names.

The assignment occurs in realtime with a livestatus query to the monitoring core
running in the same instance as the EC which received the message.
This can of course only function if the syslog messages, SNMP-Traps, etc.,
are only sent to the {CMK}-instance on which the host is actively monitored!

If the query fails, the host cannot be found, or you are using
{CMK} Version {v128}, substitute data will be assumed:

[cols="25,~"]
|===

|[.guihint]#Hostname# |The host name from the event
|[.guihint]#Hostalias# |The host name will be used as an alias
|[.guihint]#IP-Address# |The IP-Address field contains the host name – if this has the format of an IP-Address, and is otherwise empty. But Version {v14} will insert the message's original sender-address here.
|[.guihint]#Host attributes# |The host receives no tag. If you have tag groups with blank tags, the host there takes these attributes, otherwise it has no tag from the group. Please be aware of this if in notification rules you define conditions via tags.
|[.guihint]#WATO-Folder# |No folder. All conditions going to a specific folder are thus unrealisable – even if it concerns the main folder.
|[.guihint]#Contacts# |The list of the contacts is empty. From Version {v14} the fallback-contacts will be inserted here.
|===


If the host cannot be assigned in active monitoring,
this can of course lead to problems with notifications.
On the one hand it is possible that the conditions can no longer be applied,
on the other hand the contact selection will be affected.
In such cases you can customise the notification rules so that notifications
from the Event Console can be treated using their own targeted rule.
This has its own condition with which you can either make a positive match only
to EC-notifications, or conversely, exclude them:

image::ec_notification_condition.png[]


==== Remaining notification fields

So that notifications from the EC can be processed by the active monitoring's
notification system, the EC must conform to the system's schema.
In the process the typical data fields in a monitoring notification will be
filled as sensibly as possible. How the host's data is identified has just been
described. Further fields are:

[cols="25,~"]
|===

|[.guihint]#Alarmtyp# |EC-notifications are always treated as a _Service notification_
|[.guihint]#Service description# |Here the [.guihint]#Application# field from the event will be inserted. If this is empty, up to {CMK} Version {v128} ‘`Unset`’ will be inserted, from {CMK} Version {v14} ‘`Event Console`’ will be inserted.
|[.guihint]#Notification number# |This has a fixed value of `1`. No escalation is possible from this value. Even multiple sequential events of the same type appear independent from each other. The EC does not currently support recurring notifications in the case of an event not being acknowledged.
|[.guihint]#Date / Time# |With events, the xref:counting[counting], is the time of the _last_ occurrence of a message associated with an event.
|[.guihint]#Plug-in output# |The text content of an event
|[.guihint]#Service state# |The event's state, i.e., {OK}, {WARN}, {CRIT} or {UNKNOWN}
|[.guihint]#Previous state# |Since events have no previous states, normal events will always be {OK} here, and cancelled events will always receive a {CRIT} entry. This rule comes the closest to what one needs to have for a notification rule that is conditional on the exact change of state!
|===



==== Configuring contact groups manually

As described above, it may not be possible to determine the applicable
contacts for an event automatically. For such cases, from {CMK}
Version {v14}, you can specify the contact groups to be
used for the notification directly in the EC-rule.
Important – don't forget the [.guihint]#Use in notifications# check box:

image::ec_set_contact_groups.png[]

*Attention*: the similar setting in Version {v128} applies
exclusively to the visibility, NOT to the notification!


==== Global switch for notifications

In the [.guihint]#Master Control# element there is a central switch for notifications.
From {CMK} Version {v14} this also affects notifications
that are relayed from the EC:

image::master_control_notifications_off.png[width=280]

As with the host allocation, an enquiry to the switch from the EC requires a
livestatus access on the local monitoring core.
A successful request can be seen in the Event Console's logfile:

.var/log/mkeventd.log
[{file}]
----
[1482142567.147669] Notifications are currently disabled. Skipped notification for event 44
----


==== Hosts in scheduled downtimes

From Version {v14} the Event Console recognises hosts
that are currently in a xref:basics_downtimes#[scheduled downtime] and issues no
notification in such a situation. Its logfile entry will look like this:

.var/log/mkeventd.log
[{file}]
----
[1482144021.310723] Host myserver123 is currently in scheduled downtime. Skipping notification of event 433.
----

The prerequisite of course is successfully finding the host in the active monitoring.
If this is not successful it will be assumed that the host is _not_ in maintenance,
and the notification will definitely be generated.


==== Auxiliary macros

If you code your own xref:notifications#scripts[notification scripts],
especially with notifications from the Event Console, you have a number
of additional variables available that describe the original event
(access as usual with the `NOTIFY_` prefix):

[cols=2]
|===

|EC_ID |Event-ID
|EC_RULE_ID |ID of the rule that generated the event
|EC_PRIORITY |Syslog priority as a number from `0` (`emerg`) to `7` (`debug`).
|EC_FACILITY |Syslog facility – likewise a number. The range of values is from `0` (`kern`) to `32` (`snmptrap`).
|EC_PHASE |Phase of the event. Since only open events can trigger actions, `open` should be present here. A manual notification of an already acknowledged event, will `ack` will be seen here
|EC_COMMENT |The event's comment field
|EC_OWNER |The [.guihint]#Owner# field
|EC_CONTACT |The comment field with the contact information
|EC_PID |The process-ID of the process that sent the message (bei Syslog-Events)
|EC_MATCH_GROUPS |The match groups from matches in the rule
|EC_CONTACT_GROUPS |The optional contact groups defined manually in the rule
|===


[#automatic_actions]
=== Executing actions

We have already seen the manual execution of actions by the operator in
xref:commands[Commands]. More interesting is the automatic execution of
actions, which in EC-rules can be configured in the [.guihint]#Outcome & Action# submenu:

image::ec_rule_actions.png[]

Here you can choose one or more actions that will always be executed when,
according to the rule, an event will be _opened_ or xref:cancelling[cancelled].
With the latter, via the [.guihint]#Do Cancelling-Actions when# check box you can define
whether the action should be executed if the cancelled event is already in the [.guihint]#open# phase.
With the use of xref:counting[counting] or xref:timing[delay] it can occur that events
are cancelled which were in a ‘wait’ status and not yet visible to the user.

The execution of actions will be logged in the `var/log/mkevent.log`
logfile:

.var/log/mkeventd.log
[{file}]
----
[1481120419.712534] Executing command: ACTION;1;cmkadmin;test
[1481120419.718173]   Exitcode: 0
----

These will also be noted in the event archive.

[#snmp]
== SNMP-Traps

=== Setting up the reception of SNMP-Traps

Since the Event Console has its own built-in SNMP-Engine, setting up the reception
of SNMP-Traps is very simple. No `snmptrapd` from the operating system is needed!
Should you already have one running, please stop it.

As described in the section on xref:setup[setting up] the Event Console,
now activate the trap receiver in this instance with `omd config`:

image::ec_config_traps.png[width=300]

Because the UDP-Port for the traps can only be used by one process on a server,
it may only be setup for a single {CMK}-instance per computer.
When starting the instance you can control whether the trap receiver is active:

[{shell}]
----
{c-omd} omd start
Starting mkeventd (builtin: [hilite]#snmptrap#)...OK
Starting Livestatus Proxy-Daemon...OK
Starting mknotifyd...OK
Starting rrdcached...OK
Starting Check_MK Micro Core...OK
Starting dedicated Apache for site mysite...OK
Initializing Crontab...OK
----

For SNMP-Traps to function, the sender and receiver must agree in
specific [.guihint]#Credentials#. In the cases of SNMP Version 1 and 2c it is a
simple password, referred to here as ‘Community’. With Version 3 a few
more details are required. These credentials are configured in the Event Console's
settings under [.guihint]#Credentials for processing SNMP traps#.
Various different credentials can be set up with the [.guihint]#Add new element# button
which are then available to the devices for alternate uses:

image::ec_trap_credentials.png[]

By far the most time-consuming part is of course the entering of the target
addresses for the traps on all of the target devices to be monitored,
as well as to configure the credentials there.

*Tip*: Up until {CMK} Version {v128} traps with the
`public` community were always automatically accepted, regardless of any
further configured credentials. From {v14} this is no longer
the case – here only explicitly-configured credentials are permitted.

=== Testing

Unfortunately, few devices offer effective testing capabilities.
At least you can test the reception of traps by the Event Console quite simply
by sending a test trap – ideally from another Linux system.
This is done with the `snmptrap` command.
The following example sends a trap to `192.168.178.11`. Your chosen
host name is entered after `.1.3.6.1` and it must be resolvable
or entered as an IP-Address (here `192.168.178.30`):

[{shell}]
----
{c-user} snmptrap -v 1 -c public 192.168.178.11 .1.3.6.1 192.168.178.30 6 17 '' .1.3.6.1 s "Just kidding"
----

If the [.guihint]#Log level# in the settings has been set to [.guihint]#Verbose logging#,
the reception and evaluation of the traps will be visible in the EC's logfile:

.var/log/mkeventd.log
[{file}]
----
[1482387549.481439] Trap received from 192.168.178.30:56772. Checking for acceptance now.
[1482387549.485096] Trap accepted from 192.168.178.30 (ContextEngineId "0x80004fb8054b6c617070666973636816893b00", ContextName "")
[1482387549.485136] 1.3.6.1.2.1.1.3.0                        = 329887
[1482387549.485146] 1.3.6.1.6.3.1.1.4.1.0                    = 1.3.6.1.0.17
[1482387549.485186] 1.3.6.1.6.3.18.1.3.0                     = 192.168.178.30
[1482387549.485219] 1.3.6.1.6.3.18.1.4.0                     =
[1482387549.485238] 1.3.6.1.6.3.1.1.4.3.0                    = 1.3.6.1
[1482387549.485258] 1.3.6.1                                  = Just kidding
----

If the credentials are false only a single line will be displayed:

.var/log/mkeventd.log
[{file}]
----
[1482387556.477364] Trap received from 192.168.178.30:56772. Checking for acceptance now.
----

An event generated by such a trap will look like this:

image::ec_trap_event.png[]

=== From numbers come texts, but also: translating traps

SNMP is a binary protocol and it is very economical with its textual descriptions
of messages. Which type of traps are involved is communicated internally by
a sequence of numbers in so-called OIDs. These are shown as strings of numbers
separated by periods (e.g. `1.3.6.1.6.3.18.1.3.0`).

With the help of so-called MIB-files (Management Information Base) the
Event Console can translate these number sequences into texts. So for example,
from `1.3.6.1.6.3.18.1.3.0`, the text `SNMPv2-MIB::sysUpTime.0`
will be derived.

The translation of the traps is activated in the Event Console's settings:

image::ec_translate_traps.png[]

The above test trap now generates a somewhat different event:

image::ec_trap_event_translated.png[]

If the [.guihint]#Add OID descriptions# option has been activated, the result will be
significantly more comprehensive – and more complicated.
Is does however help to better understand exactly what a trap means:

image::ec_trap_event_translated2.png[]

=== Uploading your own MIBs

Unfortunately the advantages of Open Source for the authoring of MIB-files haven't
become common knowledge yet, and thus at the {CMK} project we are regrettably
not in the position of being able to provide vendor-specific MIB-files.
Only a small collection of free basic-MIBs is preinstalled to handle,
e.g., a translation of `sysUpTime`.

To upload your own MIB files, switch to the module 
[.guihint]#SNMP MIBs for trap translation# and then use the link
icon:icon_new[] [.guihint]#Add one or multiple MIBs# to select one or multiple MIB files for inclusion.

image::ec_mibs_for_translation.jpg[]

Tips for MIBs:

* The uploaded files are stored in `local/share/snmp/mibs`. You can also store them there manually if the method using the GUI is too involved for you.
* Instead of individual files, you can upload ZIP-archives with collected MIBs all in one go.
* MIBs have dependencies among themselves. Missing MIBs will be reported by {CMK}.
* The uploaded MIBs will also be used on the `cmk --snmptranslate` command line.


[#logwatch]
== Monitoring log files

The {CMK}-Agent is able to evaluate log files using the [.guihint]#Logwatch#-plug-in.
First of all, this plug-in provides its own monitoring of log files
(independently from the Event Console), which includes a small GUI integrated in
{CMK} for viewing and acknowledging of found messages.
There is also the possibility of forwarding messages found by the plug-in
to the Event Console on a one-to-one basis.

Log file monitoring is fully integrated in the Windows agent –
in the form of a plug-in for evaluating text files, and another for the
Windows-Eventlogs. For Linux and Unix the `mk_logwatch` plug-in written
in Python is available. All three can be installed and/or configured using the
xref:wato_monitoringagents#bakery[Agent Bakery]. Use the following rule sets for these:

* [.guihint]#Text logfiles (Linux)#
* [.guihint]#Text logfiles (Windows)#
* [.guihint]#Finetune Windows Eventlog monitoring#

The precise configuration of the logwatch plug-in is not the subject of this article.
It is nonetheless still important that in the logwatch plug-in itself you prepare
the best possible prefiltering of the messages, and not simply send the complete
contents of a text file to the Event Console.

Please don't confuse this with the _subsequent_ reclassification via
the [.guihint]#Logwatch patterns# rule set. This can only change the status of messages
that have already been sent by agents. If you have already set up these patterns
however, and simply wish to switch from logwatch to the Event Console you can
still retain the patterns. Additionally, included in the forwarding there is the
[.guihint]#Reclassify messages before forwarding them to the EC# option.
In this scenario all messages pass through alltogether *three* rule chains:
on the agents, through the reclassification, and in the Event Console!

Now change the logwatch over so that the messages found by the plug-ins
are no longer monitored by the normal Logwatch-Check, rather they are
forwarded one-to-one to the Event Console for processing. This forwarding
service is performed by the [.guihint]#Parameters for discovered services > Applications, Services & Processes > Logwatch Event Console Forwarding#
rule set:

image::ec_logwatch_forwarding.png[]

A few helpful tips concerning forwarding:

If you have a distributed environment in which not every instance runs its own
Event Console (first possible from Version {v14}),
the remote instances must redirect the messages to the central console via syslog.
UDP is the default for this procedure. This however is not a secure protocol.
It is better to use syslog via TCP, which must of course be activated in the
processing centre (`omd config`).

When forwarding specify any [.guihint]#Syslog facility#. With the help of this you can
easily recognise the forwarded messages in the Event Console.
`local0` to `local7` are well suited for this.

With [.guihint]#List of expected logfiles# you can monitor the list of found logfiles,
and will be warned when particular expected files cannot be found.

Important: Just saving the rules achieves nothing. This rule only becomes active
through a service dicovery. Not until this has been executed will the existing
logwatch services be removed, and replaced in each host by a newly-created
_single_ new service with the name [.guihint]#Log Forwarding#.

image::ec_log_forwarding_check.png[]

This check will also display possible problems with forwarding to the
Event Console in the future.

== Conforming host names on receipt

The host names used by your devices in messages are unfortunately not always
consistent. As we have already seen, when sending notifications {CMK} attempts
as far as possible to automatically assign the host names from events in
active monitoring when assigning the event's checks, and when displaying the
events in the operation. At the same time upper and lower case use will be
standardised, and the alias as well as the IP-address will be tested as host names.

If that is not sufficient, you can already rewrite host names directly on receipt
of messages with the [.guihint]#Hostname translation for incoming messages# EC-setting.
There are numerous possibilities for this:

image::ec_hostname_translation.png[]

The most flexible method is to use xref:regexes#[regular expressions], which
allow quasi-intelligent ‘find and replace’ actions in the host names.
In cases where that won't do you can also provide a table of individual names
and their corresponding new versions.

*Important*: The name conversion is performed *before* processing the
rule conditions, and thus long before a possible rewriting of the host names
through a rule action [.guihint]#Rewrite hostname#.


== Viewing event states in active monitoring

When you also wish to see which hosts in the active monitoring currently have
open problem events, in each host you can add an active check which summarises
the current event states.
For a host currently without open events, it will look like this:

image::ec_events_check_none.png[]

If only events with an {OK} state are present, the check will show the
number of events, but remain green:

image::ec_events_check_ok.png[]

Here is a situation with open events in a {CRIT} state:

image::ec_events_check_crit.png[]

This active check is generated using a rule in the
[.guihint]#Host & Service Parameters > Event Console > Check event state in Event Console#
rule set.
When using this rule you can also specify whether already-acknowledged events should,
or should not be added to the state:

image::ec_events_check.png[]

With the [.guihint]#Application (regular expression)# option you can restrict the check
to events that have a specific text in the application field. In this case it can also
make sense to have more than one events check on a host, and to separate the checks
according to application. So that these services are distinguishable by name,
you will additionally need the [.guihint]#Item (used in service description)# option,
which will insert your predefined text into the service's name.

If your Event Console is not running on the same {CMK}-instance that is monitoring
the host, you will need a remote access via TCP through [.guihint]#Access to Event Console#:

image::ec_check_remote.png[]

For this to function the Event Console must permit an access via TCP.
This can be configured in the settings of the EC that will be accessed:

image::ec_remote_access.png[]


[#archive]
== The Archive

=== Fundamentals of operation

The Event Console maintains a protocol of the changes that an event goes through.
This can be found via two precedures:

* In the global overview [.guihint]#Event Console > Recent event history#.
* In the details of an event using the [.guihint]#History of Event# button.

In the global overview a filter that only shows the events for the last
24 hours is used. As usual the filter can be customised.

The following image shows the history of event 5976, which experienced a
total of four changes. The event was initially generated (`NEW`),
then its state was manually changed from {OK} to {CRIT} (`CHANGESTATE`),
the event was then acknowledged and a comment was added (`UPDATE`),
and finally the event was archived/deleted (`DELETE`):

image::ec_history.png[]

The following types of entry are found in the archive:

[cols="20,~"]
|===
|Entry |Meaning 

|NEW |The event has been newly created (by a message, or by a rule which is missing an expected message).
|UPDATE |The event was edited by the operator (a change to comments, contact info, acknowledgement).
|DELETE |The event has been archived.
|CANCELLED |The event was automatically xref:cancelling[cancelled] following an OK-message.
|CHANGESTATE |The event's state was changed by the operator.
|ARCHIVED |The event has been automatically archived – since no rule was invoked, and the [.guihint]#Force message archiving# option was activated in the global settings.
|ORPHANED |The event was automatically archived as the applicable rule was deleted while the event was in the [.guihint]#counting# phase.
|COUNTREACHED |The event was changed from [.guihint]#counting# to [.guihint]#open# because the configured count of messages had been reached.
|COUNTFAILED |The event has been automatically archived because in the [.guihint]#counting# phase the required message count had not been reached.
|NOCOUNT |The event has been automatically archived because during the [.guihint]#counting# phase, the applicable rule has been altered so that it no longer counts the messages.
|DELAYOVER |The event was opened because the xref:timing[delay] configured in the rule has expired.
|EXPIRED |The event was automatically archived because its configured xref:timing[lifetime] had expired.
|EMAIL |An email has been sent.
|SCRIPT |An automatic action (script) has been executed.
|AUTODELETE |The event was automatically archived directly and immediately after opening because this action was configured in the applicable rule.
|===


=== Location of the archive

As mentioned at the beginning, the Event Console has not been conceived as a
comprehensive syslog archive. In order to make the implementation and
administration as simple as possible it does without a database backend.
Instead of this the archive is written as simple text data. Each entry consists
of a single line of text divided into columns by tabs. The file is located
in `var/mkeventd/history`:

[{shell}]
----
{c-omd} ll var/mkeventd/history/
total 1328
-rw-rw-r-- 1 stable stable     131 Dez  4 23:59 1480633200.log
-rw-rw-r-- 1 stable stable 1123368 Dez  5 23:39 1480892400.log
-rw-rw-r-- 1 stable stable  219812 Dez  6 09:46 1480978800.log
----

By default a new file is opened every day. Its rotation can be customised
in xref:globalsettings[Settings for the EC].
The [.guihint]#Event history logfile rotation# setting enables the rotation to be
set to weekly.

The file's name corresponds to the Unix-timestamp from the time of the creation
of the file (Seconds since the 1.1.1970 UTC).

These files will be retained for 365 days, unless otherwise altered in the
[.guihint]#Event history lifetime# setting. The files will additionally be included
in {CMK}'s central disk space-management, which can be configured in the
global settings under [.guihint]#Site management#. The respective _shorter_ preset
time limit applies here. The global management has the advantage that if disk
space becomes tight, starting from the oldest records it can delete historic
data from all files in an *evenly distributed* manner.

If you run into space problems the files in the catalogue can be simply deleted
or moved to another location by hand. Do not however store zipped or any other
files in this catalogue.


=== Automatic archiving

Despite the limitations imposed by text files it is theoretically possible
to archive a great number of messages. The writing to the archive's text files
is very efficient – though at the cost of any subsequent searches.
Since the files have only the time range for the query as an index,
every query requires all relevant files to be read and searched sequentially.

The EC will normally only write those messages to the archive for which an
event was actually opened.
This function can be extended to _all_ events in two ways:

. Create a rule to match all other events, and in [.guihint]#Outcome & actions# activate the [.guihint]#Delete event immediately after the actions# option.
. In the xref:globalsettings[EC's global settings], activate the [.guihint]#Force message archiving# option.

This latter point ensures that messages to which no rule applies nonetheless
go to the archive (flagged as `ARCHIVED`).


[#tuning]
== Peformance and tuning

=== Processing of messages

Even in these days of servers with 64 bit cores and 2 TB main storage, software
performance still plays a role. Especially when processing events, in extreme
cases inadequate performance can lead to the loss of incoming messages.

The reason for this is that none of the protocols in use (Syslog, SNMP-Traps,
etc.) provide a flow control. If 1000 hosts simultaneously send a message every
second the recipient has no chance of coping with such a flow.

For this reason, in larger environments it is important to keep an eye on the
processing time for a message. This of course basically depends on how
many rules have been defined and how those rules have been constructed.

==== Measuring performance

For measuring performance there is a separate element for the
xref:user_interface#sidebar[Side bar] named [.guihint]#Event Console Performance#.
This can be integrated as usual with icon:button_sidebar_add_snapin[]:

image::ec_performance.png[width=280]

The values shown here are mean values over the last minute or so.
An ‘event storm’ that only lasts a couple of seconds cannot be read directly
here, but in this way the numbers have been somewhat ‘smoothed’ and are thus
easier to read.

To test for the achievable maximum performance, a storm of unclassified messages
can be artificially generated (but please, only in a test system!),
in which for example, you can continuously code the contents of a text file as
a loop in a shell in the Events-Pipe:

[{shell}]
----
{c-omd} while true ; do cat /etc/services > tmp/run/mkeventd/events ; done
----

The performance values from the performance element have the following meanings:

[cols="30,~"]
|===
|Wert |Meaning 

|[.guihint]#Received messages# |Count of the current incoming messages per second.
|[.guihint]#Rule hits# |The number of rules currently _being applied_ per second. These can also be rules that delete messages or simply only count. Thus not every rule match results in an event.
|[.guihint]#Rule tries# |The count of rules being tested. This provides valuable information on the efficiency of the rule chain – especially in conjunction with the following parameter:
|[.guihint]#Rule hit ratio# |The proportion of [.guihint]#Rule tries# to [.guihint]#Rule hits#. In other words – how many rules must the EC try before one (finally) applies. In the example shown in the screenshot the rate is questionably low.
|[.guihint]#Created events# |The count of events being generated each second. Because the Event Console should really only show _relevant problems_ (and is thus comparable to host and service problems in monitoring), in practice the number *3.77/s* in the illustration is of course far too high!
|[.guihint]#Processing time per message# |Here the time required for processing a message can be read. Attention: this is generally *not* the inverse of [.guihint]#Received messages# – since it doesn't include the times when the Event Console is idle when no messages are incoming. Here only the actual elapsed time required from the receipt of a message to the time its processing has finished is measured. In this you can roughly see the maximum number of messages that the EC _can_ process in a given time range.

 Please also note that this is not a measure of _CPU-time_, rather it is _real_ time. In a system with enough free CPUs these times will be around the same. But if the system is under such a load that not every process is allocated a CPU, then the real time can be noticibly longer.
|===


==== Tuning tips

The approximate number of messages the Event Console can process per second can be
be seen in [.guihint]#Processing time per message#. This time generally depends on how
many rules must be tested before a message can be processed.
There are a number of options for optimisation:

* Rules that exclude many messages should be placed at the front of the rule chain if possible
* Work with xref:rulepacks[rulepacks] to bundle related rules. The first rule in each pack should immediately exit the pack if the common basic condition is not satisfied

Furthermore, there is an optimisation in the EC based on the syslog priority
and facility. Here an internal rule chain will be constructed for every combination
of priority and facility, which will only include rules that are relevant to
messages in these combinations.

Any rule with a condition for priority or facility – or ideally both – will no
longer be included in ALL of the rule chains, rather for optimisation
in only a single rule chain. This means that the rule will not need to be
tested for messages with another syslog classification.

Following a restart an overview of all optimised rule chains will be
shown in `var/log/mkeventd.log`:

.var/log/mkeventd.log
[{file}]
----
[8488808306.233330]  kern        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233343]  user        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233355]  mail        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233367]  daemon      : emerg(120) alert(89) crit(89) err(89) warning(89) notice(89) info(89) debug(89)
[8488808306.233378]  auth        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233389]  syslog      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233408]  lpr         : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233482]  news        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233424]  uucp        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233435]  cron        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233446]  authpriv    : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233457]  ftp         : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233469]  (unused 12) : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233480]  (unused 13) : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233498]  (unused 13) : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233502]  (unused 14) : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233589]  local0      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233538]  local1      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233542]  local2      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233552]  local3      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233563]  local4      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233574]  local5      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233585]  local6      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233595]  local7      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233654]  snmptrap    : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
----

In the above example 67 rules can be seen that must be checked for every case.
For messages from the `daemon` facility there are 89 relevant rules,
and 120 rules must be checked only for the `daemon`/`emerg` combination.
Any rule that receives a condition for priority or facility reduces
the count by a further 67.

Of course these conditions can only be set if it is certain that they will also
be satisfied by the relevant messages!


=== Count of current events

The count of actual current events can also influence the EC's performance –
especially when they are clearly out of control. As already mentioned, the EC
should not be seen as a substitute for a syslog archive, rather to merely
display ‘ongoing problems’. The Event Console can in fact deal with several thousand
problems, but that is not really the point.

Once the count of current events exceeds around 5000, performance will become
noticibly degraded. On the one hand this will be seen in the GUI which will
respond more slowly to queries – and on the other hand the processing will also
slow down, since in some cases messages must be compared against all active events.
High memory usage can also be problematic.

For performance reasons the Event Console alsways holds all active events in RAM.
These will be logged once per minute (customisable), and at clean completion, in the
`var/mkeventd/status` file.
If this file becomes very large (e.g. over 50 megabytes), this procedure will
likewise continue slowing down. The actual size can be quickly checked with `ll` (alias for `ls -alF`):

[{shell}]
----
{c-omd} ll -h var/mkeventd/status
-rw-r--r-- 1 mysite mysite [hilite]#386K# Dez 14 13:46 var/mkeventd/status
----

If due to a clumsy rule (e.g., a rule that matches everything) far too many current
events are generated, manual deletions via the GUI are quite impractical.
In such a situation simply deleting the status file helps:

[{shell}]
----
{c-omd} omd stop mkeventd
Stopping mkeventd...killing 17436......OK
{c-omd} rm var/mkeventd/status
{c-omd} omd start mkeventd
Starting mkeventd (builtin: syslog-udp)...OK
----


*Attention*: Naturally _all_ current events will be lost, likewise
the stored rule counts and other states.
In particular, new events will begin again with the ID 1.


[#overflow]
==== Automatic overflow protection

From Version {v14}i2] the Event Console has an automatic protection
against ‘flooding’. This limits the number of current events per host, per rule,
and globally. In this way not only are open events counted, but also those in other
phases, such as, for example, [.guihint]#delayed# or [.guihint]#counting#.
Archived events are not counted.

This protects you in situations in which, due to a systemic problem in the
network, thousands of critical events could stream in and ‘jam’ the Event Console.
On the one hand this averts a performance breakdown in the Event Console while
it tries to contain too many events in main memory – on the other hand the
overview remains (just) manageable for the operator, and events that are not a
part of the storm remain visible.


Once a limit has been reached, one of the following actions will take place:

* The creation of new events will be stopped (for this host, this rule, or globally)
* Like the preceeding, but an ‘overflow event’ will also be generated
* Like the preceeding, but an appropriate contact person will also be notified
* Alternatively to the preceeding three options, you can allow the respective oldest event to be deleted in order to make space for a newer


The limits, and likewise the associated consequence of a limit being reached
can be set in [.guihint]#Generic > Limit amount of current events#.
The following image shows the default setting:

image::ec_limit_open_events.jpg[]

If you have activated the [.guihint]#create overflow event# option, when the limit has
been reached _an artificial_ event will be generated which will inform the
operator of the error situation:

image::ec_overflow_event.png[]

If you have additionally activated the [.guihint]#notify contacts...# option,
relevant contact personnel will be notified via {CMK}-Alarm.
The notification runs through {CMK}'s xref:notifications#[notification rules].
These rules do not absolutely have to use the exact contact selection specified
in the Event Console, but they can modify it. The following table shows which
contacts will be selected if you have set the
[.guihint]#Notify all contacts of the notified host or service# option (the default):


[cols="15,~"]
|===
|Limit |Contact list 

|per Host |The host contacts, which are identified in exactly the same way as with the xref:notifications[notification of events] in {CMK}.
|per Rule |Here the field for the host name will be left empty. If the rule defines contact groups, these will be selected – otherwise the fallback- contacts will apply.
|Global |The fallback-contacts.
|===



=== Archive too large


As shown xref:archive[above] the Event Console has an archive of all events and
their processing steps. For reasons of simple implementation and administration
these are stored as simple text files.

Text files are unbeatable for performance when it comes to the _writing_
of data – not even by the world's fastest database. This is due to,
among other factors, the optimisation of this type of access through Linux, and
the complete storage hierarchy of hard drives and SANs. This is however to the
detriment of the read access – since text files have no indexes, searching in the
files requires the complete file to be read.

As an index the Event Console at least uses the log file's name for the _time_ of
the event. The narrower the time range for the query, the faster the search can be
processed.

It is nonetheless very important that the archive doesn't get too large.
If you simply use the Event Console to process genuine error messages,
this can't really happen. But if it is used as a substitute for a real syslog
archive, it can certainly result in a very large file being produced.

If you find yourself in the situation in which the archive has gotten too large,
you can simply delete older files in `var/mkeventd/history/`.
You can also apply a general limit to data lifetimes in [.guihint]#Event history lifetime#,
thus predefining future deletions. By default the data will be saved for
365 days. You may well get by with much less.


=== Measuring performance over time

From Version {v14}, for every active instance on the event
console {CMK} automatically provides a new service which displays the
performance data in curves, and which also warns of xref:overflow[overflow].

As long as at least one Linux agent of this version is installed on the
monitoring core itself, the Check will be automatically found and set up as usual:

image::ec_check.png[]


The Check provides very many interesting performance data, for example, the count
of incoming messages over a time range, and how many of these are discarded:

image::ec_graph_message_rate.png[width=550]


The efficiency of your rule chain will be displayed through a comparison of
rules tested with those that have taken effect:

image::ec_graph_rule_efficiency.png[width=550]

This graph shows the average time for processing a message:

image::ec_graph_processing_time.png[width=550]


As well as those shown here, there are numerous further diagrams.



== Distributed monitoring


How to implement the Event Console in an installation with multiple
{CMK}-instances can be learned about in the
xref:distributed_monitoring#ec[article on distributed monitoring].



== The status interface

Via the `tmp/run/mkeventd/status` Unix-Socket, as well as access to the
internal status, the Event Console enables the execution of commands.
The protocol used here is a greatly-restricted subset of xref:livestatus#[Livestatus].

Up until Version {v128} the xref:user_interface#[GUI] used this socket
to display the open and archived events, and to execute commands on events.
From Version {v14} the monitoring core acts as a substitute on
the interface, and passes the data to the GUI to make both a
xref:distributed_monitoring#[distributed monitoring] and the Event Console possible.



The following restrictions apply to the Event Console's simplified live status:

* The only permitted headers are `Filter:` and `OutputFormat:`.
* For this reason keep alive is not possible. Only a single query per connection is possible.


The following tables are available:

[cols=2]
|===

|events |List of all current events
|history |Access to the xref:archive[archive]. A query to this table directs to an access of the archive's text data. Definitely use a filter for the time range of the desired entry to avoid a full accessing all of the files.
|status |Status and performance data for the EC. This table always has exactly one line.
|===



With the help of `unixcat` commands can be written to the socket using a very simple syntax:

[{shell}]
----
{c-omd} echo "COMMAND RELOAD" | unixcat tmp/run/mkeventd/status
----


The following commands are available:

[cols=2]
|===

|DELETE |Archives an event. Argument: Event-ID and username.
|RELOAD |Refreshes the configuration
|SHUTDOWN |Shuts the Event Console down
|REOPENLOG |Reopens the Log file. This command is required by the Log file rotation.
|FLUSH |Deletes all current and archived events!
|SYNC |Initiates an immediate update of the `var/mkeventd/status` file.
|RESETCOUNTERS |Resets the hits counters (corresponds to the menu entry [.guihint]#Event Console > Reset counters# in the setup GUI.
|UPDATE |Updates an event. The arguments are in the sequence – event-ID, user-ID, acknowledgement (0/1), comments, contact info.
|CHANGESTATE |Changes the states {OK} / {WARN} / {CRIT} / {UNKNOWN} for an event. Arguments are event-ID, user-ID and state number (`0`/`1`/`2`/`3`)
|ACTION |Executes a user-defined action on an event. Arguments are event-ID, user-ID and actions-ID. The special `@NOTIFY` ID corresponds to a xref:notifications[notification] over {CMK}.
|===



== Files and directories

[cols="50,~"]
|===
|File path |Meaning 

|var/mkeventd |The Event-Daemon's working directory
|var/mkeventd/status |The complete current state of the Event Console. This primarily includes all current open events (and those intermediate states like  [.guihint]#counting#..). In the case of a configuration error that produces very many open events this file can be huge and it can drastically reduce the EC's performance. In such a case you can stop the `mkeventd` service, delete the file, and restart the service, in order to delete all open events with one action.
|var/mkeventd/history/ |The xref:archive[EC-Archive's] storage location
|etc/check_mk/mkeventd.d/wato/global.mk |WATO stores the Event Console's global settings in Python-syntax.
|etc/check_mk/mkeventd.d/wato/rules.mk |All of your configured rule packs and rules in Python-syntax.
|tmp/run/mkeventd/events |A Named-Pipe in which with `echo` or other commands you can write messages directly in order to pass them to the EC. Please ensure that only a single application writes in this pipe at any point in time, otherwise the messages' texts can become mixed together.
|tmp/run/mkeventd/eventsocket |A Unix-socket that performs the same function as the pipe, but which makes simultaneous writing by multiple applications possible. To write to it the `unixcat` or `socat` commands are needed.
|tmp/run/mkeventd/pid |The current process-ID of the event daemon when it is running.
|tmp/run/mkeventd/status |A Unix-socket that enables the querying of the current state, and the sending of commands. Up to {CMK} Version {v128} the GUI uses this socket to display the views and the execution of commands. From Version {v14}i2] the GUI's queries go to the monitoring core which then connects itself to the socket.
|local/share/snmp/mibs |Your uploaded MIB-files for the translation of SNMP-traps
|===





////
== Einleitung

=== Ereignisse sind keine Zustände

Die Hauptaufgabe von {CMK} ist das aktive Überwachen von _Zuständen._
Zu jedem Zeitpunkt hat jeder überwachte Service
einen der Zustände {OK}, {WARN}, {CRIT} oder {UNKNOWN}. Durch regelmäßige Abfragen
aktualisiert das Monitoring ständig sein Bild von der Lage.

Eine ganz andere Art des Monitorings ist das Arbeiten mit _Ereignissen_ (_events_).
Ein Beispiel für ein Ereignis ist eine Exception, die in einer Anwendung
auftritt. Die Anwendung läuft eventuell korrekt weiter und hat nach wie
vor den Zustand {OK} -- aber irgendetwas _ist passiert._

=== Die Event Console

{CMK} verfügt mit der *Event Console* (kurz EC) über ein voll
integriertes System zur Überwachung von Ereignissen aus Quellen wie
Syslog, SNMP Traps, Windows Event Logs, Log-Dateien und eigenen Anwendungen.
Dabei werden aus Ereignissen nicht einfach Zustände gemacht, sondern sie
bilden eine eigene Kategorie und werden
von {CMK} sogar im [.guihint]#Overview# der xref:user_interface.html#sidebar[Seitenleiste] mit angezeigt:

image::tactical_overview_events.png[width=400]

Intern werden Ereignisse nicht durch den Monitoring-Kern, sondern von einem eigenen
Dienst verarbeitet -- dem Event Daemon (`mkeventd`).

Die Event Console verfügt auch über ein Archiv, in dem Sie über Ereignisse
in der Vergangenheit recherchieren können. Gleich vorweg sei allerdings
gesagt: Dies ist kein Ersatz für ein echtes Log-Archiv. Die Aufgabe der
Event Console ist das intelligente Herausfiltern einer _kleinen_ Zahl
von _relevanten_ Meldungen aus einem großen Strom. Sie ist optimiert
auf Einfachheit, Robustheit und Durchsatz -- nicht auf Speicherung großer
Datenmengen.

Ein kurzer Abriss der Funktionalität der EC:

* Sie kann Meldungen per Syslog oder SNMP-Traps _direkt_ empfangen. Eine Konfiguration der entsprechenden Linux-Systemdienste ist daher nicht notwendig.
* Sie kann mithilfe der {CMK}-Agenten auch textbasierte Log-Dateien und Windows Event Logs auswerten.
* Sie klassifiziert Meldungen anhand einer Kette von benutzerdefinierten Regeln.
* Sie kann Meldungen korrelieren, zusammenfassen, zählen, annotieren, umschreiben und auch deren zeitliche Zusammenhänge berücksichtigen.
* Sie kann automatisiert Aktionen ausführen und über {CMK} xref:notifications#[Benachrichtigungen] versenden.
* Sie ist voll in die Oberfläche von {CMK} integriert.
* Sie ist in jedem aktuellen {CMK}-System enthalten und sofort einsatzfähig.


=== Begriffe

Die Event Console empfängt *Meldungen* (meist in Form von _Log Messages_). Eine Meldung ist
eine Zeile Text mit einer Reihe von möglichen Zusatzattributen, wie z.B. einem
Zeitstempel, einem Host-Namen usw. Wenn die Meldung relevant ist, wird daraus
direkt ein *Event* mit den gleichen Attributen, aber:

* Nur wenn eine Regel greift, wird aus einer Meldung ein Event erzeugt.
* Regeln können den Text und andere Attribute von Meldungen verändern.
* Mehrere Meldungen können zu einem Event zusammengefasst werden.
* Meldungen können aktuelle Events wieder xref:cancelling[aufheben].
* Künstliche Events können erzeugt werden, wenn bestimmte xref:expect[Meldungen ausbleiben].

Ein Event kann verschiedene *Phasen* durchlaufen:

[cols="17,~"]
|===

|*open* |Der „normale“ Zustand: Etwas ist passiert: der Operator soll sich kümmern.
|*acknowledged* |Das Problem wurde quittiert -- dies ist analog zu Host- und Service-Problemen aus dem statusbaserten Monitoring.
|*counting* |Es ist noch nicht die erforderliche Anzahl von bestimmten Meldungen eingetroffen: die Situation ist noch unproblematisch. Das Ereignis wird dem Operator deswegen noch nicht angezeigt.
|*delayed* |Eine Störmeldung ist eingegangen, aber die Event Console wartet noch, ob in einer konfigurierten Zeit die passende {OK}-Meldung eingeht. Erst danach wird das Event dem Operator angezeigt.
|*closed* |Das Event wurde vom Operator oder automatisch geschlossen und ist nur noch im Archiv.
|===

Ein Event hat ferner einen *Zustand.* Genau genommen ist hier aber
nicht der Zustand des Events selbst gemeint, sondern des Dienstes
oder Gerätes, der/das den Event gesendet hat. Um eine Analogie zum statusbasierten
Monitoring zu schaffen, ist auch ein Event als {OK}, {WARN}, {CRIT} oder
{UNKNOWN} eingestuft.

[#setup]
== Die Event Console aufsetzen

Das Einrichten der Event Console ist sehr einfach, da die Event Console 
fester Bestandteil von {CMK} ist und automatisch aktiviert wird.

Falls Sie jedoch über das Netzwerk Syslog-Meldungen oder SNMP-Traps
empfangen möchten, so müssen Sie dies separat aktivieren. Der Grund ist,
dass beide Dienste einen UDP-Port mit einer jeweils bestimmten bekannten
Portnummer öffnen müssen. Und da dies pro System nur eine {CMK}-Instanz
machen kann, ist der Empfang über das Netzwerk per Default abgeschaltet.
Die Portnummern sind:

[cols=3]
|===
|Protokoll |Port |Dienst 

|UDP |162 |SNMP Traps
|UDP |514 |Syslog
|TCP |514 |Syslog via TCP
|===

Syslog via TCP wird nur selten verwendet, hat aber den Vorteil, dass die
Übertragung der Meldungen hier abgesichert wird. Bei UDP ist niemals
garantiert, dass Pakete wirklich ankommen. Und weder Syslog noch SNMP-Traps
bieten Quittungen oder einen ähnlichen Schutz vor verlorengegangen Meldungen.
Damit Sie Syslog via TCP verwenden können, muss natürlich auch das sendende
System dazu in der Lage sein, Meldungen über diesen Port zu verschicken.

In der {CMK}-Appliance können Sie den Empfang von Syslog/SNMP-Traps in
der Instanzkonfiguration einschalten. Ansonsten verwenden Sie einfach `omd
config`. Sie finden die benötigte Einstellung unter [.guihint]#Addons#:

image::ec_omd_config.png[width=360]

Beim `omd start` sehen Sie in der Zeile mit `mkeventd`, welche externen Schnittstellen Ihre EC
offen hat:

[{shell}]
----
{c-omd} omd start
Creating temporary filesystem /omd/sites/mysite/tmp...[green]#OK#
Starting mkeventd (builtin: syslog-udp,snmptrap)...OK
Starting liveproxyd...OK
Starting mknotifyd...OK
Starting rrdcached...OK
Starting cmc...OK
Starting apache...OK
Starting dcd...OK
Starting redis...OK
Initializing Crontab...OK
----


== Erste Schritte mit der Event Console

[#first_steps_rules]
=== Regeln, Regeln, Regeln

Eingangs wurde erwähnt, dass die EC dazu dient, _relevante_ Meldungen
herauszufischen und anzuzeigen. Nun ist es leider so, dass die meisten
Meldungen -- egal ob aus Textdateien, dem Windows Event Log oder dem
Syslog -- ziemlich unwichtig sind. Und da hilft es auch nichts, wenn Meldungen
seitens des Verursachers bereits voreingestuft sind.

Zum Beispiel gibt es in Syslog und im Windows Event Log eine Klassifizierung der
Meldungen in etwas Ähnliches wie OK, WARN und CRIT. Aber was jetzt WARN und
CRIT ist, hat dabei der jeweilige Programmierer subjektiv festgelegt. Und es
ist noch nicht einmal gesagt, dass die Anwendung, welche die Meldung produziert
hat, auf diesem Rechner überhaupt wichtig ist.  Kurzum: Sie kommen nicht
drumherum, selbst zu konfigurieren, welche Meldungen für Sie nach einem
Problem aussehen und welche einfach verworfen werden können.

Wie überall in {CMK} erfolgt auch hier die Konfiguration über
_Regeln,_ welche bei jeder eingehenden Meldung von der EC nach dem
„first match“-Prinzip abgearbeitet werden. Die erste Regel, die auf eine
eingehende Meldung greift, entscheidet also über deren Schicksal. Greift
keine Regel, so wird die Meldung einfach lautlos verworfen.

Da man bei der EC mit der Zeit gewöhnlich sehr viele Regeln aufbaut,
sind die Regeln hier in _Paketen_ organisiert. Die Abarbeitung geschieht
Paket für Paket und innerhalb eines Pakets von oben nach unten. Damit ist
auch die Reihenfolge der Pakete wichtig.

=== Anlegen einer einfachen Regel

Die Konfiguration der EC finden Sie wenig überraschend im [.guihint]#Setup#-Menü
unter [.guihint]#Events > Event Console#. 
Ab Werk finden Sie dort nur das [.guihint]#Default rule pack#, das aber keine Regeln enthält.
Eingehende Meldungen werden demnach, wie bereits erwähnt, verworfen und auch nicht geloggt. Das Modul präsentiert
sich so:

image::ec_wato_module.png[]

Legen Sie nun mit icon:icon_new[] [.guihint]#Add rule pack# als Erstes ein neues Regelpaket an:

image::ec_new_rule_pack.png[]

Wie immer gilt die ID als interne Referenz und kann später nicht mehr geändert
werden. Nach dem Speichern finden Sie den neuen Eintrag in der Liste Ihrer
Regelpakete:

image::ec_rule_pack_list.png[]

Dort können Sie jetzt mit icon:icon_ec_rules[] in das noch leere
Paket wechseln und mit icon:icon_new[] [.guihint]#Add rule# eine neue Regel anlegen.
Füllen Sie hier lediglich den ersten Kasten mit der Überschrift
[.guihint]#Rule Properties#:

image::ec_first_rule.png[]

Einzig notwendig ist eine eindeutige [.guihint]#Rule ID#. Diese
ID werden Sie später auch in Log-Dateien finden, und sie wird bei den
erzeugten Events mit gespeichert. Es ist also nützlich, die IDs systematisch
zu vergeben.  Alle weiteren Kästen sind optional. Das gilt insbesondere
für die Bedingungen.

*Wichtig:* Die neue Regel ist erst einmal nur zum Testen und greift vorerst auf
_jedes_ Ereignis. Daher ist es auch wichtig, dass Sie diese später
wieder entfernen oder zumindest deaktivieren! Andernfalls wird ihre Event
Console mit jeder nur erdenklichen unnützen Meldung geflutet und so ziemlich
nutzlos werden.


==== Aktivieren der Änderungen

Wie immer in {CMK}, müssen Sie zuerst xref:wato.html#activate_changes[Änderungen aktivieren], damit diese
wirksam werden. Das ist nicht von Nachteil: Denn so können Sie bei
Änderungen, die mehrere zusammengehörige Regeln betreffen, genau festlegen,
wann diese „live“ gehen sollen. Und Sie können mit dem [.guihint]#Event Simulator#
zuvor testen, ob alles passt.

Klicken Sie zuerst rechts oben auf der Seite auf die Zahl der aufgelaufenen Änderungen.

image::ec_activate_changes.png[]

Klicken Sie anschließend auf [.guihint]#Activate on selected sites# um die Änderung
zu aktivieren. Die Event Console ist so konstruiert, dass diese Aktion absolut
_unterbrechungsfrei_ abläuft. Der Empfang von eingehenden Meldungen wird
zu jeder Zeit sichergestellt, so dass durch den Prozess keine Meldungen verlorengehen können.

Das Aktivieren von Änderungen in der EC ist nur Administratoren
erlaubt. Gesteuert wird das über die xref:wato_user#roles[Berechtigung]
[.guihint]#Activate changes for event console#.


[#eventsimulator]
==== Ausprobieren der neuen Regel

Für das Testen könnten Sie jetzt natürlich Meldungen per Syslog oder SNMP
senden. Das sollten Sie später auch tun.  Für einen ersten Test ist aber
der in der EC eingebaute [.guihint]#Event Simulator# praktischer:

image::ec_simulator.png[]

Hier haben Sie zwei Möglichkeiten: [.guihint]#Try out# berechnet anhand der
simulierten Meldung, welche der Regeln matchen würden. Befinden Sie sich
in der obersten Ebene der Setup-GUI für die EC, so werden die Regelpakete
markiert. Befinden Sie sich innerhalb eines Regelpakets, so werden die
einzelnen Regeln markiert. Jedes Paket bzw. jede Regel wird mit einem der
folgenden drei Symbole gekennzeichnet:

[cols="10,~"]
|===

|icon:icon_rulematch[] |Diese Regel ist die erste, die auf die Meldung greift und legt folglich deren Schicksal fest.
|icon:icon_rulepmatch[] |Diese Regel würde zwar greifen, aber die Meldung wurde schon von einer früheren Regel bearbeitet.
|icon:icon_rulenmatch[] |Diese Regel greift nicht. Sehr praktisch: Wenn Sie mit der Maus über die graue Kugel fahren, bekommen Sie eine Erklärung, aus welchem Grund die Regel nicht greift.
|===


Ein Klick auf [.guihint]#Generate event# macht fast das Gleiche wie [.guihint]#Try out#, nur wird
jetzt die Meldung *tatsächlich erzeugt.* Eventuell definierte xref:actions[Aktionen]
werden tatsächlich ausgeführt. Und das Event taucht dann auch in den offenen
Events im Monitoring auf. Den Quelltext der erzeugten Meldung sehen Sie in
der Bestätigung:

image::ec_event_generated.png[]

Das so erzeugte Event taucht im [.guihint]#Monitor#-Menü unter [.guihint]#Event Console > Events# auf:

image::ec_one_open_event.png[]

==== Meldungen testweise von Hand erzeugen

Für einen ersten echten Test über das Netzwerk können Sie sehr einfach von einem
anderen Linux-Rechner aus per Hand eine Syslog-Meldung versenden. Da das Protokoll
so einfach ist, brauchen Sie dafür nicht einmal ein spezielles Programm, sondern
können die Daten einfach per `netcat` oder `nc` via UDP versenden.
Der Inhalt des UDP-Pakets besteht aus einer Zeile Text. Wenn diese einem
bestimmten Aufbau entspricht, werden die Bestandteile von der Event Console
sauber zerlegt:

[{shell}]
----
{c-user} echo '<78>Dec 18 10:40:00 myserver123 MyApplication: It happened again.' | nc -w 0 -u 10.1.1.94 514
----

Sie können aber auch einfach _irgendetwas_ senden. Die EC wird das dann trotzdem
annehmen und einfach als Meldungstext auswerten. Zusatzinformation wie z.B. die Anwendung,
die Priorität etc. fehlen dann natürlich. Als Status wird zur Sicherheit {CRIT}
angenommen:

[{shell}]
----
{c-user} echo 'This is no syslog message' | nc -w 0 -u 10.1.1.94 514
----

Innerhalb der {CMK}-Instanz, auf der die EC läuft, gibt es eine _named Pipe_,
in die Sie Textmeldungen lokal per `echo` schreiben können. Dies ist eine
sehr einfache Methode, um eine lokale Anwendung anzubinden und ebenfalls eine Möglichkeit,
das Verarbeiten von Meldungen zu testen:

[{shell}]
----
{c-omd} echo 'Local application says hello' > tmp/run/mkeventd/events
----

Auch hier ist es übrigens möglich, im Syslog-Format zu senden, damit alle Felder des Events
sauber befüllt werden.

[#globalsettings]
=== Einstellungen der Event Console

Die Event Console hat ihre eigenen globalen Einstellungen, welche Sie
nicht bei denen der anderen Module finden, sondern unter [.guihint]#Setup > Events > Event Console# mit dem Knopf [.guihint]#Settings.#

image::ec_settings.png[]

Die Bedeutung der einzelnen Einstellungen erfahren Sie wie immer aus der
Inline-Hilfe ([.guihint]#Help > icon:icon_help[] Show inline help#)
und an den jeweils passenden Stellen in diesem Artikel.

Der Zugriff auf die Einstellungen ist über die Berechtigung
[.guihint]#Configuration of Event Console# geschützt, welche per
Default nur in der Rolle `admin` enthalten ist.


[#permissions]
=== Berechtigungen

Auch bei den xref:wato_user#roles[Rollen und Berechtigungen] hat die Event Console einen
eigenen Abschnitt. Auf einige der Berechtigungen werden wir an passenden Stellen
im Artikel näher eingehen.

image::ec_permissions.png[]

[#hostnames]
=== Host-Zuordnung in der Event Console

Eine Besonderheit der Event Console ist, dass im Gegensatz zum statusbasierten Monitoring nicht Hosts im Zentrum stehen:
Events können ohne explizite Host-Zuordnung auftreten, was oft sogar gewünscht ist. Allerdings
sollte bei Hosts, die sich bereits im aktiven Monitoring befinden, eine leichte
Zuordnung möglich sein, um im Monitoring bei Auftreten eines Events schnell zur
Statusübersicht zu gelangen. Spätestens, wenn aus Events 
xref:eventsgostate[Zustände] werden sollen, ist die korrekte Zuordnung zwingend.

Grundsätzlich gilt bei per Syslog empfangenen Meldungen, dass der in der
Meldung verwendete Host-Name dem Host-Namen im Monitoring entsprechen sollte.
Dies erreichen Sie durch Verwendung des _fully qualified domain name_ (FQDN) / _fully qualified host name_ (FQHN) sowohl in Ihrer
Syslog-Konfiguration als auch in der Benennung der Hosts in {CMK}.
In Rsyslog erreichen Sie dies über die globale Direktive `$PreserveFQDN on`.

{CMK} versucht die Host-Namen aus den Events denen aus dem aktiven Monitoring so gut es geht xref:hostmatching[automatisch zuzuordnen.]
Neben dem Host-Namen wird auch der Host-Alias ausprobiert. Steht hier der per Syslog
übertragene Kurzname, erfolgt die Zuordnung korrekt.

Eine Rückwärtsauflösung der IP-Adresse wäre hier wenig sinnvoll, da häufig
zwischengeschaltete Log-Server genutzt werden. Ist die Umstellung der Host-Namen
auf FQDN/FQHN oder das Nachtragen vieler Aliase zu aufwendig, können Sie mit
der EC-xref:globalsettings[Einstellung] [.guihint]#Hostname translation for incoming messages#
Host-Namen bereits direkt beim Empfang von Meldungen umschreiben.
Dabei haben Sie zahlreiche Möglichkeiten:

image::ec_hostname_translation.png[]

Am flexibelsten ist die Arbeit mit xref:regexes#[regulären Ausdrücken],
welche intelligentes Suchen und Ersetzen in den Host-Namen erlauben.
Insbesondere, wenn zwar Host-Namen eineindeutig sind, aber nur der in {CMK}
mitverwendete Domainpart fehlt, hilft eine simple Regel: `(.*)` wird zu
`\1.mydomain.test`. 
In Fällen, wo das alles nicht genügt, können Sie noch mit [.guihint]#Explicit hostname mapping#
eine Tabelle von einzelnen Namen und deren jeweiliger Übersetzung angeben.

*Wichtig:* Die Namensumwandlung geschieht bereits *vor* dem Prüfen
der Regelbedingungen und somit lange vor einem möglichen Umschreiben des
Host-Namens durch die Regelaktion [.guihint]#Rewrite hostname# beim xref:rewriting[automatisches Umschreiben von Texten.]

Etwas einfacher ist die Zuordnung bei xref:snmp#[SNMP]. Hier wird die
IP-Adresse des Senders mit den gecacheten IP-Adressen der Hosts im Monitoring
verglichen, d.h. sobald regelmäßige aktive Checks vorhanden sind, wie
Erreichbarkeitsprüfung des Telnet- oder SSH-Ports eines Switches, werden per
SNMP versandte Statusmeldungen dieses Gerätes dem korrekten Host zugeordnet
werden.


[#monitoring]
== Die Event Console im Monitoring

=== Event-Ansichten

Von der Event Console erzeugte Events werden analog zu Hosts und Services in
der xref:user_interface#[Monitoring-Umgebung] angezeigt. 
Den Einstieg dazu finden Sie im [.guihint]#Monitor#-Menü unter [.guihint]#Event Console > Events:#

image::ec_open_events_hilites.png[]

Die angezeigte Ansicht [.guihint]#Events# können Sie genauso anpassen wie alle anderen. Sie können die angezeigten
Events filtern, Kommandos ausführen usw. Einzelheiten erfahren Sie im Artikel über die xref:views#[Ansichten].
Wenn Sie neue Event-Ansichten erstellen,
stehen Ihnen Events sowie xref:archive[Event-Historie] als Datenquellen zur Verfügung.

Ein Klick auf die ID des Events (hier z.B. `27`) bringt Sie zu dessen
Details:

image::ec_event_details.png[]

Wie Sie sehen können, hat ein Event eine ganze Menge von Datenfeldern,
deren Bedeutung wir in diesem Artikel nach und nach erklären werden. Die wichtigsten
Felder sollen trotzdem bereits hier kurz erwähnt werden:

[cols="25,~"]
|===
|Feld |Bedeutung 

|[.guihint]#State (severity) of event# |Wie in der Einleitung erwähnt. wird jeder Event als {OK}, {WARN}, {CRIT} oder {UNKNOWN} eingestuft. Events vom Status {OK} sind eher ungewöhnlich. Denn die EC ist gerade dafür gedacht, nur die _Probleme_ herauszufiltern. Es gibt aber Situationen, in denen ein {OK}-Event durchaus Sinn machen kann.
|[.guihint]#Text/Message of the event# |Der eigentliche Inhalt des Events: Eine Textmeldung.
|[.guihint]#Hostname# |Der Name des Hosts, der die Meldung gesendet hat. Dieser muss nicht unbedingt ein mit {CMK} aktiver überwachter Host sein. Falls ein Host dieses Namens jedoch im Monitoring existiert, stellt die EC automatisch eine xref:hostnames[Verknüpfung] her. In diesem Fall sind dann auch die Felder [.guihint]#Host alias#, [.guihint]#Host contacts# und [.guihint]#Host icons# gefüllt und der Host erscheint in der gleichen Schreibweise wie im aktiven Monitoring.
|[.guihint]#Rule-ID# |Die ID der Regel, welche diesen Event erzeugt hat. Ein Klick auf diese ID bringt Sie direkt zu den Details der Regel. Übrigens bleibt die ID auch dann erhalten, wenn die Regel inzwischen nicht mehr existiert.
|===


Wie eingangs erwähnt, werden Events
direkt im [.guihint]#Overview# der Seitenleiste angezeigt:


Dabei sehen Sie drei Zahlen:

* [.guihint]#Events# -- alle offenen und quittierten Events (entspricht der Ansicht [.guihint]#Event Console > Events#)
* [.guihint]#Problems# -- davon nur diejenigen mit dem Zustand {WARN} / {CRIT} / {UNKNOWN}
* [.guihint]#Unhandled# -- davon wiederum nur die noch nicht quittierten (dazu gleich mehr)


[#commands]
=== Kommandos und Workflow von Events

Analog zu den Hosts und Services wird auch für Events ein einfacher Workflow
abgebildet.  Wie gewohnt geschieht das über xref:commands#[Kommandos],
welche Sie im Menü [.guihint]#Commands# finden. Durch Einblenden und Auswahl mit Checkboxen können Sie ein Kommando auf vielen
Events gleichzeitig ausführen. Als Besonderheit gibt es das häufig
gebrauchte _Archivieren_ eines einzelnen Events direkt über das Symbol
icon:icon_archive_event[].

Für jedes der Kommandos gibt es eine xref:permissions[Berechtigung], über die Sie steuern können, welcher Rolle
das Kommando erlaubt ist. Per Default sind alle Kommandos für Mitglieder
der Rollen `admin` und `user` freigeschaltet.

image::ec_commands_menu.png[width=550]

Folgende Kommandos stehen zur Verfügung:

==== Aktualisieren und quittieren

Das Kommando [.guihint]#Update & Acknowledge# blendet den folgenden Bereich oberhalb der Event-Liste ein:

image::ec_commands.png[width=550]

Mit dem Knopf [.guihint]#Update# können Sie in einem einzigen Arbeitsschritt einen Kommentar
an das Event hängen, eine Kontaktperson eintragen und das Event quittieren.
Das Feld [.guihint]#Change contact# ist bewusst Freitext. Hier können Sie auch Dinge
wie Telefonnummern eintragen. Das Feld hat insbesondere keinen Einfluss auf
die Sichtbarkeit des Events in der GUI. Es ist ein reines Kommentarfeld.

Die Checkbox [.guihint]#Set event to acknowledged# führt dazu, dass das Event
von der Phase [.guihint]#open# übergeht nach [.guihint]#acknowledged# und fortan als
[.guihint]#handled# gilt. Dies ist analog zu dem xref:basics_ackn#[Quittieren] von Host-
und Serviceproblemen.

Ein späteres erneutes Aufrufen des Kommando mit nicht gesetzter Checkbox
_entfernt_ die Quittierung wieder.

==== Zustand ändern

Das Kommando [.guihint]#Change State# erlaubt den manuellen Zustandswechsel von Events --
z.b. von {CRIT} auf {WARN}.

==== Aktionen ausführen

Mit dem Kommando [.guihint]#Custom Action# können Sie auf Events frei definierbare xref:actions[Aktionen]
ausführen lassen. Zunächst ist nur die Aktion [.guihint]#Send monitoring notification#
verfügbar. Diese sendet eine {CMK}-Benachrichtigung, die genauso behandelt wird wie die
von einem aktiv überwachten Service. Diese durchläuft die xref:notifications#[Benachrichtigungsregeln]
und führt dann entsprechend zu E-Mails, SMS oder was auch immer Sie konfiguriert haben.
Einzelheiten zur Benachrichtigung durch die EC erfahren Sie xref:notifications[weiter unten].

==== Archivieren

Der Knopf [.guihint]#Archive event# löscht den Event endgültig aus den offenen Events. Da
alle Aktionen auf Events -- inklusive dieses Löschvorgangs -- auch im xref:archive[Archiv]
aufgezeichnet werden, können Sie später immer noch auf alle Informationen des
Events zugreifen. Deswegen sprechen wir nicht von Löschen, sondern von Archivieren.

Das Archivieren von einzelnen Events erreichen Sie auch aus der Eventliste bequem
über das Symbol icon:icon_archive_event[].


[#visibility]
=== Sichtbarkeit von Events

==== Problematik der Sichtbarkeit

Für die Sichtbarkeit von Hosts und Services im Monitoring für normale
Benutzer werden von {CMK} xref:wato_user#contact_groups[Kontaktgruppen]
verwendet. Diese werden per Setup-GUI, Regel oder Ordnerkonfiguration den
Hosts und Service zugeordnet.

Nun ist es aber bei der Event Console so, dass so eine Zuordnung von Events
zu Kontaktgruppen erst einmal nicht existiert. Denn im Vorhinein ist gar nicht
bekannt, welche Meldungen überhaupt empfangen werden können. Nicht einmal die
Liste der Hosts ist bekannt, denn die Sockets für Syslog und SNMP sind ja
von überall aus erreichbar. Deswegen gibt es bei der Sichtbarkeit in der
Event Console ein paar Besonderheiten:


==== Erst einmal dürfen alle alles sehen

Zunächst einmal gibt es bei der Konfiguration der
xref:wato_user#roles[Benutzerrollen] die Berechtigung
[.guihint]#Event Console > See all events#. Diese ist per Default an, so dass
*auch normale Benutzer alle Events sehen dürfen!* Dies ist bewusst so
eingestellt, damit nicht aufgrund fehlerhafter Konfiguration wichtige
Fehlermeldungen unter den Tisch fallen. Der erste Schritt zu einer genaueren
Steuerung der Sichtbarkeit ist also das Entfernen dieser Berechtigung aus der
Rolle `user`.



[#hostmatching]
==== Zuordnung zu Hosts

Damit die Sichtbarkeit von Events möglichst konsistent mit dem übrigen
Monitoring ist, versucht die Event Console so gut wie möglich die Hosts,
von denen sie Events empfängt, Ihren per Setup-GUI konfigurierten Hosts
zuzuordnen. Was einfach klingt ist trickreich im Detail. Denn teils fehlt
im Event eine Angabe zum Host-Namen und nur die IP-Adresse ist bekannt.
In anderen Fällen hat der Host-Name eine andere Schreibweise als in der Setup-GUI.

Die Zuordnung erfolgt konkret wie folgt:

* Ist im Event kein Host-Name bekannt, so wird anstelle dessen seine IP-Adresse als Host-Name verwendet.
* Der Host-Name im Event wird dann _ohne Berücksichtigung von Groß-/Kleinschreibung_ mit allen Host-Namen, Host-Aliassen und IP-Adressen der Hosts aus dem Monitoring verglichen.
* Wird so ein Host gefunden, werden dessen Kontaktgruppen für den Event übernommen, und darüber wird dann die Sichtbarkeit gesteuert.
* Wird der Host jedoch *nicht* gefunden, so werden die Kontaktgruppen -- falls xref:contactgroups[dort konfiguriert] -- aus der Regel übernommen, welche den Event erzeugt hat.
* Sind auch dort keine Gruppen hinterlegt, so darf der Benutzer den Event nur dann sehen, wenn er die Berechtigung [.guihint]#Event Console > See events not related to a known host# hat.

Sie können die Zuordnung an einer Stelle beeinflussen: Falls nämlich in der
Regel Kontaktgruppen definiert sind *und* der Host zugeordnet werden
konnte, hat normalerweise die Zuordnung Vorrang.
Dies können Sie in einer Regel mit der Option [.guihint]#Precedence of contact groups# umstellen:

image::ec_outcome_contact_groups.png[]

Zudem können Sie direkt in der Regel Einstellungen für 
die Benachrichtigung vornehmen. Dies ermöglicht es,
die Art des Events gegenüber den regulären Zuständigkeiten für einen Host zu priorisieren.


=== Fehlersuche

==== Welche Regel greift wie oft?

Sowohl bei den Regelpaketen {nbsp}...

image::ec_pack_hits.png[]

&#8230;{nbsp} als auch bei den einzelnen Regeln {nbsp}...

image::ec_rule_hits.png[]

&#8230; finden Sie in der Spalte [.guihint]#Hits# die Angabe, wie oft das Paket bzw. die Regel
schon auf eine Meldung gepasst hat. Dies hilft Ihnen zum einen dabei, unwirksame Regeln
zu eliminieren oder zu reparieren. Aber auch bei Regeln, die sehr oft matchen, kann dies
interessant sein. Für die optimale Performance der EC sollten diese möglichst am Anfang
der Regelkette stehen. So können Sie die Anzahl von Regeln, die die EC bei jeder
Meldung ausprobieren muss, reduzieren.

Die Zählerstände können Sie jederzeit mit dem Menüpunkt [.guihint]#Event Console > Reset counters# 
zurücksetzen.

==== Regelauswertung debuggen

Beim xref:eventsimulator[Ausprobieren einer Regel] haben Sie schon gesehen, wie Sie mit dem [.guihint]#Event Simulator# die Auswertungen
Ihrer Regeln prüfen können. Ähnliche Informationen bekommen Sie zur Laufzeit für _alle_
Meldungen, wenn Sie in den xref:globalsettings[Einstellungen der EC] den Wert
von [.guihint]#Debug rule execution# auf [.guihint]#on# umstellen.

Die Log-Datei der Event Console finden Sie unter `var/log/mkeventd.log`.
Für jede Regel, die geprüft wird, aber nicht greift, erfahren Sie den
genauen Grund:

.var/log/mkeventd.log
[{file}]
----
[1481020022.001612] Processing message from ('10.40.21.11', 57123): '<22>Dec  6 11:27:02 myserver123 exim[1468]: Delivery complete, 4 message(s) remain.'
[1481020022.001664] Parsed message:
 application:    exim
 facility:       2
 host:           myserver123
 ipaddress:      10.40.21.11
 pid:            1468
 priority:       6
 text:           Delivery complete, 4 message(s) remain.
 time:           1481020022.0
[1481020022.001679] Trying rule test/myrule01...
[1481020022.001688]   Text:   Delivery complete, 4 message(s) remain.
[1481020022.001698]   Syslog: 2.6
[1481020022.001705]   Host:   myserver123
[1481020022.001725]   did not match because of wrong application 'exim' (need 'security')
[1481020022.001733] Trying rule test/myrule02n...
[1481020022.001739]   Text:   Delivery complete, 4 message(s) remain.
[1481020022.001746]   Syslog: 2.6
[1481020022.001751]   Host:   myserver123
[1481020022.001764]   did not match because of wrong text
----

Es versteht sich wohl von selbst, dass Sie dieses intensive Logging nur bei Bedarf
und mit Bedacht verwenden sollten. Bei einer nur etwas komplexeren Umgebung
werden _Unmengen_ von Daten erzeugt!

[#rules]
== Die ganze Mächtigkeit der Regeln

=== Die Bedingung

Der wichtigste Teil einer EC-Regel ist natürlich die _Bedingung_
[.guihint]#(Matching criteria)#. Nur wenn eine Meldung alle in der Regel
hinterlegten Bedingungen erfüllt, werden die in der Regel definierten
Aktionen ausgeführt und die Auswertung der Meldung damit abgeschlossen.

image::ec_matching_criteria.png[]

==== Allgemeines zu Textvergleichen

Bei allen Bedingungen, die Textfelder betreffen, wird der Vergleichstext
grundsätzlich als xref:regexes#[regulärer Ausdruck] behandelt. Der Vergleich
findet hier immer _ohne Unterscheidung von Groß-/Kleinschreibung_
statt. Letzteres ist eine Ausnahme von {CMK}-Konventionen in anderen Modulen.
Es macht aber das Formulieren der Regeln robuster. Auch sind
gerade Host-Namen in Events nicht unbedingt konsistent in ihrer Schreibweise,
falls diese nicht zentral, sondern auf jedem Host selbst konfiguriert werden.
Daher ist diese Ausnahme hier sehr sinnvoll.

Ferner gilt immer ein _Infix-Match_ -- also eine Überprüfung auf ein
_Enthaltensein_ des Suchtextes. Ein `pass:[.*]` am Anfang oder am Ende
des Suchtexts können Sie sich also sparen.

Davon gibt es allerdings eine *Ausnahme:*
Wird beim Match auf den Host-Namen *kein regulärer Ausdruck* verwendet, sondern ein
*fester Host-Name,* so wird dieser auf *exaktes* Übereinstimmen geprüft und
*nicht* auf ein Enthaltensein. Achtung: Sobald der Suchtext einen Punkt enthält,
wird dieser als regulärer Ausdruck gewertet und es gilt die Infix-Suche. `myhost.de`
matcht dann auch z.B. auf `notmyhostide`!

[#matchgroups]
==== Match-Gruppen

Sehr wichtig und nützlich ist hier das Konzept
xref:regexes#matchgroups[Match-Gruppen] beim Feld [.guihint]#Text to match#. Damit sind
die Textabschnitte gemeint, die beim Matchen mit geklammerten Ausdrücken
im regulären Ausdruck übereinstimmen.

Nehmen Sie an, Sie möchten folgende Art von Meldung in der Log-Datei einer
Datenbank überwachen:

[{file}]
----
Database instance WP41 has failed
----

Das `WP41` ist dabei natürlich variabel und Sie möchten sicher nicht
für jede unterschiedliche Instanz ein eigene Regel formulieren. Daher verwenden
Sie im regulären Ausdruck `pass:[.*]`, was für eine beliebige Zeichenfolge steht:

`Database instance .* has failed`

Wenn Sie jetzt den variablen Teil in runde Klammern setzen, wird sich die Event
Console den tatsächlichen Wert beim Matchen für weitere Aktionen *merken* (_capturing_):

`Database instance *(pass:[.*])* has failed`

Nach einem erfolgreichen Match der Regel ist jetzt die erste Match-Gruppe
auf den Wert `WP41` gesetzt (oder welche Instanz auch immer den
Fehler produziert hat).

Diese Match-Gruppen können Sie im Regelsimulator sehen, wenn Sie mit
der Maus über die grüne Kugel fahren:

image::ec_match_groups_1.png[]

Auch in den Details des erzeugten Events können Sie die Gruppen sehen:

image::ec_match_groups_2.png[width=700]

Die Match-Gruppen finden unter anderem Anwendung bei:

* Umschreiben von Events (xref:rewriting[Rewriting])
* Automatisches Aufheben von Events (xref:cancelling[Cancelling])
* Zählen von Meldungen (xref:counting[Counting])

An dieser Stelle noch ein Tipp: Es gibt Situationen, in denen Sie im regulären Ausdruck
etwas gruppieren müssen, aber *keine* Match-Gruppe erzeugen möchten.
Dies können Sie durch ein `?:` direkt nach der öffnenden Klammer
erreichen. Beispiel: Der Ausdruck `one (pass:[.*]) two (?:.*) three` erzeugt
bei einem Match auf `one 123 two 456 three` nur die eine Match-Gruppe
`123`.

==== IP-Adresse

Im Feld [.guihint]#Match original source IP address#
können Sie auf die IPv4-Adresse des Senders der Meldung matchen.
Geben Sie entweder eine exakte Adresse an oder ein Netzwerk in der
Notation X.X.X.X/Y, also z.B. `192.168.8.0/24`, um alle Adressen
im Netzwerk `192.168.8.`pass:[X] zu matchen.

Beachten Sie, dass der Match auf die IP-Adresse nur dann funktioniert,
wenn die überwachten Systeme direkt an die Event Console senden. Ist noch
ein anderer Syslog-Server dazwischen geschaltet, der die Meldungen weiterleitet,
wird stattdessen dessen Adresse als Absender in der Meldung erscheinen.


[#syslogfacility]
==== Syslog-Priorität und -Facility

Die Felder [.guihint]#Match syslog priority# und [.guihint]#Match syslog facility#
sind ursprünglich von Syslog definierte, standardisierte
Informationen. Intern wird dabei ein 8-Bit-Feld in 5 Bits für die Facility
(ergibt 32 Möglichkeiten) und 3 Bits für die Priority (8 Möglichkeiten)
aufgeteilt.

Die 32 vordefinierten Facilities waren mal für so etwas wie
eine Anwendung gedacht. Nur ist die Auswahl damals nicht sehr zukunftsweisend
gemacht worden. Eine der Facilities ist z.B. `uucp` -- ein Protokoll
das schon in den 90er Jahren des vergangenen Jahrtausends kaum noch
verwendet wurde.

Fakt ist aber, dass jede Meldung, die per Syslog kommt, eine der Facilities
trägt. Teilweise können Sie diese beim Senden auch frei vergeben, um
später darauf gezielt zu filtern. Das ist durchaus nützlich.

Die Verwendung von Facility und Priority hat auch einen Performanceaspekt.
Wenn Sie eine Regel definieren, die sowieso nur auf Meldungen greift, die
alle die gleiche Facility oder Priorität haben, sollten Sie diese zusätzlich
in den Filtern der Regel setzen. Die Event Console kann diese Regeln dann
sehr effizient sofort umgehen, wenn eine Meldung mit abweichenden Werten
eingeht. Je mehr Regeln diese Filter gesetzt haben, desto weniger
Regelvergleiche werden benötigt.

==== Invertieren des Matches

Die Checkbox [.guihint]#Negate match: Execute this rule if the upper conditions are not fulfilled.#
führt dazu, dass die Regel genau dann greift, wenn die Bedingungen _nicht_ alle
erfüllt sind. Dies ist eigentlich nur nützlich im Zusammenhang mit zwei Regelarten
([.guihint]#Rule type# im Kasten [.guihint]#Outcome & Action# der Regel):

* [.guihint]#Do not perform any action, drop this message, stop processing#
* [.guihint]#Skip this rule pack, continue rule execution with next pack#

Zu den Regelpaketen erfahren Sie xref:rulepacks[weiter unten] mehr.


[#outcome]
=== Auswirkung der Regel

==== Regeltyp: Abbrechen oder Event erzeugen

Wenn eine Regel matcht, legt sie fest, was mit der Meldung geschehen
soll. Das geschieht im Kasten [.guihint]#Outcome & Action#:

image::ec_outcome.png[]

Mit dem [.guihint]#Rule type# kann die Auswertung an der Stelle ganz oder für das
aktuelle Regelpaket abgebrochen werden. Gerade die erste Möglichkeit sollten
Sie nutzen, um den größten Teil des nutzlosen „Rauschens“ durch ein
paar gezielte Regeln ganz am Anfang loszuwerden. Nur bei den „normalen“
Regeln werden die anderen Optionen in diesem Kasten überhaupt ausgewertet.

==== Festlegen des Status

Mit [.guihint]#State# legt die Regel den Monitoring-Status des Events fest. In der
Regel wird diese {WARN} oder {CRIT} sein. Regeln, die {OK}-Events erzeugen,
können in Ausnahmen interessant sein, um bestimmte Ereignisse rein informativ
darzustellen. Hier ist dann eine Kombination mit einem automatischen
xref:timing[Herausaltern] dieser Events interessant.

Neben dem Festlegen eines expliziten Status gibt es noch zwei dynamischere Möglichkeiten.
Die Einstellung [.guihint]#(set by syslog)# übernimmt die Einstufung anhand der Syslog-Priorität.
Dies funktioniert allerdings nur, wenn die Meldung bereits vom Absender nutzbar klassifiziert wurde.
Meldungen, die direkt per Syslog empfangen wurden, enthalten eine von acht per RFC
festgelegten Prioritäten, die wie folgt abgebildet werden:

[cols="15,15,15,~"]
|===
|Priorität |ID |Zustand |Definition laut Syslog 

|emerg |0 |{CRIT} |Das System ist unbrauchbar
|alert |1 |{CRIT} |Sofortige Aktion erforderlich
|crit |2 |{CRIT} |Kritischer Zustand
|err |3 |{CRIT} |Fehler
|warning |4 |{WARN} |Warnung
|notice |5 |{OK} |Normal, aber signifikante Information
|info |6 |{OK} |Reine Information
|debug |7 |{OK} |Debug-Meldung
|===


Neben Syslog-Meldungen bieten auch Meldungen aus dem Windows Event Log und Meldungen
aus Textdateien, die bereits mit dem {CMK}-Plugin xref:logwatch[Logwatch] auf dem Zielsystem
klassifiziert wurden, vorbereitete Zustände. Bei SNMP-Traps gibt es diese leider
nicht.

Eine ganze andere Methode ist, die Einstufung der Meldung anhand des
Texts selbst zu machen. Dies geht mit der Einstellung [.guihint]#(set by message text)#:

image::ec_state_by_text.png[]

Der Match auf die hier konfigurierten Texte geschieht erst, nachdem auf [.guihint]#Text to match#
und auf die anderen Regelbedingungen geprüft wurde. Diese müssen Sie also hier
nicht wiederholen.

Falls keines der konfigurierten Patterns gefunden wird, nimmt das Event den Zustand
{UNKNOWN} an.

[#servicelevel]
==== Service-Level

Hinter dem Feld [.guihint]#Service Level# steckt die Idee, dass jeder Host und jeder Service im
Unternehmen eine bestimmte Wichtigkeit hat. Damit kann eine konkrete
Service-Vereinbarung verbunden sein. In {CMK} können Sie per xref:wato_rules#[Regeln]
Ihren Hosts und Services solche Level zuordnen und dann z.B. die Benachrichtigung oder
selbstdefinierte Dashboards davon abhängig machen.

Da Events erst einmal nicht unbedingt mit Hosts oder Services korrelieren, erlaubt
die Event Console, dass Sie einem Event per Regel ebenfalls einen Service-Level
zuordnen. Sie können die Event-Ansichten dann später nach diesem Level filtern.

Ab Werk definiert {CMK} die vier Level 0 (kein Level), 10 (Silber), 20 (Gold)
und 30 (Platin). Diese Auswahl können Sie in den [.guihint]#Global settings > Notifications > Service Levels#
beliebig anpassen. Entscheidend sind hierbei die Zahlen der Levels, dann nach diesen
werden sie sortiert und auch nach der Wichtigkeit verglichen.

[#contactgroups]
==== Kontaktgruppen

Die Kontaktgruppen für die xref:visibility[Sichtbarkeit] werden
auch bei der
xref:notifications[Benachrichtigung] von Events verwendet. Sie können hier per
Regel Events explizit Kontaktgruppen zuordnen. Einzelheiten
erfahren Sie im xref:visibility[Kapitel über das Monitoring].


==== Aktionen

Aktionen sind den xref:alert_handlers#[Alert Handlern] für Hosts und Services sehr ähnlich.
Hier können Sie beim Öffnen eines Events ein selbst definiertes Skript ausführen lassen.
Alle Einzelheiten zu den Aktionen erfahren Sie weiter unten in einem eigenen
xref:actions[Abschnitt].


==== Automatisches Löschen

Das automatische Löschen (= Archivieren), welches Sie mit [.guihint]#Delete event immediately after the actions#
einstellen können, sorgt letztlich dafür, dass ein Event im Monitoring überhaupt nicht
sichtbar wird. Das ist dann sinnvoll, wenn Sie lediglich automatisch Aktionen
auslösen oder nur bestimmte Events archivieren möchten,
damit Sie später danach recherchieren können.


[#rewriting]
=== Automatisches Umschreiben von Texten (Rewriting)

Mit dem [.guihint]#Rewriting# kann eine EC-Regel Textfelder in der Meldung automatisch
umschreiben und Anmerkungen anfügen. Dies wird in einem eigenen Kasten konfiguriert:

image::ec_rewriting.png[]

Beim Umschreiben sind die oben beschriebenen xref:matchgroups[Match-Gruppen] besonders
wichtig. Denn Sie erlauben es, Teile der Originalmeldung gezielt in den neuen
Text einzubauen. Sie können bei den Ersetzungen auf die Gruppen wie folgt zugreifen:

[cols="10,~"]
|===

|`\1` |Wird durch die _erste_ Match-Gruppe der Originalmeldung ersetzt.
|`\2` |Wird durch die _zweite_ Match-Gruppe der Originalmeldung ersetzt (usw.).
|`\0` |Wird durch die _komplette_ Originalmeldung ersetzt.
|===


In obigem Screenshot wird der neue Meldungstext auf `Instance \1 has been shut down.`
gesetzt. Das klappt natürlich nur, wenn beim [.guihint]#Text to match# in der *gleichen* Regel
der reguläre Suchausdruck auch mindestens einen Klammerausdruck hat. Ein Beispiel dafür
wäre z.B.:

image::ec_rewrite_match.png[]

Einige weitere Hinweise zum Umschreiben:

* Das Umschreiben geschieht _nach_ dem Matchen und _vor_ dem Ausführen von Aktionen.
* Match, Umschreiben und Aktionen geschehen immer in der gleichen Regel. Es ist nicht möglich, eine Meldung umzuschreiben, um sie dann mit einer späteren Regel zu bearbeiten.
* Die Ausdrücke `\1`, `\2` usw. können in allen Textfeldern verwendet werden, nicht nur im [.guihint]#Rewrite message text#.


[#cancelling]
=== Automatisches Aufheben von Events (Cancelling)

Manche Anwendungen oder Geräte sind so nett, nach einer Störmeldung
später eine passende OK-Meldung zu senden, sobald das Problem wieder
behoben ist. Sie können die EC so konfigurieren, dass in so einem
Fall das durch die Störung geöffnete Event automatisch wieder
geschlossen wird. Dies nennt man [.guihint]#Aufheben (Cancelling)#.

Folgende Abbildung zeigt eine Regel, in der nach Meldungen mit dem Text `database
instance (pass:[.*]) has failed` gesucht wird. Der Ausdruck `(pass:[.*])` steht
für eine beliebige Zeichenfolge, die in einer xref:matchgroups[Match-Gruppe]
eingefangen wird. Der Ausdruck `database instance (pass:[.*]) recovery in progress`, welcher
im Feld [.guihint]#Text to cancel event(s)# in der gleichen Regel eingetragen ist, sorgt
für ein automatisches Schließen von mit dieser Regel erzeugten Events,
wenn eine passende Meldung eingeht:

image::ec_cancelling.png[]

Das automatische Aufheben funktioniert genau dann, wenn

* eine Meldung eingeht, deren Text auf [.guihint]#Text to cancel event(s)# passt,
* der hier in der Gruppe `(pass:[.*])` eingefangene Wert _identisch_ mit der Match-Gruppe aus der ursprünglichen Meldung ist,
* beide Meldungen vom gleichen Host kamen und
* es sich um die gleiche Anwendung handelt (Feld [.guihint]#Syslog application to cancel event#).

Das Prinzip der Match-Gruppen ist hier sehr wichtig. Denn es wäre schließlich
wenig sinnvoll, wenn die Meldung `database instance TEST recovery in progress` ein
Event aufheben würde, das von der Meldung `database instance PROD has failed`
stammt, oder?

Bitte machen Sie nicht den Fehler, in [.guihint]#Text to cancel events(s)# den Platzhalter
`\1` zu verwenden. Das funktioniert _nicht!_ Diese Platzhalter
funktionieren nur beim xref:rewriting[Rewriting].

In einigen Fällen kommt es vor, dass ein Text sowohl zur _Erzeugung_ als auch
zum _Aufheben_ eines Events passt. In diesem Fall bekommt das _Aufheben_ Priorität.

==== Ausführen von Aktionen beim Aufheben

Sie können beim Aufheben eines Events auch automatisch xref:automatic_actions[Aktionen] ausführen
lassen. Dazu ist es wichtig zu wissen, dass beim Aufheben etliche Datenfelder
des Events von Werten der OK-Meldung überschrieben werden, bevor die
Aktionen ausgeführt werden. Auf diese Art sind im Aktionsskript dann die
Daten der OK-Meldung vollständig verfügbar. Auch ist während dieser
Phase der Zustand des Events als {OK} eingetragen. Auf diese Art kann ein
Aktionsskript ein Aufheben erkennen und Sie können das gleiche Skript
für Fehler und OK-Meldung verwenden (z.B. bei der Anbindung an ein
Ticketsystem).

Folgende Felder werden aus Daten der OK-Meldung überschrieben:

* Der Meldungstext
* Der Zeitstempel
* Die Zeit des letzten Auftretens
* Die Syslog-Priorität

Alle anderen Felder bleiben unverändert -- inklusive der Event-ID.


==== Aufheben in Kombination mit Umschreiben

Falls Sie in der gleichen Regel mit xref:rewriting[Umschreiben] und Aufheben arbeiten,
so sollten Sie vorsichtig sein beim Umschreiben des Host-Namens oder der
Application. Beim Aufheben prüft die EC stets, ob die aufhebende Meldung
zu Host-Name und Anwendung des offenen Events passt. Wenn diese aber umgeschrieben
wurden, würde das Aufheben nie funktionieren.

Daher simuliert die Event Console vor dem Aufheben ein Umschreiben von
Host-Name und Anwendung (_application_), um so die relevanten Texte zu vergleichen. Das
ist wahrscheinlich das, was Sie auch erwarten würden.

Dieses Verhalten können Sie auch ausnutzen, wenn das Anwendungsfeld
bei der Fehlermeldung und der späteren OK-Meldung nicht übereinstimmen!
Schreiben Sie in diesem Fall einfach das Anwendungsfeld in einen bekannten
festen Wert um. Das führt faktisch dazu, dass dieses Feld beim Aufheben
ignoriert wird.


==== Aufheben anhand der Syslog-Priorität

Es gibt (leider) Fälle, in denen der Text der Fehler- und OK-Meldung absolut
identisch ist. Meist ist der eigentliche Status dann nicht im Text, sondern
in der Syslog-Priorität kodiert.

Dazu gibt es die Option [.guihint]#Syslog priority to cancel event#. Geben Sie
hier z.B. den Bereich `debug` ... `notice` an. Alle Prioritäten
in diesem Bereich werden normalerweise als OK-Status gewertet. Bei Verwendung
dieser Option sollten Sie _trotzdem_ in das Feld [.guihint]#Text to cancel event(s)#
einen passenden Text eintragen. Sonst wird die Regel auf alle OK-Meldungen
matchen, welche die gleiche Anwendung betreffen.


[#counting]
=== Zählen von Meldungen

Im Kasten [.guihint]#Counting & Timing# finden Sie Optionen zum Zählen von gleichartigen
Meldungen. Die Idee ist, dass manche Meldungen erst dann relevant sind, wenn
Sie in bestimmten Zeiträumen _zu häufig_ oder _zu selten_ auftreten.

==== Zu häufige Meldungen

Das Prüfen auf zu oft auftretende Meldungen aktivieren Sie
mit der Option [.guihint]#Count messages in interval#:

image::ec_counting.png[]

Hier geben Sie zunächst einen Zeitraum bei [.guihint]#Time period for counting# und
eine Anzahl von Meldungen bei [.guihint]#Count until triggered# vor, die zum
Öffnen eines Events führen sollen. Im Beispiel in der Abbildung ist
das auf 10 Meldungen pro Stunde eingestellt. Natürlich handelt es
sich dabei nicht um 10 beliebige Meldungen, sondern um solche,
die von der Regel gematcht werden.

Normalerweise ist es hier aber sinnvoll, nicht einfach global alle passenden Meldungen
zu zählen, sondern nur diejenigen, die sich auf die gleiche „Ursache“
beziehen. Um das zu steuern, gibt es die drei Checkboxen mit dem Titel
[.guihint]#Force separate events for different ...#.  Diese sind so voreingestellt, dass
Meldungen nur dann zusammengezählt werden, wenn sie übereinstimmen in:

* Host
* Anwendung
* xref:matchgroups[Match-Gruppen]

Damit können Sie Regeln formulieren wie „Wenn vom gleichen Host,
der gleichen Anwendung und dort der gleichen Instanz mehr als 10
Meldungen pro Stunde kommen, dann...“. Dadurch kann es dann
auch sein, dass aufgrund der Regel mehrere unterschiedliche Events
erzeugt werden.

Wählen Sie z.B. alle drei Checkboxen ab, so wird nur noch global
gezählt und die Regel kann auch nur insgesamt ein einziges Event
generieren!

Es kann übrigens durchaus sinnvoll sein, als Anzahl eine 1 einzutragen!
Damit können Sie „Eventstürme“ effektiv in den Griff bekommen. Kommen
z.B. in kurzer Zeit 100 Meldungen der gleichen Art, so wird dafür dann trotzdem
nur ein einziges Event erzeugt. Sie sehen dann in den Event-Details

* den Zeitpunkt des Auftretens der ersten Meldung,
* den Zeitpunkt der jüngsten Meldung und
* die Gesamtzahl an Meldungen, die in diesem Event zusammengefasst sind.

Wann der Fall dann „abgeschlossen“ ist und bei erneuten Meldungen wieder
ein neues Event aufgemacht werden soll, legen Sie über zwei Checkboxen fest.
Normalerweise führt eine Quittierung des Events dazu, dass bei weiteren
Meldungen eine neue Zählung mit einem neuen Event angefangen wird.
Das können Sie mit [.guihint]#Continue counting when event is acknowledged#
abschalten.

Die Option [.guihint]#Discontinue counting after time has elapsed#
sorgt dafür,
dass für jeden Vergleichszeitraum immer ein separates Event geöffnet
wird. In obigem Beispiel war eine Schwelle von 10 Meldungen pro
Stunde eingestellt. Ist diese Option aktiviert, so werden auf ein
bereits geöffnetes Event maximal Meldungen einer Stunde
aufgerechnet. Sobald die Stunde abgelaufen ist, wird (bei ausreichender
Zahl von Meldungen) wieder ein neues Event geöffnet.

Setzen Sie z.B. die Anzahl auf 1 und das Zeitintervall auf einen
Tag, so werden Sie pro Tag von diesem Meldungstyp nur noch maximal
ein Event sehen.

Die Einstellung [.guihint]#Algorithm# ist auf den ersten Blick vielleicht etwas
überraschend. Aber mal ehrlich: Was meint man eigentlich mit „10 Meldungen
pro Stunde“? Welche Stunde ist damit gemeint? Immer volle Stunden der
Tageszeit? Dann könnte es sein, dass in der letzten Minute einer Stunde neun
Meldungen kommen und in der ersten Minute der nächsten nochmal neun. Macht
insgesamt 18 Meldungen in zwei Minuten.  Aber trotzdem weniger als 10 pro
Stunde und die Regel würde nicht greifen. Das klingt nicht so sinnvoll {nbsp}...

Weil es dazu nicht nur eine einzige Lösung gibt, bietet {CMK}
drei verschiedene Definitionen an, was denn „10 Meldungen pro Stunde“
genau bedeuten soll:

[cols="20,~"]
|===
|Algorithmus |Funktionsweise 

|[.guihint]#Interval# |Das Zählintervall startet bei der ersten eingehenden passenden Meldung. Ein Event in der Phase [.guihint]#counting# wird erzeugt. Vergeht nun die eingestellte Zeit, bevor die Anzahl erreicht wird, wird das Event stillschweigend gelöscht. Wird die Anzahl aber schon vor Ablauf der Zeit erreicht, wird das Event _sofort_ geöffnet (und eventuell konfigurierte Aktionen ausgelöst).
|[.guihint]#Token Bucket# |Dieser Algorithmus arbeitet nicht mit festen Zeitintervallen, sondern implementiert ein Verfahren, das bei Netzwerken oft zum Trafficshaping eingesetzt wird.  Angenommen, Sie haben 10 Meldungen pro Stunde konfiguriert. Das sind im Schnitt eine alle 6 Minuten. Wenn zum ersten Mal eine passende Meldung eingeht, wird ein Event in der Phase [.guihint]#counting# erzeugt und die Anzahl auf 1 gesetzt. Bei jeder weiteren Meldung wird diese um 1 erhöht. Und alle 6 Minuten wird der Zähler wieder um 1 _verringert_ -- egal, ob eine Meldung gekommen ist oder nicht. Fällt der Zähler wieder auf 0, wird das Event gelöscht.  Der Trigger wird also dann ausgelöst, wenn die Rate der Meldungen _im Schnitt_ dauerhaft über 10 pro Stunde liegt.
|[.guihint]#Dynamic Token Bucket# |Dies ist eine Variante des [.guihint]#Token Bucket#-Algorithmus, bei der der Zähler umso langsamer verringert wird, je kleiner er gerade ist. In obigem Beispiel würde der Zähler bei Stand von 5 nur alle _12_ statt alle 6 Minuten verringert.  Das führt insgesamt dazu, dass Meldungsraten, die nur knapp über der erlaubten Rate liegen, deutlich schneller ein Event öffnen (und damit benachrichtigt werden).
|===


Welchen Algorithmus sollten Sie also wählen?

* [.guihint]#Interval# ist am einfachsten zu verstehen und leichter nachzuvollziehen, wenn Sie später in Ihrem Syslog-Archiv genau nachzählen möchten.
* [.guihint]#Token Bucket# dagegen ist intelligenter und „weicher“. Es kommt zu weniger Anomalien an den Rändern der Intervalle.
* [.guihint]#Dynamic Token Bucket# macht das System reaktiver und erzeugt schneller Benachrichtigungen.

Events, die die eingestellte Anzahl noch nicht erreicht haben,
sind latent schon vorhanden aber für den Operator nicht
automatisch sichtbar. Sie befinden sich in der Phase [.guihint]#counting#.
Sie können solche Events mit dem Filter [.guihint]#Phase# in der Event-Ansicht
sichtbar machen:

image::ec_phase_filter_counting.png[width=440]

[#expect]
==== Zu seltene oder ausbleibende Meldungen

Genauso wie das Eingehen einer bestimmten Meldung kann auch das
*Ausbleiben* ein Problem bedeuten. Eventuell erwarten Sie pro Tag
mindestens eine Meldung von einem bestimmten Job. Bleibt diese aus, ist der
Job wahrscheinlich nicht gelaufen und sollte dringend repariert werden.

So etwas können Sie unter [.guihint]#Counting & Timing > Expect regular messages#
konfigurieren:

image::ec_expect_messages.png[]

Wie beim Zählen müssen Sie auch hier einen Zeitraum angeben, in dem
Sie die Meldung(en) erwarten. Hier kommt allerdings ein ganz anderer
Algorithmus zur Anwendung, der an dieser Stelle viel sinnvoller ist.
Der Zeitraum wird hier nämlich immer exakt an definierten Stellen
ausgerichtet. So wird z.B. beim Interval [.guihint]#Stunde# immer bei Minute
und Sekunde Null begonnen. Sie haben folgende Optionen:

[cols="25,~"]
|===
|Interval |Ausrichtung 

|[.guihint]#10 seconds# |Bei einer durch 10 teilbaren Sekundenzahl
|[.guihint]#minute# |Auf der vollen Minute
|[.guihint]#5 minutes# |Bei 0:00, 0:05, 0:10, usw.
|[.guihint]#15 minutes# |Bei 0:00, 0:15, 0:30, 0:45, usw.
|[.guihint]#hour# |Auf dem Beginn jeder vollen Stunde
|[.guihint]#day# |Exakt bei 00:00 Uhr, allerdings in einer konfigurierbaren Zeitzone. Damit können Sie auch sagen, dass Sie eine Meldung zwischen 12:00 Uhr und 12:00 Uhr am nächsten Tag erwarten. Wenn Sie selbst z.B. in der Zeitzone [.guihint]#UTC+1# sind, geben Sie dazu [.guihint]#UTC-11# an.
|[.guihint]#two days# |Zu Beginn einer vollen Stunde. Sie können hier einen Zeitzonenoffset von 0 bis 47 angeben, der sich auf 1970-01-01 00:00:00 UTC bezieht.
|[.guihint]#week# |Um 00:00 Uhr am Donnerstag morgen in der Zeitzone UTC plus das Offset, das Sie in Stunden ausgeben können. Donnerstag deswegen, weil der 1.1.1970 -- der Beginn der „Epoche“, an einem Donnerstag war.
|===

Warum ist das so kompliziert? 
Das soll Fehlalarme vermeiden. Erwarten Sie z.B.
eine Meldung vom Backup pro Tag? Sicher wird es leichte Unterschiede in der
Laufzeit des Backups geben, so dass die Meldungen nicht exakt 24 Stunden
auseinander liegen. Erwarten Sie die Meldung z.B. ungefähr gegen Mitternacht
plus/minus ein oder zwei Stunden, so ist ein Intervall von 12:00 bis 12:00 Uhr viel
robuster, als eines von 00:00 bis 00:00 Uhr. Allerdings bekommen Sie dann auch
erst um 12:00 Uhr eine Benachrichtigung, wenn die Meldung ausbleibt.

==== Mehrfaches Auftreten des gleichen Problems

Die Option [.guihint]#Merge with open event# ist so voreingestellt, dass bei einem
mehrfachen hintereinander Ausbleiben der gewünschten Meldung, das bestehende
Event aktualisiert wird. Dies können Sie so umschalten, dass jedes Mal ein
neues Event aufgemacht wird.


[#timing]
=== Timing

Unter [.guihint]#Counting & Timing# gibt es zwei Optionen, welche das Öffnen
bzw. automatische Schließen von Events betreffen.

Die Option [.guihint]#Delay event creation# ist nützlich, wenn Sie mit dem
automatischen xref:cancelling[Aufheben] von Events arbeiten. Setzen
Sie z.B. eine Verzögerung von 5 Minuten, so verharrt bei einer
Störmeldung das so erzeugte Event 5 Minuten im Zustand [.guihint]#delayed# --
in der Hoffnung, dass in dieser Zeit die OK-Meldung eintrifft.
Ist das der Fall, so wird das Event automatisch und ohne Aufhebens
wieder geschlossen und schlägt nicht im Monitoring auf.
Läuft die Zeit aber ab, so wird das Event geöffnet und eventuell
eine dafür definierte Aktion ausgeführt:

image::ec_delay.png[]

In etwa das Gegenteil macht [.guihint]#Limit event lifetime#. Damit können Sie
Events nach einer bestimmten Zeit automatisch schließen lassen. Das ist
z.B. nützlich für informative Events mit {OK}-Status, die Sie zwar
anzeigen möchten, aber für die das Monitoring keine Aktivitäten nach
sich ziehen soll. Durch das automatische „Herausaltern“ sparen Sie sich
das manuelle Löschen solcher Meldungen:

image::ec_limit_livetime.png[]

Durch ein Quittieren wird das Herausaltern erst einmal gestoppt. Dieses Verhalten
können Sie aber mit den beiden Checkboxen nach Bedarf justieren.


[#rulepacks]
=== Regelpakete

Regelpakete haben nicht nur den Sinn, Dinge übersichtlicher zu machen, sondern können
die Konfiguration vieler ähnlicher Regeln auch deutlich vereinfachen und gleichzeitig
die Auswertung beschleunigen.

Angenommen, Sie haben einen Satz von 20 Regeln, die sich alle um
das Windows Event Log [.guihint]#Security# drehen. Alle diese Regeln haben gemeinsam,
dass sie in der Bedingung auf einen bestimmten Text im Anwendungsfeld
prüfen (der Name dieser Log-Datei wird bei den Meldungen von der EC als
[.guihint]#Application# eingetragen). Gehen Sie in so einem Fall wie folgt vor:

. Legen Sie ein eigenes Regelpaket an.
. Legen Sie die 20 Regeln für [.guihint]#Security# in diesem Paket an oder ziehen Sie sie dorthin um (Auswahlliste [.guihint]#Move to pack...# rechts in der Regeltabelle).
. Entfernen Sie aus allen diesen Regeln die Bedingung auf die Anwendung.
. Legen Sie *als erste Regel* in dem Paket eine Regel an, durch die  Meldungen das Paket sofort verlassen, wenn die Anwendung _nicht_ [.guihint]#Security# ist.

Diese Ausschlussregel ist wie folgt aufgebaut:

* [.guihint]#Matching Criteria > Match syslog application (tag)# auf `Security`
* [.guihint]#Matching Criteria > Invert matching# auf [.guihint]#Negate match: Execute this rule if the upper conditions are not fulfilled.#
* [.guihint]#Outcome & Action > Rule type# auf [.guihint]#Skip this rule pack, continue rule execution with next rule pack#

Jede Meldung, die nicht vom Security-Log kommt, wird also bereits von der ersten Regel in diesem
Paket „abgewiesen“. Das vereinfacht nicht nur die weiteren Regeln des Pakets, sondern beschleunigt
auch die Abarbeitungen, da diese in den meisten Fällen gar nicht mehr geprüft werden müssen.


[#actions]
== Aktionen

=== Arten von Aktionen

Die Event Console bietet drei Arten von Aktionen, welche Sie entweder manuell
oder beim Öffnen oder xref:cancelling[Aufheben] von Events ausführen lassen können:

* Ausführen von selbstgeschriebenen Shell-Skripten
* Versenden von selbstdefinierten E-Mails
* Erzeugen von {CMK}-xref:notifications[Benachrichtigungen]


=== Shell-Skripte und E-Mails

E-Mails und Skripte müssen Sie zunächst in den xref:globalsettings[Einstellungen der Event Console] definieren.
Sie finden diese unter dem Eintrag [.guihint]#Actions (E-Mails & Scripts)#:

image::ec_add_action.png[]

==== Shell-Skripte ausführen

Mit dem Knopf [.guihint]#Add new action# legen Sie eine neue Aktion an. Folgendes Beispiel zeigt,
wie Sie ein einfaches Shell-Skript als Aktion vom Typ [.guihint]#Execute Shell Script# anlegen können.
Dem Skript stehen über Umgebungsvariablen Details zu den Events zur Verfügung,
beispielsweise die `$CMK_ID` des Events, der `$CMK_HOST`, Volltext `$CMK_TEXT` oder die erste Match-Gruppe als `$CMK_MATCH_GROUP_1`.
Eine vollständige Liste der verfügbaren Umgebungsvariablen erhalten Sie in der icon:icon_help[] Inline-Hilfe.

image::ec_define_action.png[]

Ältere Versionen von {CMK} haben neben Umgebungsvariablen auch Makros wie
`$TEXT$` erlaubt, die vor Ausführung des Skriptes ersetzt wurden. Wegen der
Gefahr, dass ein Angreifer über ein eigens angefertigtes UDP-Paket Befehle
einschleusen kann, die mit den Rechten des {CMK}-Prozesses ausgeführt werden,
sollten Sie von Makros keinen Gebrauch machen. Makros sind derzeit noch aus
Kompatibilitätsgründen erlaubt, jedoch behalten wir uns die Entfernung in
einer künftigen {CMK}-Version vor.

Das Beispielskript aus dem Screenshot legt im Instanzverzeichnis die
Datei `tmp/test.out` an und schreibt dort einen Text mit den konkreten Werten
der Variablen zu dem jeweils letzten Event:

[{file}]
----
cat << EOF > ${OMD_ROOT}/tmp/test.out
Something happened:

Event-ID: $CMK_ID
Host: $CMK_HOST
Application: $CMK_APPLICATION
Message: $CMK_TEXT
EOF
----

Die Skripte werden unter folgender Umgebung ausgeführt:

* Als Interpreter wird `/bin/bash` verwendet.
* Das Skript läuft als Instanzbenutzer mit dem Home-Verzeichnis der Instanz (z.B. `/omd/sites/mysite`).
* Während der Laufzeit des Skripts ist die Verarbeitung weiterer Events angehalten!

Sollte Ihr Skript eventuell Wartezeiten enthalten, können Sie es mithilfe von Linux' `at`-Spooler
asynchron laufen lassen. Dazu legen Sie das Skript in einer eigenen Datei `local/bin/myaction`
an und starten es mit dem `at`-Befehl, z.B.:

[{file}]
----
echo "$OMD_ROOT/local/bin/myaction '$HOST$' '$TEXT$' | at now
----

==== Versenden von E-Mails

Der Aktionstyp [.guihint]#Send Email# versendet eine einfache Text-E-Mail. Eigentlich könnten
Sie das auch über den Umweg mit einem Skript erreichen, in dem Sie z.B. mit dem
Kommandozeilenbefehl `mail` arbeiten. Aber so ist es komfortabler.
Bitte beachten Sie, dass auch in den Feldern [.guihint]#Recipient E-Mail address# und [.guihint]#Subject#
Platzhalter erlaubt sind.

image::ec_define_action_email.png[]


[#notifications]
=== Benachrichtigung durch {CMK}

Neben dem Ausführen von Skripten und dem Versenden von (einfachen) E-Mails
kennt die EC noch eine dritte Art von Aktion: Das Versenden von Benachrichtigungen über das
{CMK}-xref:notifications#[Benachrichtigungssystem]. Die dabei von der EC erzeugten
Benachrichtigungen gehen den gleichen Weg, wie die Host- und Servicebenachrichtigungen aus
dem aktiven Monitoring. Die Vorteile gegenüber den oben beschriebenen
einfachen E-Mails liegen auf der Hand:

* Die Benachrichtigung wird für aktives und eventbasiertes Monitoring gemeinsam an zentraler Stelle konfiguriert.
* Funktionen wie xref:notifications#bulk[Sammelbenachrichtigungen], HTML-E-Mails und andere nützliche Dinge stehen zur Verfügung.
* Benutzerdefinierte Benachrichtigungsregeln, ein Abschalten der Benachrichtigungen und Ähnliches funktionieren wie gewohnt.

Die Aktionsart [.guihint]#Send monitoring notification#, die das macht, steht immer
automatisch zur Verfügung und muss nicht extra konfiguriert werden.

Da Events von der Natur her einige Unterschiede zu den „normalen“ Hosts oder Services haben,
gibt es ein paar Besonderheiten bei deren Benachrichtigung, welche Sie im Folgenden
genauer kennen lernen.


==== Zuordnung zu bestehenden Hosts

Events können von beliebigen Hosts kommen -- egal, ob diese im aktiven Monitoring
konfiguriert sind oder nicht. Schließlich steht der Syslog- und SNMP-Port
allen Hosts im Netzwerk offen. Daher stehen die erweiterten Host-Attribute wie
Alias, Host-Merkmale, Kontakte usw. erst einmal nicht zur Verfügung. Das
bedeutet insbesondere, dass _Bedingungen_ in Benachrichtigungsregeln nicht
unbedingt so funktionieren, wie Sie das erwarten würden.

Daher versucht die EC bei der Benachrichtigung
einen zum Event passenden Host aus dem aktiven Monitoring zu finden.
Dabei wird das gleiche Verfahren wie bei der xref:visibility[Sichtbarkeit von Events]
angewandt.  Kann so ein Host gefunden werden, so werden von diesem
folgende Daten übernommen:

* Die korrekte Schreibweise des Host-Namens
* Der Host-Alias
* Die in {CMK} konfigurierte primäre IP-Adresse
* Die Host-Merkmale (_host tags_)
* Der Ordner in der Setup-GUI
* Die Liste der Kontakte und Kontaktgruppen

Dadurch kann es dazu kommen, dass der Host-Name in der Benachrichtigung nicht exakt mit
dem Host-Namen aus der ursprünglichen Meldung übereinstimmt. Die Anpassung auf die
Schreibweise des aktiven Monitorings vereinfacht aber das Formulieren von
einheitlichen Benachrichtigungsregeln, welche Bedingungen auf den Host-Namen enthalten.

Die Zuordnung geschieht in Echtzeit durch eine xref:livestatus#[Livestatus]-Abfrage an den
Monitoring-Kern, welcher in der gleichen Instanz wie die EC läuft, die die
Meldung empfangen hat. Das klappt natürlich nur, wenn die Syslog-Meldungen,
SNMP-Traps usw. immer an diejenige {CMK}-Instanz gesendet werden, auf
der der Host auch aktiv überwacht wird!

Falls die Abfrage nicht klappt oder der Host nicht gefunden werden kann, werden Ersatzdaten
angenommen:

[cols="25,~"]
|===

|[.guihint]#Hostname# |Der Host-Name aus dem Event.
|[.guihint]#Hostalias# |Als Alias wird der Host-Name verwendet.
|[.guihint]#IP-Adresse# |Das Feld IP-Adresse enthält die originale Absenderadresse der Meldung.
|[.guihint]#Hostmerkmale# |Der Host erhält kein Host-Merkmal. Falls Sie Host-Merkmalsgruppe mit leeren Merkmalen haben, nimmt der Host dort diese Merkmale an. Ansonsten hat er kein Merkmal der Gruppe. Bitte beachten Sie das, wenn Sie in den Benachrichtigungsregeln Bedingungen über Host-Merkmale definieren.
|[.guihint]#Setup-GUI Ordner# |Kein Ordner. Sämtliche Bedingungen, die auf einen bestimmten Ordner gehen, sind damit unerfüllbar -- selbst wenn es sich um den Hauptordner handelt.
|[.guihint]#Kontakte# |Die Liste der Kontakte ist leer. Sind Fallback-Kontakte vorhanden, werden diese eingetragen.
|===

Wenn der Host im aktiven Monitoring nicht zugeordnet werden kann, kann
das natürlich zu Problemen bei der Benachrichtigung führen.  Zum einen wegen
der Bedingungen, die dann evtl. nicht mehr greifen, zum anderen wegen der
Kontaktauswahl. Für solche Fälle können Sie Ihre Benachrichtigungsregeln so
anpassen, dass Benachrichtigungen aus der Event Console mit einer eigenen Regel gezielt
behandelt werden. Dazu gibt es eine eigene Bedingung, mit der Sie entweder
positiv nur auf EC-Benachrichtigungen matchen oder umgekehrt diese ausschließen können:

image::ec_notification_condition.png[]


==== Restliche Felder der Benachrichtigung

Damit Benachrichtigungen aus der EC das Benachrichtigungssystem des aktiven Monitorings
durchlaufen können, muss sich die EC an dessen Schema anpassen. Dabei werden
die typischen Datenfelder einer Monitoring-Benachrichtigung so sinnvoll wie möglich
gefüllt. Wie die Daten des Hosts ermittelt werden, haben wir gerade beschrieben.
Weitere Felder sind:


[cols="25,~"]
|===

|[.guihint]#Benachrichtigungstyp# |EC-Benachrichtigungen gelten immer als _Servicenachricht._
|[.guihint]#Service description# |Hier wird der Inhalt des Felds [.guihint]#Application# aus dem Event eingetragen. Falls das leer ist, wird „`Event Console`“ eingetragen.
|[.guihint]#Benachrichtigungsnummer# |Diese ist fest auf `1` eingestellt. Damit ist hier auch keine Eskalation möglich. Selbst mehrere aufeinanderfolgende Events der gleichen Art geschehen voneinander unabhängig. Aktuell unterstützt die EC keine wiederholte Benachrichtigung für den Fall, dass ein Event nicht quittiert wird.
|[.guihint]#Datum/Uhrzeit# |Bei Events, die xref:counting[zählen], ist das der Zeitpunkt des _letzten_ Auftretens einer zum Event gehörigen Meldung.
|[.guihint]#Pluginoutput# |Der Textinhalt des Events.
|[.guihint]#Servicezustand# |Zustand des Events, also {OK}, {WARN}, {CRIT} oder {UNKNOWN}.
|[.guihint]#Vorheriger Zustand# |Da Events keinen früheren Status haben, wird hier bei normalen Events immer {OK}, beim xref:cancelling[Aufhebung eines Events] immer {CRIT} eingetragen. Diese Regelung kommt dem am nächsten, was man für Benachrichtigungsregeln braucht, die eine Bedingung auf den genauen Zustandswechsel haben.
|===

==== Kontaktgruppen manuell festlegen

Wie oben beschrieben, können zu einem Event eventuell nicht die
passenden Kontakte automatisch ermittelt werden. Für solche Fälle
können Sie
direkt in der EC-Regel Kontaktgruppen angeben, welche für die Benachrichtigung
verwendet werden sollen. Wichtig ist, dass Sie den Haken
bei [.guihint]#Use in notifications# nicht vergessen:

image::ec_set_contact_groups.png[]


==== Globale Schalter für Benachrichtigungen

Im Snapin [.guihint]#Master control# gibt es einen zentralen Schalter für Benachrichtigungen.
Dieser gilt auch für
Benachrichtigungen, die von der EC weitergeleitet werden:

image::master_control_notifications_off.png[width=400]

Ebenso wie die Host-Zuordnung erfordert die Abfrage des Schalters durch die
EC einen Livestatus-Zugriff auf den lokalen Monitoring-Kern. Eine erfolgreiche
Abfrage sehen Sie in der Log-Datei der Event Console:

.var/log/mkeventd.log
[{file}]
----
[1482142567.147669] Notifications are currently disabled. Skipped notification for event 44
----


==== Wartungszeiten von Hosts

Die Event Console erkennt Hosts, die gerade in
einer xref:basics_downtimes#[Wartungszeit] sind und versendet in diesem Fall keine
Benachrichtigungen. In der Log-Datei sieht das so aus:

.var/log/mkeventd.log
[{file}]
----
[1482144021.310723] Host myserver123 is currently in scheduled downtime. Skipping notification of event 433.
----

Auch das setzt natürlich ein erfolgreiches Finden des Hosts im aktiven
Monitoring voraus. Falls dies nicht gelingt, wird angenommen, dass sich der
Host _nicht_ in Wartung befindet und die Benachrichtigung auf jeden Fall generiert.


==== Zusätzliche Makros

Falls Sie ein eigenes xref:notifications#scripts[Benachrichtigungsskript] schreiben, haben Sie
speziell bei Benachrichtigungen, die aus der Event Console kommen, etliche zusätzliche Variablen
zur Verfügung, die den ursprünglichen Event beschreiben (Zugriff wie gewohnt mit
Präfix `NOTIFY_`):


[cols="25,~"]
|===

|`EC_ID` |Event-ID.
|`EC_RULE_ID` |ID der Regel, die das Event erzeugt hat.
|`EC_PRIORITY` |Syslog-Priorität als Zahl von `0` (`emerg`) bis `7` (`debug`).
|`EC_FACILITY` |Syslog Facility -- ebenfalls als Zahl. Der Wertebereich geht von `0` (`kern`) bis `32` (`snmptrap`).
|`EC_PHASE` |Phase des Events. Da nur offene Events Aktionen auslösen, sollte hier `open` stehen. Bei einer manuellen Benachrichtigung eines bereits quittierten Events steht hier `ack`.
|`EC_COMMENT` |Das Kommentarfeld der Events.
|`EC_OWNER` |Das Feld [.guihint]#Owner#.
|`EC_CONTACT` |Das Kommentarfeld mit der Event-spezifischen Kontaktinformation.
|`EC_PID` |Die ID des Prozesses, der die Meldung gesendet hat (bei Syslog-Events).
|`EC_MATCH_GROUPS` |Die Match-Gruppen vom Matchen in der Regel.
|`EC_CONTACT_GROUPS` |Die optional manuell in der Regel definierten Kontaktgruppen.
|===


[#automatic_actions]
=== Aktionen ausführen

Das manuelle Ausführen von Aktionen durch den Operator haben Sie schon weiter
oben bei den xref:commands[Kommandos] gesehen. Spannender ist das automatische
Ausführen von Aktionen, welches Sie in EC-Regeln im Abschnitt [.guihint]#Outcome & Action#
konfigurieren können:

image::ec_rule_actions.png[]

Hier können Sie eine oder mehrere Aktionen auswählen, die immer dann ausgeführt
werden, wenn aufgrund der Regel ein Event _geöffnet_ oder xref:cancelling[aufgehoben]
wird. Bei Letzterem können Sie über die Auswahlbox [.guihint]#Do cancelling actions#
noch festlegen, ob die Aktion nur dann ausgeführt werden soll, wenn das aufgehobene
Event schon die Phase [.guihint]#open# erreicht hat. Bei Verwendung von xref:counting[Zählen]
oder xref:timing[Verzögerung] kann es nämlich dazu kommen, dass Events aufgehoben
werden, die quasi noch im Wartezustand und für den Benutzer noch nicht sichtbar
waren.

Die Ausführung von Aktionen wird in der Log-Datei `var/log/mkeventd.log` vermerkt:

.var/log/mkeventd.log
[{file}]
----
[1481120419.712534] Executing command: ACTION;1;cmkadmin;test
[1481120419.718173]   Exitcode: 0
----

Auch in das xref:archive[Archiv] werden diese geschrieben.


[#snmp]
== SNMP-Traps

=== Empfang von SNMP-Traps aufsetzen

Da die Event Console eine eingebaute eigene SNMP-Engine hat, ist das Aufsetzen
des Empfangs von SNMP-Traps sehr einfach. Sie benötigen keinen `snmptrapd` vom Betriebssystem!
Falls Sie diesen bereits am Laufen haben, so beenden Sie ihn bitte.

Wie im Abschnitt über das xref:setup[Aufsetzen] der Event Console beschrieben,
aktivieren Sie mit `omd config` den Trap-Empfänger in dieser
Instanz:

image::ec_config_traps.png[width=360]

Da auf jedem Server der UDP-Port für die Traps nur von einem Prozess verwendet
werden kann, darf das pro Rechner nur in einer einzigen {CMK}-Instanz
gemacht werden. Beim Start der Instanz können Sie in der Zeile mit `mkeventd` kontrollieren, ob der
Trap-Empfang eingeschaltet ist:

[{shell}]
----
{c-omd} omd start
Creating temporary filesystem /omd/sites/mysite/tmp...[green]#OK#
Starting mkeventd (builtin: snmptrap)...OK
Starting liveproxyd...OK
Starting mknotifyd...OK
Starting rrdcached...OK
Starting cmc...OK
Starting apache...OK
Starting dcd...OK
Starting redis...OK
Initializing Crontab...OK
----

Damit SNMP-Traps funktionieren, müssen sich Sender und Empfänger auf bestimmte
[.guihint]#Credentials# einigen. Im Fall von SNMP Version 1 und 2c ist das ein
einfaches Passwort, was hier „Community“ genannt wird. Bei Versi  on 3 benötigen
Sie ein paar mehr Angaben. Diese Credentials konfigurieren Sie in den xref:globalsettings[Einstellungen der Event Console] 
unter [.guihint]#Credentials for processing SNMP traps#.
Dabei können Sie mit dem Knopf [.guihint]#Add new element# mehrere unterschiedliche
Credentials einrichten, welche von den Geräten alternativ verwendet werden
können:

image::ec_trap_credentials.png[]

Der weitaus aufwendigere Teil ist es jetzt natürlich, bei allen Zielgeräten, die
überwacht werden sollen, die Zieladresse für Traps einzutragen und auch hier
die Credentials zu konfigurieren.

=== Testen

Leider bieten die wenigsten Geräte sinnvolle Testmöglichkeiten.
Immerhin können Sie den Empfang der Traps durch die Event Console selbst recht
einfach von Hand testen, indem Sie -- am besten von einem anderen Linux-Rechner
aus -- eine Test-Trap senden. Dies geht mit dem Befehl `snmptrap`.
Folgendes Beispiel sendet eine Trap an `192.168.178.11`. Der eigene
Host-Name wird nach dem `.1.3.6.1` angegeben und muss auflösbar sein
oder als IP-Adresse (hier `192.168.178.30`) angegeben werden:

[{shell}]
----
{c-user} snmptrap -v 1 -c public 192.168.178.11 .1.3.6.1 192.168.178.30 6 17 '' .1.3.6.1 s "Just kidding"
----

Falls Sie in den Einstellungen das [.guihint]#Log level# auf [.guihint]#Verbose logging# eingestellt haben,
können Sie den Empfang und die Auswertung der Traps in der Log-Datei der EC sehen:

.var/log/mkeventd.log
[{file}]
----
[1482387549.481439] Trap received from 192.168.178.30:56772. Checking for acceptance now.
[1482387549.485096] Trap accepted from 192.168.178.30 (ContextEngineId "0x80004fb8054b6c617070666973636816893b00", ContextName "")
[1482387549.485136] 1.3.6.1.2.1.1.3.0                        = 329887
[1482387549.485146] 1.3.6.1.6.3.1.1.4.1.0                    = 1.3.6.1.0.17
[1482387549.485186] 1.3.6.1.6.3.18.1.3.0                     = 192.168.178.30
[1482387549.485219] 1.3.6.1.6.3.18.1.4.0                     =
[1482387549.485238] 1.3.6.1.6.3.1.1.4.3.0                    = 1.3.6.1
[1482387549.485258] 1.3.6.1                                  = Just kidding
----

Bei falschen Credentials sehen Sie nur eine einzige Zeile:

.var/log/mkeventd.log
[{file}]
----
[1482387556.477364] Trap received from 192.168.178.30:56772. Checking for acceptance now.
----

Und so sieht ein Event aus, das von solch einer Trap erzeugt wurde:

image::ec_trap_event.png[]

=== Aus Zahlen werden Texte: Traps übersetzen

SNMP ist ein binäres Protokoll und sehr sparsam mit textuellen Beschreibungen
der Meldungen. Um welche Art von Traps es sich handelt, wird intern durch
Folgen von Zahlen in sogenannten OIDs übermittelt. Diese werden als durch
Punkte getrennte Zahlenfolgen angezeigt (z.B. `1.3.6.1.6.3.18.1.3.0`).

Mithilfe von sogenannten MIB-Dateien kann die Event Console diese Zahlenfolgen
in Texte übersetzen. So wird dann aus `1.3.6.1.6.3.18.1.3.0` z.B.
der Text `SNMPv2-MIB::sysUpTime.0`.

Die Übersetzung der Traps schalten Sie in den Einstellungen der Event Console
ein:

image::ec_translate_traps.png[]

Die Test-Trap von oben erzeugt jetzt einen etwas anderen Event:

image::ec_trap_event_translated.png[]

Haben Sie die Option [.guihint]#Add OID descriptions# aktiviert, wird das Ganze
wesentlich umfangreicher -- und unübersichtlicher. Es hilft aber besser zu verstehen,
was ein Trap genau bedeutet:

image::ec_trap_event_translated2.png[]

=== Hochladen eigener MIBs

Leider haben sich die Vorteile von Open Source bei den Autoren von MIB-Dateien
noch nicht herumgesprochen, und so sind wir vom {CMK}-Projekt leider
nicht in der Lage, herstellerspezifische MIB-Dateien mit auszuliefern. Nur
eine kleine Sammlung von freien Basis-MIBs ist vorinstalliert und sorgt
z.B. für eine Übersetzung von `sysUpTime`.

Sie können aber in der Event Console im Modul
[.guihint]#SNMP MIBs for trap translation# mit dem Menü-Eintrag 
icon:icon_new[] [.guihint]#Add one or multiple MIBs# eigene
MIB-Dateien hochladen, wie das hier mit einigen MIBs 
von _Netgear Smart Switches_
geschehen ist:

image::ec_mibs_for_translation.jpg[]

Hinweise zu den MIBs:

* Die hochgeladenen Dateien werden unter `local/share/snmp/mibs` abgelegt. Dort können Sie sie auch von Hand ablegen, wenn Ihnen der Weg über die GUI zu umständlich ist.
* Anstelle von Einzeldateien können Sie auch ZIP-Dateien mit MIBs-Sammlungen in einem Rutsch hochladen.
* MIBs haben untereinander Abhängigkeiten. Fehlende MIBs werden Ihnen von {CMK} angezeigt.
* Die hochgeladenen MIBs werden auch auf der Kommandozeile von `cmk --snmptranslate` verwendet.


[#logwatch]
== Überwachen von Log-Dateien

Der {CMK}-Agent ist in der Lage, Log-Dateien über das [.guihint]#Logwatch#-Plugin 
auszuwerten. Dieses Plugin bietet zunächst einmal eine eigene von der
Event Console unabhängige Überwachung von Log-Dateien -- inklusive der Möglichkeit, Meldungen direkt im Monitoring zu quittieren. 
Es gibt aber auch die Möglichkeit, die vom Plugin gefundenen
Meldungen 1:1 in die Event Console weiterzuleiten.

Beim Windows-Agenten ist die Log-Dateiüberwachung fest integriert -- in Form
eines Plugins für die Auswertung von Textdateien und eines für die von
Windows Event Logs. Für Linux und Unix steht das in Python geschriebene
Plugin `mk_logwatch` bereit. Alle drei können Sie über die
xref:wato_monitoringagents#bakery[Agentenbäckerei] aufsetzen bzw. konfigurieren. Verwenden Sie
dazu folgende Regelsätze:

* [.guihint]#Text logfiles (Linux, Solaris, Windows)#
* [.guihint]#Finetune Windows Eventlog monitoring#

Die genaue Konfiguration des Logwatch-Plugins ist nicht Thema dieses Artikels.
Wichtig ist allerdings, dass Sie nach wie vor im Logwatch-Plugin selbst bereits
eine möglichst gute Vorfilterung der Meldungen vornehmen und nicht einfach
die kompletten Inhalte der Textdateien zur Event Console senden.

Bitte verwechseln Sie das nicht mit der _nachträglichen_
Umklassifizierung über den Regelsatz [.guihint]#Logfile patterns#. Diese kann
lediglich den Status von Meldungen ändern, die bereits vom Agenten gesendet
wurden. Sollten Sie diese Patterns aber schon eingerichtet haben und möchten
einfach nur von Logwatch auf die Event Console umstellen, so können Sie
die Patterns beibehalten. Dazu gibt es bei den Regeln für die Weiterleitung ([.guihint]#Logwatch Event Console Forwarding#) die Option
[.guihint]#Reclassify messages before forwarding them to the EC#. 

In diesem
Fall gehen alle Meldungen durch insgesamt *drei* Regelketten: auf
dem Agenten, durch die Reklassifizierung und in der Event Console!

Stellen Sie Logwatch nun so um, dass die von den Plugins gefunden
Meldungen nicht mehr mit dem normalen Logwatch-Check überwacht,
sondern einfach 1:1 in die Event Console weitergeleitet und dort
verarbeitet werden. Dazu dient der Regelsatz
[.guihint]#Logwatch Event Console Forwarding#:

image::ec_logwatch_forwarding.png[]

Dazu einige Hinweise:

Falls Sie eine verteilte Umgebung haben, bei der nicht in jeder Instanz eine eigene
Event Console läuft, müssen
die Remote-Instanzen die Meldungen an die zentrale Konsole per Syslog weiterleiten.
Der Default dafür ist UDP. Das ist aber kein abgesichertes Protokoll. Besser ist,
Sie verwenden Syslog via TCP, welches Sie das allerdings in der Zentrale xref:setup[aktivieren]
müssen (`omd config`).

Bei der Weiterleitung geben Sie eine beliebige [.guihint]#Syslog facility# an. Anhand dieser
können Sie in der EC dann leicht die weitergeleiteten Meldungen erkennen. Gut
geeignet sind dafür `local0` bis `local7`.

Mit [.guihint]#List of expected logfiles# können Sie die Liste der gefundenen Log-Dateien
überwachen lassen und werden so gewarnt, wenn bestimmte erwartete Dateien gar nicht
gefunden werden.

*Wichtig:* Das Speichern der Regeln alleine bewirkt noch nichts. Diese Regel
wird lediglich bei der Service-Erkennung aktiv. Erst wenn Sie diese neu durchführen,
werden die bisherigen Logwatch-Services entfernt, und anstelle dessen wird pro Host _ein_
neuer Service mit dem Namen [.guihint]#Log Forwarding# erzeugt.

image::ec_log_forwarding_check.png[]

Dieser Check zeigt Ihnen später auch an, ob es beim Weiterleiten an die
Event Console zu irgendwelchen Problemen kommen sollte.

=== Service-Level und Syslog-Priorität

Da weitergeleitete Log-Dateien je nach verwendetem Format oft die Syslog-Klassifizierung fehlt, 
können Sie die Neu-Klassifizierung im Regelsatz
[.guihint]#Logwatch Event Console Forwarding# unter [.guihint]#Log Forwarding# vornehmen.
Zudem ist in den Regelsätzen, die Sie als Teil von [.guihint]#Rule packs# definieren, immer das individuelle 
xref:outcome[Setzen von Status und Service-Level] möglich.

[#eventsgostate]
== Event-Status im aktiven Monitoring sehen

Wenn Sie auch im aktiven Monitoring sehen möchten, zu welchen Hosts aktuell
problematische Events offen sind, können Sie pro Host einen
xref:active_checks#[aktiven Check] hinzufügen lassen, welcher dessen aktuellen Event-Status zusammenfasst.
Bei einem Host ohne offene Events sieht das dann so aus:

image::ec_events_check_none.png[]

Sind nur Events im Zustand {OK} vorhanden, so zeigt der Check deren Anzahl, bleibt
aber immer noch grün:

image::ec_events_check_ok.png[]

Hier ist ein Fall mit offenen Events im Zustand {CRIT}:

image::ec_events_check_crit.png[]

Diesen aktiven Check erzeugen Sie durch eine Regel im Regelsatz
[.guihint]#Check event state in Event Console.#
Dabei können Sie auch angeben, ob bereits quittierte Events noch zum Status
beitragen sollen oder nicht:

image::ec_check_remote.png[]

Über die Option [.guihint]#Application (regular expression)# können Sie den Check
auf solche Events einschränken, die einen bestimmten Text im Anwendungsfeld haben.
In diesem Fall kann es dann Sinn machen, mehr als einen Events-Check auf einem
Host zu haben und die Checks nach Anwendungen zu trennen. Damit sich diese
Services vom Namen unterscheiden, benötigen Sie dabei dann noch die Option
[.guihint]#Item (used in service description)#, welche einen von Ihnen festgelegten Text
in den Namen des Services einbaut.

Falls Ihre Event Console nicht auf der gleichen {CMK}-Instanz läuft, von
der auch der Host überwacht wird, brauchen Sie unter [.guihint]#Access to Event Console#
einen Remote-Zugriff per TCP:

image::ec_events_check.png[]

Damit dies funktioniert, muss die Event Console den Zugriff per TCP erlauben.
Dies können Sie in den xref:globalsettings[Einstellungen der Event Console] konfigurieren, auf die zugegriffen werden soll:

image::ec_remote_access.png[]


[#archive]
== Das Archiv

=== Funktionsweise

Die Event Console führt ein Protokoll von allen Änderungen, die ein Event
durchläuft. Dieses finden Sie über zwei Wege:

* In der globalen Ansicht [.guihint]#Recent event history#, die Sie in [.guihint]#Monitor > Event Console# finden
* Bei den Details eines Events mit dem Menüeintrag [.guihint]#Event Console Event > History of Event#

In der globalen Ansicht greift ein Filter, der nur die Ereignisse
der letzten 24 Stunden zeigt. Sie können die Filter aber wie gewohnt anpassen.

Folgende Abbildung zeigt die Historie von Event 5976, welches insgesamt
vier Änderungen erfahren hat. Zuerst wurde das Event erzeugt (`NEW`),
dann der Zustand manuell von {OK} auf {CRIT} geändert (`CHANGESTATE`),
dann wurde quittiert und ein Kommentar hinzugefügt (`UPDATE`) und
schließlich archiviert/gelöscht (`DELETE`):

image::ec_history.png[]

Es gibt im Archiv folgende Aktionstypen, die in der Spalte [.guihint]#Action# angezeigt werden:

[cols="20,~"]
|===
|Aktionstyp |Bedeutung

|NEW |Das Event wurde neu erzeugt (aufgrund einer Meldung oder aufgrund einer Regel, welche eine Meldung erwartet, die ausgeblieben ist).
|UPDATE |Das Event wurde durch den Operator editiert (Änderung an Kommentar, Kontaktinfo, Quittierung).
|DELETE |Das Event wurde archiviert.
|CANCELLED |Das Event wurde durch eine OK-Meldung automatisch xref:cancelling[aufgehoben].
|CHANGESTATE |Der Zustand des Events wurde durch den Operator geändert.
|ARCHIVED |Das Event wurde automatisch archiviert, da keine Regel gegriffen hat und in den globalen Einstellungen [.guihint]#Force message archiving# aktiviert war.
|ORPHANED |Das Event wurde automatisch archiviert, da, während es in der Phase [.guihint]#counting# war, die zugehörige Regel gelöscht wurde.
|COUNTREACHED |Das Event wurde von [.guihint]#counting# nach [.guihint]#open# gesetzt, weil die konfigurierte Anzahl von Meldungen erreicht wurde.
|COUNTFAILED |Das Event wurde automatisch archiviert, da in der Phase [.guihint]#counting# die erforderliche Anzahl von Meldungen nicht erreicht wurde.
|NOCOUNT |Das Event wurde automatisch archiviert, da, während es in der Phase [.guihint]#counting# war, die zugehörige Regel so umgestellt wurde, dass sie nicht mehr zählt.
|DELAYOVER |Das Event wurde geöffnet, da die in der Regel konfigurierte xref:timing[Verzögerung] abgelaufen ist.
|EXPIRED |Das Event wurde automatisch archiviert, da seine konfigurierte xref:timing[Lebenszeit] abgelaufen ist.
|EMAIL |Eine E-Mail wurde versendet.
|SCRIPT |Eine automatische Aktion (Skript) wurde ausgeführt.
|AUTODELETE |Das Event wurde direkt nach dem Öffnen sofort automatisch archiviert, da dies in der entsprechenden Regel so konfiguriert war.
|===


=== Speicherort des Archivs

Wie eingangs erwähnt, ist die Event Console nicht als vollwertiges Syslog-Archiv
konzipiert.  Um die Implementierung und vor allem die Administration so einfach
wie möglich zu halten, wurde auf ein Datenbank-Backend verzichtet. Anstelle
dessen wird das Archiv in simple Textdateien geschrieben.  Jeder Eintrag
besteht aus einer Zeile Text, welche durch Tabulatoren getrennte Spalten
enthält.  Sie finden die Dateien in `var/mkeventd/history`:

[{shell}]
----
{c-omd} ll var/mkeventd/history/
total 1328
-rw-rw-r-- 1 stable stable     131 Dez  4 23:59 1480633200.log
-rw-rw-r-- 1 stable stable 1123368 Dez  5 23:39 1480892400.log
-rw-rw-r-- 1 stable stable  219812 Dez  6 09:46 1480978800.log
----

Per Default wird jeden Tag automatisch eine neue Datei begonnen. In den
xref:globalsettings[Einstellungen der Event Console] können Sie die Rotation
anpassen. Die Einstellung [.guihint]#Event history logfile rotation# ermöglicht
das Umstellen auf eine wöchentliche Rotation.

Der Name der Dateien entspricht dem Unix-Zeitstempel vom Zeitpunkt
der Erzeugung der Datei (Sekunden seit dem 1.1.1970 UTC).

Die Dateien werden 365 Tage aufbewahrt, sofern Sie das nicht in der Einstellung
[.guihint]#Event history lifetime# umstellen. Zudem werden die Dateien auch
vom zentralen Plattenplatzmanagement von {CMK} erfasst, welches Sie
in den globalen Einstellungen unter [.guihint]#Site management# konfigurieren
können. Dabei gilt die jeweils _kürzere_ eingestellte Frist.
Das globale Management hat den Vorteil, dass es automatisch bei Knappheit
von Plattenplatz alle historischen Daten von {CMK} *gleichmäßig*
beginnend mit den ältesten löschen kann.

Wenn Sie in Platzprobleme laufen sollten, können Sie die Dateien
in dem Verzeichnis auch einfach von Hand löschen oder auslagern.
Legen Sie jedoch keine gezippten oder irgendwelche anderen Dateien
in diesem Verzeichnis ab.


=== Automatisches Archivieren

Trotz der Limitierung durch die Textdateien ist es theoretisch möglich,
in der Event Console sehr viele Meldungen zu archivieren. Das Schreiben
in die Textdateien des Archivs ist sehr performant -- allerdings auf
Kosten einer späteren Recherche. Da die Dateien als einzigen Index
den Anfragezeitraum haben, müssen bei jeder Anfrage alle relevanten
Dateien komplett gelesen und durchsucht werden.

Normalerweise wird die EC nur solche Meldungen ins Archiv schreiben,
für die auch wirklich ein Event geöffnet wird. Sie können das auf
zwei verschieden Arten auf _alle_ Events ausweiten:

. Sie erzeugen eine Regel, die auf alle (weiteren) Events matcht und aktiveren in [.guihint]#Outcome & actions# die Option [.guihint]#Delete event immediately after the actions#.
. Sie aktivieren in den Einstellungen der Event Console den Schalter [.guihint]#Force message archiving#.

Letzterer sorgt dafür, dass Meldungen, auf die keine Regel greift, trotzdem
ins Archiv wandern (Aktionstyp `ARCHIVED`).


[#tuning]
== Performance und Tuning

=== Verarbeitung von Meldungen

Auch in Zeiten, da Server 64 Kerne und 2 TB Hauptspeicher haben, spielt
Performance von Software noch eine Rolle. Speziell bei der Verarbeitung
von Events kommt hinzu, dass bei nicht ausreichender Leistung bei der
Verarbeitung im Extremfall eingehende Meldungen verloren gehen können.

Der Grund ist, dass keines der verwendeten Protokolle (Syslog, SNMP-Traps,
etc.)  eine Flusskontrolle vorsieht. Wenn tausende Hosts gleichzeitig im
Sekundentakt munter drauf los senden, dann hat der Empfänger keinerlei
Chance, diese auszubremsen.

Deswegen ist es in etwas größeren Umgebungen wichtig, dass Sie ein Auge darauf
haben, wie lang die Verarbeitungszeit für eine Meldung ist. Dies hängt
natürlich ganz wesentlich davon ab, wie viele Regeln Sie definiert haben
und wie diese aufgebaut sind.

[#ecperformance]
==== Messen der Performance

Zum Messen Ihrer Performance gibt es ein eigenes Snapin für die
xref:user_interface#sidebar[Seitenleiste] mit dem Namen [.guihint]#Event Console Performance#.
Dieses können Sie wie gewohnt mit icon:button_sidebar_add_snapin[] einbinden:

image::ec_performance.png[width=400]

Die hier dargestellten Werte sind Mittelwerte über etwa die letzte Minute.
Einen Event-Sturm, der nur ein paar Sekunden dauert, können Sie hier also
nicht direkt ablesen, aber dadurch sind die Zahlen etwas geglättet und daher
besser zu lesen.

Um die maximale Performance zu testen, können Sie künstlich einen Sturm
von unklassifizierten Meldungen erzeugen (bitte nur im Testsystem!), indem
Sie z.B. in einer Shell-Schleife fortwährend den Inhalt einer Textdatei in
die Events-Pipe schreiben:

[{shell}]
----
{c-omd} while true ; do cat /etc/services > tmp/run/mkeventd/events ; done
----

Die wichtigsten Messwerte aus dem Snapin haben folgende Bedeutung:

[cols="30,~"]
|===
|Wert |Bedeutung 

|[.guihint]#Received messages# |Anzahl der aktuell pro Sekunde eingehenden Meldungen.
|[.guihint]#Rule tries# |Anzahl der Regeln, die ausprobiert werden. Dies liefert wertvolle Informationen über die Effizienz der Regelkette -- vor allem zusammen mit dem nächsten Parameter.
|[.guihint]#Rule hits# |Anzahl der Regeln, die aktuell pro Sekunde _greifen_. Dies können auch Regeln sein, die Meldungen verwerfen oder einfach nur zählen. Daher resultiert nicht aus jedem Regeltreffer auch ein Event.
|[.guihint]#Rule hit ratio# |Das Verhältnis aus [.guihint]#Rule tries# und [.guihint]#Rule hits#. Mit anderen Worten: Wie viele Regeln muss die EC ausprobieren, bis (endlich) eine greift. In dem Beispiel aus dem Screenshot ist die Rate bedenklich klein.
|[.guihint]#Created events# |Anzahl der Events, die pro Sekunde neu erzeugt werden. Da die Event Console ja nur _relevante Probleme_ anzeigen soll (also vergleichbar mit Host- und Serviceprobleme aus dem Monitoring), wäre in der Praxis die Zahl [.guihint]#0.77/s# aus der Abbildung natürlich zu hoch!
|[.guihint]#Processing time per message# |Hier können Sie ablesen, wie viel Zeit denn nun die Verarbeitung einer Meldung gedauert hat. Vorsicht: Im allgemeinen ist dies *nicht* der Kehrwert zu [.guihint]#Received messages#. Denn dabei fehlen ja noch die Zeiten, in denen die Event Console gar nichts zu tun hatte, weil gerade keine Meldungen eingingen. Hier wird wirklich die reine real vergangene Zeit  zwischen dem Eintreffen einer Meldung und dem endgültigen Abschluss der Verarbeitung gemessen. Sie können darin in etwa ablesen, wie viele Meldungen die EC pro Zeit maximal schaffen _kann_.
Beachten Sie auch, dass es sich hier nicht um _CPU-Zeit_ handelt, sondern um _reale_ Zeit. Bei einem System mit genügend freien CPUs sind diese Zeiten etwa gleich. Sobald aber das System so unter Last ist, dass nicht alle Prozesse immer eine CPU bekommen, kann die reale Zeit deutlich höher werden.
|===

==== Tipps für das Tuning

Wie viele Meldungen die Event Console pro Sekunde verarbeiten kann, können Sie
in etwa an der [.guihint]#Processing time per message# ablesen. Generell hängt diese
Zeit damit zusammen, wie viele Regeln probiert werden müssen, bis eine Meldung
verarbeitet wird. Sie haben verschiedene Möglichkeiten, hier zu optimieren:

* Regeln, die sehr viele Meldungen ausschließen, sollten möglichst weit am Anfang der Regelkette stehen.
* Arbeiten Sie mit xref:rulepacks[Regelpaketen], um Sätze von verwandten Regeln zusammenzufassen. Die erste Regel in jedem Paket sollte das Paket sofort verlassen, wenn die gemeinsame Grundbedingung nicht erfüllt ist.

Weiterhin gibt es in der EC eine Optimierung, die auf der xref:syslogfacility][Syslog-Priorität und -Facility]basiert. 
Dazu wird für jede Kombination von Priorität und
Facility intern eine eigene Regelkette gebildet, in die jeweils nur
solche Regeln aufgenommen werden, die für Meldungen dieser Kombination
relevant sind.

Jede Regel, die eine Bedingung auf die Priorität, die Facility oder
am besten auf beides enthält, kommt dann nicht mehr in alle dieser Regelketten,
sondern optimalerweise nur in eine einzige. Das bedeutet, dass diese
Regel bei Meldungen mit einer anderen Syslog-Klassifizierung gar nicht
überprüft werden muss.

Im `var/log/mkeventd.log` sehen Sie nach einem Neustart eine
Übersicht der optimierten Regelketten:

.var/log/mkeventd.log
[{file}]
----
[8488808306.233330]  kern        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233343]  user        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233355]  mail        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233367]  daemon      : emerg(120) alert(89) crit(89) err(89) warning(89) notice(89) info(89) debug(89)
[8488808306.233378]  auth        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233389]  syslog      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233408]  lpr         : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233482]  news        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233424]  uucp        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233435]  cron        : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233446]  authpriv    : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233457]  ftp         : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233469]  (unused 12) : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233480]  (unused 13) : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233498]  (unused 13) : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233502]  (unused 14) : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233589]  local0      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233538]  local1      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233542]  local2      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233552]  local3      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233563]  local4      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233574]  local5      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233585]  local6      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233595]  local7      : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
[8488808306.233654]  snmptrap    : emerg(112) alert(67) crit(67) err(67) warning(67) notice(67) info(67) debug(67)
----

In obigem Beispiel sehen Sie, dass es 67 Regeln gibt, die in jedem Fall geprüft werden müssen.
Bei Meldungen der Facility `daemon` sind 89 Regeln relevant, nur bei der Kombination
`daemon`/`emerg` müssen 120 Regeln geprüft werden. Jede Regel, die eine Bedingung
auf Priorität oder Facility bekommt, reduziert die Anzahl von 67 weiter.

Natürlich können Sie diese Bedingungen nur dann setzen, wenn Sie sicher sind, dass sie von den
relevanten Meldungen auch erfüllt werden!


=== Anzahl aktueller Events

Auch die Anzahl der aktuell vorhandenen Events kann die Performance der EC beeinflussen --
und zwar, wenn diese deutlich aus dem Ruder läuft. Wie bereits erwähnt, sollte die EC
nicht als Ersatz für ein Syslog-Archiv gesehen werden, sondern lediglich „aktuelle Probleme“
anzeigen. Die Event Console kann zwar durchaus mit mehreren tausend Problemen umgehen,
aber der eigentliche Sinn ist das nicht.

Sobald die Anzahl der aktuellen Events etwa 5.000 übersteigt, beginnt die Performance
spürbar schlechter zu werden. Das zeigt sich zum einen in der GUI, die langsamer
auf Anfragen reagiert. Zum anderen wird auch die Verarbeitung langsamer, da in manchen
Situationen Meldungen mit allen aktuellen Events verglichen werden müssen.
Auch der Speicherbedarf kann problematisch werden.

Die Event Console hält aus Gründen der Performance alle aktuellen Events stets
im RAM. Diese werden einmal pro Minute (einstellbar) und beim sauberen
Beenden in die Datei `var/mkeventd/status` geschrieben.
Wenn diese sehr groß wird (z.B. über 50 Megabyte), wird dieser Vorgang
ebenfalls immer langsamer. Die aktuelle Größe können Sie schnell mit `ll`
abfragen (Alias für `ls -alF`):

[{shell}]
----
{c-omd} ll -h var/mkeventd/status
-rw-r--r-- 1 mysite mysite [hilite]#386K# Dez 14 13:46 var/mkeventd/status
----

Sollten Sie aufgrund einer ungeschickten Regel (z.B. einer, die auf alles matcht)
viel zu viele aktuelle Events haben, ist ein manuelles Löschen über die GUI
kaum noch sinnvoll zu schaffen. In diesem Fall hilft einfach ein Löschen der
Statusdatei:

[{shell}]
----
{c-omd} omd stop mkeventd
Stopping mkeventd...killing 17436......OK
{c-omd} rm var/mkeventd/status
{c-omd} omd start mkeventd
Starting mkeventd (builtin: syslog-udp)...OK
----

*Achtung:* Natürlich gehen dabei _alle_ aktuellen Events verloren sowie
die gespeicherten Zählerstände und andere Zustände. Insbesondere beginnen neue
Events dann wieder mit der ID 1.


[#overflow]
==== Automatischer Überlaufschutz

Die Event Console besitzt einen automatischen Schutz
vor einem „Überlaufen“. Dieser limitiert die Anzahl von aktuellen Events
pro Host, pro Regel und global. Dabei werden nicht nur offene Events gezählt, sondern
auch solche in anderen Phasen, wie z.B. [.guihint]#delayed# oder [.guihint]#counting#. Archivierte
Events werden nicht gezählt.

Dies schützt Sie in Situationen, in denen aufgrund eines systematischen
Problems in Ihrem Netzwerk Tausende von kritischen Events hereinströmen
und die Event Console „dicht“ machen würde. Zum einen verhindert das
Performance-Einbrüche der Event Console, die zu viele Events im Hauptspeicher
halten müsste. Zum anderen bleibt so die Übersicht für den Operator
(einigermaßen) bewahrt und Events, die nicht Teil des Sturms sind, bleiben
sichtbar.

Sobald ein Limit erreicht ist, geschieht eine der folgenden Aktionen:

* Das Erzeugen neuer Events wird gestoppt (für diesen Host, diese Regel bzw. global).
* Das Gleiche, aber zusätzlich wird ein „Overflowevent“ erzeugt.
* Das Gleiche, aber zusätzlich werden passende Kontaktpersonen benachrichtigt.
* Alternativ zu obigen drei Varianten können Sie auch das jeweils älteste Event löschen lassen, um Platz für das Neue zu machen.

Die Limits sowie die verknüpfte Auswirkung beim Erreichen stellen Sie in den
xref:globalsettings[Einstellungen der Event Console] mit [.guihint]#Limit amount of current events# ein. Folgende
Abbildung zeigt die Voreinstellung:

image::ec_limit_open_events.png[]

Falls Sie einen Wert mit [.guihint]#...create overflow event# aktiviert haben, wird beim Erreichen des
Limits _ein_ künstliches Event erzeugt, das den Operator von der
Fehlersituation in Kenntnis setzt:

image::ec_overflow_event.png[]

Falls Sie zusätzlich einen Wert mit [.guihint]#...notify contacts# aktiviert haben, werden passende
Kontaktpersonen per {CMK}-Benachrichtigung informiert. Die Benachrichtigung durchläuft die
xref:notifications#rules[Benachrichtigungsregeln] von {CMK}. Diese Regeln müssen sich nicht
unbedingt an die Kontaktauswahl der Event Console halten, sondern können diese
modifizieren. Folgende Tabelle zeigt, welche Kontakte ausgewählt werden, falls
Sie [.guihint]#Notify all contacts of the notified host or service# eingestellt haben
(was der Default ist):


[cols="15,~"]
|===
|Limit |Kontaktauswahl 

|pro Host |Die Kontakte zum Host, welche genauso ermittelt werden, wie bei der xref:notifications[Benachrichtigung von Events] über {CMK}.
|pro Regel |Hier wird das Feld für den Host-Namen leer gelassen. Falls in der Regel Kontaktgruppen definiert sind, werden diese ausgewählt, ansonsten die Fallback-Kontakte.
|Global |Die Fallback-Kontakte.
|===


=== Zu großes Archiv

Wie xref:archive[oben] gezeigt, hat die Event Console ein Archiv von allen Events
und deren Verarbeitungsschritten. Dieses ist aus Gründen der einfachen Implementierung
und Administration in Textdateien abgelegt.

Textdateien sind beim _Schreiben_ von Daten in der Performance schwer zu
übertreffen -- von Datenbanken beispielsweise nur mit enormem Optimierungsaufwand. Das liegt unter anderem
an der Optimierung dieser Zugriffsart durch Linux und der kompletten Speicherhierarchie
von Platten und SANs. Dies geht allerdings zulasten der Lesezugriffe. Da Textdateien
über keinen Index verfügen, ist für das Suchen in den Dateien ein komplettes Einlesen
notwendig.

Die Event Console verwendet als Index für die _Zeit_ der Ereignisse zumindest
die Dateinamen der Log-Dateien. Je weiter Sie den Anfragezeitraum eingrenzen,
desto schneller geht also die Suche.

Sehr wichtig ist trotzdem, dass Ihr Archiv nicht zu groß wird. Wenn Sie die
Event Console nur dazu verwenden, wirkliche Fehlermeldungen zu verarbeiten,
kann das eigentlich nicht passieren. Sollten Sie versuchen, die EC als Ersatz für ein echtes
Syslog-Archiv einzusetzen, kann dies allerdings zu sehr großen Dateien führen.

Wenn Sie in eine Situation geraten, in der Ihr Archiv zu groß geworden ist,
können Sie einfach ältere Dateien in `var/mkeventd/history/` löschen.
Auch können Sie in [.guihint]#Event history lifetime# die Lebenszeit der Daten generell
begrenzen, so dass das Löschen in Zukunft voreingestellt ist. Per Default
wird 365 Tage gespeichert. Vielleicht kommen Sie ja mit deutlich weniger aus.


=== Performance über die Zeit messen

{CMK} startet automatisch für jede laufende
Instanz der Event Console einen Service, der die Leistungsdaten in Kurven
aufzeichnet und Sie auch warnt, wenn es zu xref:overflow[Überläufen] kommt.

Sofern Sie auf dem Monitoring-Server einen Linux-Agenten installiert haben, wird der Check wie gewohnt automatisch
gefunden und eingerichtet:

image::ec_check.png[]

Der Check bringt sehr viele interessante Messarten mit, z.B. die Anzahl
der eingehenden Meldungen pro Zeit und wie viele davon verworfen wurden:

image::ec_graph_message_rate.png[]

Die Effizienz Ihrer Regelkette wird dargestellt durch einen Vergleich von
ausprobierten Regeln zu solchen, die gegriffen haben:

image::ec_graph_rule_efficiency.png[]

Dieser Graph zeigt die durchschnittliche Zeit für die Verarbeitung einer Meldung:

image::ec_graph_processing_time.png[]

Daneben gibt es noch etliche weitere Diagramme.



== Verteiltes Monitoring

Wie Sie die Event Console in einer Installation mit mehreren {CMK}-Instanzen
einsetzen, erfahren Sie im xref:distributed_monitoring#ec[Artikel über verteiltes Monitoring].


== Die Statusschnittstelle

Die Event Console bietet über das Unix-Socket `tmp/run/mkeventd/status`
sowohl Zugriff auf den internen Status als auch die Möglichkeit, Kommandos
auszuführen. Das hier verwendete Protokoll ist eine stark eingeschränkte
Teilmenge von xref:livestatus#[Livestatus]. Auf diese Schnittstelle greift
der Monitoring-Kern zu und reicht die Daten an die GUI durch, um so ein
xref:distributed_monitoring#[verteiltes Monitoring] auch für die Event Console zu
ermöglichen.

Für den vereinfachten Livestatus der Event Console gelten folgende Einschränkungen:

* Die einzigen erlaubten Header sind `Filter:` und `OutputFormat:`.
* Daher ist kein Keepalive möglich, pro Verbindung ist nur eine Anfrage durchführbar.

Folgende Tabellen sind verfügbar:

[cols="20,~"]
|===

|`events` |Liste alle aktuellen Events.
|`history` |Zugriff auf das xref:archive[Archiv]. Eine Anfrage auf diese Tabelle führt zum Zugriff auf die Textdateien des Archivs. Verwenden Sie auf jeden Fall einen Filter über die Zeit des Eintrags, um einen Vollzugriff auf alle Dateien zu vermeiden.
|`status` |Status- und Performancewerte der EC. Diese Tabelle hat immer genau eine Zeile.
|===


Kommandos können Sie mithilfe von `unixcat` mit einer sehr einfachen Syntax
in das Socket schreiben:

[{shell}]
----
{c-omd} echo "COMMAND RELOAD" | unixcat tmp/run/mkeventd/status
----

Folgende Kommandos sind verfügbar:

[cols="20,~"]
|===

|`DELETE` |Archiviert ein Event. Argumente: Event-ID und Benutzerkürzel.
|`RELOAD` |Neuladen der Konfiguration.
|`SHUTDOWN` |Beendet die Event Console.
|`REOPENLOG` |Die Log-Datei wird neu geöffnet. Dieses Kommando wird von der Log-Dateirotation benötigt.
|`FLUSH` |Löscht alle aktuellen und archivierten Events.
|`SYNC` |Löst ein sofortiges Aktualisieren der Datei `var/mkeventd/status` aus.
|`RESETCOUNTERS` |Setzt die Trefferzähler der Regeln zurück (entspricht dem Menüeintrag [.guihint]#Event Console > Reset counters# in der Setup-GUI).
|`UPDATE` |Führt ein Update von einem Event aus. Die Argumente sind der Reihe nach Event-ID, Benutzerkürzel, Quittierung (0/1), Kommentar und Kontaktinfo.
|`CHANGESTATE` |Ändert den Status {OK} / {WARN} / {CRIT} / {UNKNOWN} eines Events. Argumente sind Event-ID, Benutzerkürzel und Statusziffer (`0`/`1`/`2`/`3`).
|`ACTION` |Führt eine benutzerdefinierte Aktion auf einem Event aus. Argumente sind Event-ID, Benutzerkürzel und Aktions-ID. Die spezielle ID `@NOTIFY` steht für eine xref:notifications[Benachrichtigung] über {CMK}.
|===


== Dateien und Verzeichnisse

[cols="50,~"]
|===
|Pfad |Bedeutung 

|`var/mkeventd` |Arbeitsverzeichnis des Event Daemons.
|`var/mkeventd/status` |Kompletter aktueller Zustand der Event Console. Dies umfasst vor allem alle aktuell offenen Events (und solche in Übergangsphasen wie [.guihint]#counting# etc.). Im Falle einer Fehlkonfiguration, die zu sehr vielen offenen Events führt, kann diese Datei riesig werden und die Performance der EC drastisch reduzieren. In diesem Fall können Sie den Dienst `mkeventd` stoppen, die Datei löschen und den Dienst wieder starten, um alle offenen Events auf einmal zu löschen.
|`var/mkeventd/history/` |Ablageort des xref:archive[Archivs].
|`var/log/mkeventd.log` |Log-Datei der Event Console.
|`etc/check_mk/mkeventd.d/wato/global.mk` |Die globalen Einstellungen der Event Console in Python-Syntax.
|`etc/check_mk/mkeventd.d/wato/rules.mk` |Ihre ganzen konfigurierten Regelpakete und Regeln in Python-Syntax.
|`tmp/run/mkeventd/events` |Eine Named-Pipe, in die Sie mit `echo` oder anderen Befehlen direkt Meldungen schreiben können, um diese an die EC zu übergeben. Achten Sie darauf, dass zu jedem Zeitpunkt nur eine einzige Anwendung in diese Pipe schreibt, da sich die Texte der Meldungen sonst vermischen können.
|`tmp/run/mkeventd/eventsocket` |Ein Unix-Socket, das die gleiche Aufgabe wie die Pipe erfüllt, aber ein gleichzeitiges Schreiben mehrerer Anwendungen ermöglicht. Zum Hineinschreiben benötigen Sie den Befehl `unixcat` oder `socat`.
|`tmp/run/mkeventd/pid` |Die aktuelle Prozess-ID des Event Daemons während dieser läuft.
|`tmp/run/mkeventd/status` |Ein Unix-Socket, das die Abfrage des aktuellen Status und das Senden von Kommandos erlaubt. Die Anfragen der GUI gehen zunächst zum Monitoring-Kern, der dann auf diesen Socket zugreift.
|`local/share/snmp/mibs` |Von Ihnen hochgeladene MIB-Dateien für die Übersetzung von SNMP-Traps.
|===
////