// -*- coding: utf-8 -*-
include::global_attr.adoc[]
= Der Piggyback-Mechanismus
:revdate: 2021-11-19
:title: Der Piggyback-Mechanismus
:description: Hier erfahren Sie, wie Sie mit {CMK} Monitoring-Daten eines Hosts beim Abfragen eines anderen Hosts huckepack (piggyback) mit übertragen.

{related-start}
link:wato_monitoringagents.html[Monitoring-Agenten]
link:dcd.html[Dynamische Host-Konfiguration]
link:monitoring_azure.html[Microsoft Azure überwachen]
link:monitoring_aws.html[Amazon Web Services (AWS) überwachen]
link:monitoring_kubernetes.html[Kubernetes überwachen]
link:monitoring_docker.html[Docker überwachen]
link:monitoring_vmware.html[VMWare ESXi überwachen]
{related-end}

// MFS: Nur Screenshots, Präzisierungen, Proxmox hinzugefügt

== Einleitung

Der Piggyback-Mechanismus wurde bereits in den frühen Zeiten
von {CMK} eingeführt -- und zwar im Rahmen der Überwachung von
xref:monitoring_vmware#[VMware.] Hier ist die Situation, dass Daten von einem
bestimmten Host abgefragt werden müssen, weil sie nur dort bereitstehen (z.B. von
einem ESX-Hostsystem oder dem vCenter), diese aber im Monitoring einen ganz
anderen Host betreffen (z.B. eine virtuelle Maschine).

Das ist mit dem normalen Mechanismus von {CMK} nicht zu realisieren,
denn dieser ordnet Daten und Services, die er von einem Host holt,
automatisch diesem zu. Und es wäre schließlich sehr unpraktisch für
das Monitoring, wenn alle Informationen zu allen VMs immer direkt
beim ESX-Host oder gar vCenter erschienen.

Der Begriff „Piggyback“ (im Deutschen „Huckepack“) drückt aus, dass
Monitoring-Daten zu Host B quasi _huckepack_ beim Abfragen von
Host A mit übertragen werden.

Heute kommt Piggyback bei vielen weiteren Monitoring-Plugins zum Einsatz,
z.B. bei der Überwachung von:

* xref:monitoring_aws#[AWS]
* xref:monitoring_azure#[Azure]
* xref:monitoring_docker#[Docker]
* xref:monitoring_kubernetes#[Kubernetes] 
* Proxmox VE
* xref:monitoring_vmware#[VMware]

Neben Virtualisierungsumgebungen kann der Piggyback-Mechanismus auch beim
Monitoring von Mobilgeräten (Mobileiron) oder dem Klima-Monitoring im
Rechenzentrum (MQTT) eingesetzt werden. Da die Abfrageschnittstellen sehr
simpel sind, ist es
sehr einfach, den Piggyback-Mechanismus selbst zu verwenden. Sie
können ihn beispielsweise beim Realisieren eigener Check-Plugins
nutzen, um Daten aus einer Quelle beliebigen anderen Hosts zuzuordnen.

// MFS: Hier muss eigentlich ein Link auf einen noch zu erstellenden Artikel
// "Howto: Piggyback-Plugins selbst erstellen!" eingefügt werden.


== Das Piggyback-Prinzip

Das Grundprinzip von Piggyback funktioniert so: Ein Host A kennt
nicht nur Monitoring-Daten zu sich selbst, sondern auch zu anderen
Hosts -- oder allgemeiner gesagt: zu anderen Objekten. So kennt
z.B. ein ESX-Host den Zustand und viele aktuelle Metriken zu jeder
seiner VMs. Der Host A wird in diesem Zusammenhang manchmal auch
als _Quell-Host_ (_source host_) bezeichnet.

Wenn {CMK} jetzt von A in seinem minütlichen Rhythmus die Monitoring-Daten abruft --
sei es vom normalen {CMK}-Agenten oder von einem Spezialagenten über eine Hersteller-API --,
bekommt es in der Antwort speziell markiert auch Daten zu den anderen Hosts/Objekten
B, C usw. mitgeteilt. Diese _Piggyback-Daten_ legt es dann für die spätere
Verarbeitung in Dateien auf dem {CMK}-Server ab. Die Hosts B, C usw. werden
als _piggybacked Hosts_ bezeichnet.

Wenn {CMK} dann später die Monitoring-Daten von B oder C benötigt, liegen
diese bereits in den Dateien vor und können direkt verarbeitet werden, ohne einen Agenten
abzufragen:

image::piggyback_scheme_1.png[width=50%,alt="Schematische Darstellung der indirekten Datenweitergabe über den Piggyback-Mechanismus."]

Es ist auch möglich und sinnvoll, normales Monitoring und Piggyback zu kombinieren.
Nehmen wir wieder das VMware-Beispiel: Vielleicht haben Sie ja in Ihrer VM B einen
{CMK}-Agenten installiert, der lokale Informationen aus der VM auswertet, die dem ESX-Host
nicht bekannt sind (z.B. die in der VM laufenden Prozesse). In diesem Fall wird
der Agent abgefragt, und die Daten werden mit den Piggyback-Daten von Host A
zusammengefasst:

image::piggyback_scheme_2.png[width=50%,alt="Schematische Darstellung der kombinierten Datenweitergabe: Ein Teil der Daten kommt via Piggyback, der Rest direkt vom überwachten Host."]


== Piggyback in der Praxis


=== Einrichten von Piggyback

Die gute Nachricht ist, dass der Piggyback-Mechanismus häufig völlig automatisch funktioniert:

* Wenn beim Abfragen von A Piggyback-Daten für andere Hosts entdeckt werden, werden diese automatisch für die spätere Auswertung gespeichert.
* Wenn beim Abfragen von B Piggyback-Daten von einem anderen Host auftauchen, werden diese automatisch verwendet.

Allerdings ist -- wie immer in {CMK} -- alles konfigurierbar. So können Sie
beispielsweise bei den Eigenschaften eines Hosts (Host B) im Kasten
[.guihint]#Monitoring agents# einstellen, wie dieser auf vorhandene oder fehlende
Piggyback-Daten reagieren soll:

image::piggyback_settings.png[alt="Die Umleitung der Piggyback-Daten wird in den Agenten-Einstellungen festgelegt"]

Der Standard ist [.guihint]#Use piggyback data from other hosts if present#.
Falls vorhanden, werden also Piggyback-Daten verwendet, und wenn
keine da sind, verwendet der Host eben nur seine „eigenen“ Monitoring-Daten.

Bei der Einstellung [.guihint]#Always use and expect piggyback data# _erzwingen_
Sie die Verarbeitung von Piggyback-Daten. Wenn diese fehlen oder veraltet
sind, wird der Service [.guihint]#Check_MK# eine Warnung ausgeben.

Bei [.guihint]#Never use piggyback data# werden eventuell vorhandene Piggyback-Daten
einfach ignoriert -- eine Einstellung, die Sie nur in Ausnahmefällen
brauchen werden.


=== Hosts müssen vorhanden sein

Damit ein Host Piggyback-Daten verarbeiten kann, muss dieser natürlich im Monitoring
vorhanden sein. Im Beispiel von ESX bedeutet das, dass Sie Ihre VMs auch als Hosts
in {CMK} aufnehmen müssen, damit sie überhaupt überwacht werden.

Mittlerweile können Sie dies mithilfe der
xref:dcd#[dynamischen Konfiguration] automatisieren und Hosts, für die Piggyback-Daten
vorhanden sind, automatisch anlegen lassen.

[#renamehosts]
=== Host-Namen und ihre Zuordnung

Im Beispiel oben war es irgendwie logisch, dass die Daten von Objekt
B auch dem Host B im Monitoring zugeordnet wurden. Aber wie genau
funktioniert das? Beim Piggyback-Mechanismus geht die Zuordnung
immer über einen _Namen_. Der (Spezial-)Agent schreibt zu jedem
Satz von Piggyback-Daten einen Objektnamen. Im Fall von ESX ist das
z.B. der Name der virtuellen Maschine. Manche Plugins wie z.B.
xref:monitoring_docker#[Docker] haben auch mehrere Möglichkeiten, was
als Name verwendet werden soll.

Damit die Zuordnung klappt, muss der Name des passenden Hosts in {CMK}
natürlich identisch sein -- auch die Groß-/Kleinschreibung betreffend.

Was aber, wenn die Namen der Objekte in den Piggyback-Daten für das Monitoring
ungeeignet oder unerwünscht sind? 
Dafür gibt es den speziellen xref:wato_rules#[Regelsatz]
[.guihint]#Hostname translation for piggybacked hosts#, den Sie im Setup-Menü unter 
[.guihint]#Setup > Agents > Agent access rules# finden.

Um eine Umbenennung zu konfigurieren, führen Sie die folgenden zwei Schritte aus:

. Legen Sie eine Regel an und stellen Sie die Bedingung so ein, dass Sie auf dem _Quell-Host_ greift -- also quasi auf Host A.
. Legen Sie im Wert der Regel eine passende Namenszuordnung fest.

Hier ist ein Beispiel für den Wert der Regel. Es wurden zwei Dinge
konfiguriert: Zunächst werden alle Host-Namen aus den Piggyback-Daten
in Kleinbuchstaben umgewandelt. Danach werden noch die beiden Hosts
`vm0815` bzw. `vm0816` in die {CMK}-Hosts `mylnxserver07`
bzw. `mylnxserver08` umgewandelt:

image::piggyback_hostname_translation.png[alt="Optionen der 'Hostname translation', Entfernen des Domain-Parts, Umwandlung nach Kleinbuchstaben oder explizites Mapping."]

Flexibler ist die Methode mit xref:regexes#[regulären Ausdrücken,] die Sie
unter [.guihint]#Multiple regular expressions# finden. Diese bietet sich an, wenn die
Umbenennung von vielen Hosts notwendig ist und diese nach einem bestimmten
Schema erfolgt. Gehen sie wie folgt vor:

. Aktivieren Sie die Option [.guihint]#Multiple regular expressions#.
. Fügen Sie mit dem Knopf [.guihint]#Add expression# einen Übersetzungseintrag an. Jetzt erscheinen zwei Felder.
. Geben Sie im Feld [.guihint]#Regular expression# einen regulären Ausdruck ein, der auf die ursprünglichen Objektnamen matcht und der mindestens eine Subgruppe enthält -- also einen Teilausdruck, der in runde Klammern gesetzt ist. Eine gute Erklärung zu diesen Gruppen finden Sie im xref:regexes#matchgroups[Artikel zu regulären Ausdrücken.]
. Geben Sie bei [.guihint]#Replacement# ein Schema für den gewünschten Namen des Ziel-Hosts an, wobei Sie die Werte, die mit den Subgruppen „eingefangen“ wurden, durch `\1`, `\2` usw. ersetzen können.

Ein Beispiel für den regulären Ausdruck wäre z.B. `vm(pass:[.*])-local`. Die Ersetzung `myvm\1`
würde dann z.B. den Namen `vmharri-local` in `myvmharri` übersetzen.


== Die Technik dahinter


=== Transport der Piggyback-Daten

Wie oben beschrieben werden die Piggyback-Daten zu anderen Hosts in der Agentenausgabe
des Quell-Hosts transportiert. Die Ausgabe des {CMK}-Agenten ist ein
einfaches textbasiertes Format, das der
xref:wato_monitoringagents#[Artikel über die Agenten] vorstellt.

Neu ist jetzt, dass im Output eine Zeile erlaubt ist, die mit `&lt;&lt;&lt;&lt;`
beginnt und mit `&gt;&gt;&gt;&gt;` endet. Dazwischen steht ein Host-Name. Alle
weiteren Monitoring-Daten ab dieser Zeile werden dann diesem Host zugeordnet. Hier
ist ein beispielhafter Auszug, der die Sektion `+<<<esx_vsphere_vm>>>+`
dem Host `316-VM-MGM` zuordnet:

[{file}]
----
<<<<316-VM-MGM>>>>
<<<esx_vsphere_vm>>>
config.datastoreUrl url /vmfs/volumes/55b643e1-3f344a10-68eb-90b11c00ff94|uncommitted 12472944334|name EQLSAS-DS-04|type VMFS|accessible true|capacity 1099243192320|freeSpace 620699320320
config.hardware.memoryMB 4096
config.hardware.numCPU 2
config.hardware.numCoresPerSocket 2
guest.toolsVersion 9537
guest.toolsVersionStatus guestToolsCurrent
guestHeartbeatStatus green
name 316-VM-MGM
----

Durch eine Zeile mit dem Inhalt `&lt;&lt;&lt;&lt;&gt;&gt;&gt;&gt;`
kann diese Zuordnung wieder aufgehoben werden. Der weitere Output gehört
dann wieder zum Quell-Host.

Bei der Verarbeitung der Agentenausgabe extrahiert {CMK} die Teile, die für andere
Hosts bestimmt sind, und legt sie in Dateien unterhalb von `tmp/check_mk/piggyback`
ab. Darunter befindet sich für jeden Ziel-Host (z.B. für jede VM) ein Unterverzeichnis --
in unserem Beispiel also ein Ordner mit dem Namen `B`. Darin ist dann pro
Quell-Host eine Datei mit den eigentlichen Daten. Deren Name wäre in unserem Beispiel `A`.
Warum ist das so kompliziert gelöst? Nun, ein Host kann in der Tat Piggyback-Daten von _mehreren_
Hosts bekommen, somit wäre eine einzelne Datei nicht ausreichend.

*Tipp:* Wenn Sie neugierig sind, wie die Piggyback-Daten bei Ihnen aussehen, finden Sie
die Agentenausgaben Ihrer Hosts in der Monitoring-Instanz im Verzeichnis
`tmp/check_mk/cache`.
Eine Übersicht über alle beteiligten Dateien und Verzeichnisse finden Sie xref:piggyback#files[weiter unten.]


=== Verwaiste Piggyback-Daten

Wenn Sie in in einer Umgebung arbeiten, in der Hosts automatisiert den
Quell-Host wechseln, empfehlen wir die Nutzung der
xref:dcd#[dynamischen Host-Konfiguration.]
Wird deren Einsatz nicht benötigt oder erwünscht (beispielsweise weil virtuelle
Maschinen manuell umgezogen werden), dann kann
es Ihnen passieren, dass Piggyback-Daten für einen Host vorhanden sind, den Sie in {CMK} gar nicht angelegt
haben. Das kann Absicht sein, vielleicht aber auch ein Fehler -- z.B. weil ein Name nicht genau übereinstimmt.

In den „Treasures“ finden Sie ein Skript mit dem Namen
`find_piggy_orphans`, das {CMK} nach Piggyback-Daten durchsucht,
zu denen es keinen Host im Monitoring gibt. Dieses rufen Sie einfach ohne
Argumente auf. Es gibt dann pro Zeile den Namen von einem nicht überwachten piggybacked Host aus:

[{shell}]
----
{c-omd} share/doc/check_mk/treasures/find_piggy_orphans
fooVM01
barVM02
----

Diese Ausgabe ist „sauber“, und Sie können Sie z.B. in einem Skript weiterverarbeiten.


=== Piggyback im verteilten Monitoring

Beachten Sie, dass in xref:distributed_monitoring#[verteilten Umgebungen]
aktuell QuellHost und die piggybacked Hosts in der gleichen
Instanz überwacht werden müssen. Dies liegt daran, dass die
Übertragung der Daten zwischen den Hosts aus Effizienzgründen mit einem lokalen
Dateiaustausch über das Verzeichnis `tmp/check_mk` läuft.

Zukünftige Versionen von {CMK} werden eventuell einen Mechanismus anbieten,
der optional den Austausch von Piggyback-Daten über Instanzgrenzen hinweg
ermöglicht.


[#files]
== Dateien und Verzeichnisse

=== Pfade auf dem {CMK}-Server

[cols="35,~"]
|===
|Pfad |Bedeutung 

|`tmp/check_mk/piggyback/` |Ablageort für Piggyback-Daten
|`tmp/check_mk/piggyback/B/` |Verzeichnis von Piggyback-Daten _für_ Host B
|`tmp/check_mk/piggyback/B/A` |Datei mit Piggyback-Daten _von_ Host A _für_ Host B
|`tmp/check_mk/piggyback_sources/` |Metainformationen zu den Hosts, die Piggyback-Daten erzeugen
|`tmp/check_mk/cache/A` |Agentenausgabe von Host A -- inklusive eventuell vorhandenen Piggyback-Daten in Rohform
|===

