include::global_attr.adoc[]
= Alarmierung (Notifications)
:revdate: 2016-11-29
:title: Alarmierung per E-Mail, SMS, Ticketsystem und mehr
:description: Bei Benachrichtigungen ist der Zeitpunkt, die Methode und die Gruppe der Empfänger essentiell. Lernen Sie hier, wie Sie Ihre Anforderungen umgesetzen.

{related-start}
link:basics_ackn.html[Quittierung von Problemen]
link:commands.html[Kommandos]
link:wato_user.html[Benutzer, Zuständigkeiten, Berechtigungen]
{related-end}


== Einleitung

[{image-left}]
image::icon_notifications.png[width=80]

Alarmierung bedeutet, dass Benutzer im Falle von Problemen oder anderen
Ereignissen von {CMK} aktiv informiert werden. Im häufigsten Fall
geschieht das durch Emails. Es gibt aber auch viele andere Methoden, wie
z.B. das Versenden von SMS oder die Weiterleitung an ein Ticketsystem. {CMK}
bietet eine einfache Schnittstelle, um eigene Alarmierungsmethoden
zu skripten.

Ausgangspunkt für jede Alarmierung ist ein _Ereignis._ Dieses bezieht
sich immer auf einen bestimmten Host oder Service. Mögliche Typen von
Ereignissen sind:

* Ein Zustandswechsel (z.B. {OK} → {WARN})
* Der Wechsel zwischen einem stetigen und einem icon:icon_flapping[] unstetigen Zustand (flapping)
* Start oder Ende einer icon:icon_downtime[] geplanten Wartungszeit
* Die icon:icon_ack[] link:basics_ackn.html[Bestätigung eines Problems] durch einen Benutzer ([.guihint]#Acknowledgement#)
* Eine durch ein icon:icon_commands[] link:commands.html[Kommando] von Hand ausgelöste Alarmierung
* Die Ausführung eines icon:icon_alert_handlers[] link:alert_handlers.html[Alerthandlers]
* Ein Ereignis, das von der icon:icon_mkeventd[] link:ec.html[Event Console] zur Alarmierung übergeben wurde

{CMK} verfügt über ein regelbasiertes System zur Konfiguration
der Alarmierung, mit dem Sie auch sehr anspruchsvolle Anforderungen
umsetzen können.  Eine einfache Alarmierung per Email -- wie sie in vielen
Fällen zunächst völlig ausreicht -- ist trotzdem schnell eingerichtet.

== Alarmieren oder (noch) nicht alarmieren?

Grundsätzlich ist Alarmierung optional, und Sie können {CMK} durchaus
auch ohne diese sinnvoll nutzen. Manche große Unternehmen haben eine Art
Leitstand, in der das Operating die Konsole von {CMK} ständig im Blick
hat und keine zusätzlichen Emails benötigt.

Wenn Sie noch im _Aufbau_ Ihrer {CMK}-Umgebung sind, sollten Sie
außerdem bedenken, dass Alarmierung erst dann für Ihre Kollegen eine
Hilfe ist, wenn keine oder nur selten _Fehlalarme_ produziert werden.
Dazu müssen Sie erstmal die Schwellwerte und alle anderen Einstellungen
soweit im Griff haben, dass im Normalfall auch alles „grün“ ist.
Die Akzeptanz für das neue Monitoring ist schnell dahin, wenn es die Inbox
jeden Tag mit Hunderten nutzloser Emails flutet.

Folgendes Vorgehen hat sich bewährt:

*Schritt 1:* Tunen Sie das Monitoring und eliminieren Sie falsche
Fehlermeldungen. Beheben Sie durch {CMK} neu aufgedeckte tatsächliche
Probleme. Tun Sie das, bis „normalerweise“ alles {OK} / {UP} ist.

*Schritt 2:* Schalten Sie die Alarmierung zunächst nur für sich
selbst ein. Reduzieren Sie das „Rauschen“, welches durch sporadisch
kurz auftretende Probleme verursacht wird. Passen Sie dazu weitere Schwellwerte
an, verwenden Sie [.guihint]#Predictive Monitoring,# erhöhen Sie die
[.guihint]#Maximum number of check attempts,# verwenden Sie [.guihint]#Delay ... notifications#
falls nötig. Wenn es sich um tatsächliche
Probleme handelt, versuchen Sie, diese in den Griff zu bekommen.

*Schritt 3:* Erst wenn in Ihrer eigenen Inbox einigermaßen Ruhe ist,
schalten Sie die Alarmierung für Ihre Kollegen ein. Richten Sie dazu sinnvolle
Kontaktgruppen ein, so dass jeder nur solche Alarme bekommt, die ihn auch wirklich
etwas angehen.

Das Ergebnis ist ein sehr nützliches System, das Ihnen und Ihren Kollegen
hilft, mit relevanten Informationen Ausfallzeiten zu reduzieren.


[#simple_mail]
== Einfache Alarmierung per Email

=== Voraussetzungen

In der Defaultkonfiguration von {CMK} bekommt ein Benutzer Alarmmeldungen
per Email, wenn folgende Voraussetzungen erfüllt sind:

* Der {CMK}-Server hat ein funktionierendes link:notifications.html#smtp[Setup für das Versenden von Emails].
* Für den link:wato_user.html[Benutzer] ist eine E-Mail-Adresse konfiguriert.
* Der Benutzer ist Mitglied einer link:wato_user.html#contact_groups[Kontaktgruppe] und somit ein Kontakt.
* Es passiert ein Ereignis bei einem Host oder Service, der dieser Kontaktgruppe zugeordnet ist.

{CMK} versendet HTML-Emails, die auch die aktuellen link:graphing.html[Messwerte]
des betroffenen Services enthalten:

[{image-border}]
image::html_notification.png[]


[#smtp]
=== Einrichten des Mailversands unter Linux

Damit das Versenden von Emails klappt, muss Ihr {CMK}-Server eine
funktionierende Konfiguration des SMTP-Servers haben. Je nach Ihrer
Linux-Distribution kann es sich dabei z.B. um Postfix, Qmail, Exim, Sendmail
oder Nullmailer handeln. Die Konfiguration erfolgt mit den Mitteln Ihrer
Linux-Distribution.

In der Regel beschränkt sich die Konfiguration auf das Eintragen eines
„Smarthosts“ (auch SMTP-Relay-Server genannt), an den alle Emails
weitergeleitet werden. Dies ist dann Ihr firmeninterner SMTP-Mailserver. Im
LAN benötigen Smarthosts in der Regel keine Authentifizierung, was die Sache
einfach macht.  Der Smarthost wird bei manchen Distributionen schon während
der Installation abgefragt.  Bei der {CMK}-Appliance können Sie den
Smarthost bequem über die link:appliance_usage.html#cma_webconf_system_settings[Web-GUI]
konfigurieren.

Sie können das Versenden von Emails auf der Kommandozeile mit dem Befehl
`mail` einfach testen. Da es für diesen Befehl unter Linux
zahlreiche unterschiedliche Implementierungen gibt, liefert {CMK} zur
Vereinheitlichung die Variante aus dem Projekt _Heirloom mailx_ direkt
im Suchpfad des Instanzbenutzers mit aus (als `~/bin/mail`). Testen
Sie also am besten als Instanzbenutzer, denn mit den gleichen Rechten laufen
später auch die Alarmierungsskripten.

Der Inhalt der Email wird von der Standardeingabe gelesen, der Betreff mit
`-s` angegeben und die Zieladresse einfach als Argument ans Ende der
Kommandozeile gestellt:

[{shell}]
----
{c-omd} echo "Inhalt" | mail -s Test-Betreff harry.hirsch@example.com
----

Die Email sollte ohne Verzögerung zugestellt werden. Falls dies nicht klappt,
finden Sie Hinweise in der Logdatei des SMTP-Server im Verzeichnis `/var/log`
(siehe link:notifications.html#maillog[Dateien und Verzeichnisse]).


=== E-Mail-Adresse und Kontaktgruppe

E-Mail-Adresse und Kontaktgruppe eines Benutzers legen Sie in der link:wato_user.html[Benutzerverwaltung] fest:

[{image-border}]
image::user_notification.png[]

Bei einer frisch erzeugten {CMK}-Instanz gibt es zunächst nur die
Kontaktgruppe [.guihint]#Everything#. Mitglieder dieser Gruppe sind automatisch
für _alle_ Hosts und Services zuständig und werden bei jedem relevanten
Monitoringereignis per Email benachrichtigt.

Hinweis: Falls Ihre {CMK}-Installation mit einer älteren Version erzeugt
wurde, kann diese Gruppe auch [.guihint]#Everybody# heißen. Dies ist aber logisch
falsch, denn diese Gruppe beinhaltet ja nicht alle Benutzer, sondern alle
[.guihint]#Hosts#! Bis auf den unterschiedlichen Namen ist aber die Funktion die
gleiche.

[#notification_testing]
=== Test

Um die Alarmierung zu testen, können Sie einen {OK}-Service einfach von Hand auf
{CRIT} setzen. Dies geht mit dem icon:icon_commands[] link:commands.html[Kommando] [.guihint]#Fake check results.#
Das muss dann sofort zu einer Email führen. Beim nächsten regulären Check
sollte der Service dann wieder auf {OK} gehen und eine erneute Alarmierung
auslösen (diesmal vom Typ [.guihint]#Recovery#).

image::fake_check_results.png[]

Bitte beachten Sie bei diesen Tests, dass der Service bei häufigen Wechseln
nach einiger Zeit in den Zustand icon:icon_flapping[] _unstetig_ gehen wird. Weitere
Zustandswechsel lösen dann keine Alarmierungen mehr aus. In der [.guihint]#Master control#
können Sie die Erkennung von Unstetigkeiten ([.guihint]#Flap detection#) vorübergehend
ausschalten.

Alternativ können Sie auch eine [.guihint]#Custom notification# versenden. Dabei
ändert sich der Status des entsprechenden Services nicht. Allerdings ist
der erzeugte Alarm dann von einem geringfügig anderen Typ und kann sich
 -- abhängig von Ihren Alarmierungsregeln -- anders verhalten.

image::various_commands.png[]


[#rules]
== Alarmierung per Regeln steuern

=== Grundprinzip

{CMK} ist „ab Werk“ so eingerichtet, dass es bei einem
Ereignis an jeden link:wato_user.html#contact_groups[Kontakt] des betroffenen Hosts
oder Services eine Email versendet. Das ist sicher erstmal sinnvoll,
aber in der Praxis tauchen viele weitergehende Anforderungen auf, z.B.:

* Unterdrücken bestimmter wenig nützlicher Meldungen
* „Abonnieren“ von Meldungen zu Services, für die man kein Kontakt ist
* Alarmierung per Email, SMS oder Pager, abhängig von der Tageszeit
* Eskalierung von Problemen nach einer bestimmten Zeit ohne link:basics_ackn.html[Quittierung]
* Eventuell keine Alarme für {WARN} oder {UNKNOWN}
* _und vieles mehr{nbsp}..._

{CMK} bietet Ihnen über einen regelbasierten Mechanismus maximale
Flexibilität bei der Umsetzung solcher Anforderungen. Über das
WATO-Modul icon:icon_notifications[] [.guihint]#Notifications# verwalten Sie
eine *Kette von Alarmierungsregeln,* welche festlegen, _wer_ _wann_
_wie_ benachrichtigt werden soll. (Mehr Informationen zu der Warnmeldung, die
vermutlich im Bereich [.guihint]#Notifications# erscheint, finden Sie link:notifications.html#fallback[weiter unten].)

image::wato_sidebar_notifications.png[width=42%]

Bei jedem Monitoringereignis wird diese Regelkette von _oben nach unten_
durchlaufen. Wie immer hat jede Regel zunächst eine _Bedingung_, die entscheidet,
ob diese Regel überhaupt zur Anwendung kommt. Ist diese für ein bestimmtes
Ereignis erfüllt, legt die Regel zwei Dinge fest:

* Eine Auswahl von link:wato_user.html[Kontakten] (_Wer_ soll alarmiert werden?)
* Eine _Alarmierungsmethode_ (z.B. HTML-Email) und dazu optional _Parameter_

Anders als bei den link:wato_rules.html[Regeln für Host- und Serviceparameter] geht die
Auswertung hier auch nach einer zutreffenden Regel weiter! Die nachfolgenden Regeln
können weitere Alarmierungen hinzufügen. Auch können sie Alarmierungen
wieder link:notifications.html#cancel[_löschen_], welche vorherige Regeln
generiert haben.  Das Endergebnis der Regelauswertung ist eine Tabelle,
die etwa folgenden Aufbau hat:

[cols=3]
|===
|Wer (Kontakt) |Wie (Methode) |Parameter 

|Harry Hirsch |Email |`Reply-To: linux.group@example.com`
|Bruno Weizenkeim |Email |`Reply-To: linux.group@example.com`
|Bruno Weizenkeim |SMS |
|===


Nun wird pro Eintrag in dieser Tabelle das zur Methode gehörende
link:notifications.html#scripts[Alarmierungsskript] aufgerufen, welches die
eigentliche Alarmierung durchführt.


=== Vordefinierte Regel

Wenn Sie {CMK} frisch aufgesetzt haben, dann finden Sie genau eine Regel
vordefiniert:

[{image-border}]
image::default_notification_rule.png[]

Diese eine Regel setzt das oben beschrieben Defaultverhalten um. Sie hat folgenden Aufbau:

[cols=2]
|===

|*Bedingung* |_keine_, gilt also für alle Ereignisse
|*Methode* |Versand einer Email im HTML-Format (mit eingebetteten Metrikgraphen)
|*Kontakte* |alle Kontakte des betroffenen Hosts/Services
|===


Wie gewohnt, können
Sie die Regel icon:icon_edit[] editieren, icon:button_clone[] kopieren,
icon:icon_delete[] löschen oder eine neue Regel anlegen. Sobald Sie mehr als
eine Regel haben, können Sie die Reihenfolge der Regeln per Drag&Drop über das
Symbol icon:icon_drag[] festlegen.

*Hinweis:* Änderungen an Alarmierungregeln erfordern *kein* [.guihint]#Activate Changes,#
sondern sind sofort wirksam!


=== Aufbau der Alarmierungsregeln

==== Generelle Eigenschaften

image::notification_rule_part1.png[]

Wie bei allen Regeln in {CMK}, können Sie hier eine Beschreibung und einen
Kommentar für die Regel hinterlegen sowie die Regel temporär abschalten. Die
Option [.guihint]#allow users to deactivate this notification# ist per Default
aktiviert. Sie erlaubt Benutzern, Alarme, die von dieser Regel erzeugt werden,
„abzubestellen“. Wie das geht, zeigen wir link:notifications.html#personal[weiter unten].


==== Alarmierungsmethode
image::notification_rule_part2.png[]

Die Alarmierungsmethode legt fest, auf welchem
technischen Weg alarmiert werden soll (z.B. _HTML Email_). Jede Methode
ist durch ein Skript realisiert. {CMK} liefert einige Skripten mit aus. Sie
können aber recht einfach link:notifications.html#scripts[eigene Skripte] in beliebigen Programmiersprachen schreiben,
um speziellere Alarmierungen umzusetzen (z.B. Weiterleitung der Alarme an
ein eigenes Ticketsystem).

Eine Methode kann _Parameter_ anbieten. Zum Beispiel erlauben es die Methoden
für ASCII- und HTML-Emails, die Absenderadresse (`From:`) explizit
zu setzen.

Bevor Sie hier Einstellungen direkt in der Regel machen, sollten Sie aber wissen, dass
Sie Parameter für die Alarmierungsmethoden auch per link:wato_rules.html[Host- und Serviceregeln]
setzen können: Bei den [.guihint]#Host- &amp; Serviceparameters# finden Sie unter [.guihint]#Monitoring Configuration > Notifications#
für jede Alarmierungsmethode einen Regelsatz, mit dem Sie
die gleichen Einstellungen festlegen können -- und das wie gewohnt sogar
abhängig von Host oder Service.

Parameterdefinitionen in Alarmierungsregeln dienen dazu, für Einzelfälle von
diesen Einstellungen abzuweichen.  So können Sie z.B. global einen bestimmten
Betreff für Ihre Email festlegen, aber in einer einzelnen Alarmierungsregel
einen alternativen Betreff definieren.

Anstelle von Parametern können Sie auch [.guihint]#Cancel all previous notifications#
auswählen. Dann werden Alarme dieser Methode aus früheren Regeln wieder verworfen.
Näheres dazu link:notifications.html#cancel[weiter unten.]


==== Kontaktauswahl
image::notification_rule_part3.png[]

Wenn die Bedingungen für eine Regel erfüllt sind, kommt als
nächstes die Kontaktauswahl. Der häufigste Fall ist, alle Benutzer
zu alarmieren, die als link:wato_user.html#contacts[Kontakt] für den jeweiligen Host/Service
eingetragen sind.  Dies ist das „normale“ Verhalten und naheliegend, da über
die Kontakte ebenfalls gesteuert wird, welcher Benutzer welche Objekte in
der GUI zu sehen bekommt und quasi dafür zuständig ist.

Sie können im Abschnitt [.guihint]#Kontaktauswahl# mehrere Optionen ankreuzen und
so die Alarmierung auf mehr Kontakte ausweiten. Doppelte Kontakte werden von
{CMK} automatisch entfernt. Damit die Regel sinnvoll ist, muss mindestens
eine Auswahl getroffen werden.

Die beiden Optionen mit [.guihint]#Restrict by ...# arbeiten etwas anders. Hier
werden die durch die übrigen Optionen ausgewählten Kontakte wieder
_eingeschränkt_. Damit können Sie auch eine UND-Verknüpfung zwischen
Kontaktgruppen herstellen, um z.B. alle Kontakte zu alarmieren, die
gleichzeitig Mitglied der Gruppen `Linux` *und* `Datacenter`
sind.

Durch die Angabe von _expliziten E-Mail-Adressen_ können Sie Personen
benachrichtigen, die überhaupt nicht als Benutzer in {CMK} hinterlegt
sind. Dies macht natürlich nur bei den Alarmierungsmethoden Sinn, die Emails
verschicken.

Falls Sie bei der Methode [.guihint]#Cancel all previous notifications# gewählt haben,
werden nur Alarme an die hier gewählten Kontakte entfernt!


==== Bedingungen
image::notification_rule_part4.png[]

Bedingungen legen fest, wann eine Regel Anwendung findet. Solange
keine Bedingung definiert ist, greift die Regel bei _jedem_
Ereignis. Einzelheiten über die Auswirkung der verschiedenen Bedingungen
erfahren Sie aus der icon:icon_help[] Onlinehilfe.

Für das Verständnis ist es wichtig, dass Sie sich daran erinnern, dass der
Ausgangspunkt immer ein Ereignis von einem ganz konkreten Host oder Service
ist. Die Bedingungen befassen sich dabei mit den statischen Eigenschaften
des Objekts (z.B. ob der Servicename den Text `/tmp` enthält), mit
dem aktuellen Zustand (z.B. ob der Service gerade von {OK}
nach {CRIT} gewechselt hat) oder mit ganz anderen Dingen
(z.B. ob die link:timeperiods.html[Zeitperiode] _Arbeitszeit_ gerade aktiv ist).

Wenn ein Ereignis auch nur eine der konfigurierten Bedingungen nicht
erfüllt, kommt die Regel nicht zur Anwendung. Eine Besonderheit dabei
sind die Bedingungen [.guihint]#Match host event type# und [.guihint]#Match service event type#:

[{image-border}]
image::notification_rule_part4b.png[]

Falls Sie *nur* [.guihint]#Match host event type# auswählen, wird die Regel auf keinen
einzigen Servicealarm matchen und umgekehrt. Falls Sie aber *beide*
Bedingungen aktivieren, matcht die Regel, falls der Ereignistyp in einer
der beiden Checkboxlisten aktiviert ist. In diesem Ausnahmefall werden diese
beiden Bedingungen also nicht wie üblich mit einem logischen UND verknüpft,
sondern mit einem ODER. So können Sie bequemer Host- und Servicealarme mit
einer einzelnen Regel verwalten.

Ein Hinweis noch zu den Bedingungen [.guihint]#Match contacts# und [.guihint]#Match contact groups#:
Hier wird als _Bedingung_ geprüft, ob der Host/Service, um den es geht,
eine bestimmte Kontaktzuordnung hat. Damit kann man Dinge machen wie _„Alarme
zu Hosts in der Kontaktgruppe Linux sollen nie per SMS versendet werden“_.
Das hat nichts mit der oben beschriebenen Kontakt_auswahl_ zu tun:

[{image-border}]
image::notifications_match_contacts.png[]


[#cancel]
=== Löschen von Alarmen

Bei der Auswahl der Methode finden Sie auch die Möglichkeit [.guihint]#Cancel all previous notifications#.
Um die Funktionsweise einer solchen Regel zu verstehen, stellen Sie sich am
besten die Alarmierungstabelle bildlich vor.
Nehmen Sie an, die Abarbeitung der Regeln zu einem konkreten Ereignis ist teilweise
gelaufen und durch etliche Regeln wurden folgende drei Alarmierungen erzeugt:

[cols=2]
|===
|Wer (Kontakt) |Wie (Methode) 

|Harry Hirsch |Email
|Bruno Weizenkeim |Email
|Bruno Weizenkeim |SMS
|===


Nun kommt eine Regel mit der Methode _SMS_ und der Auswahl
[.guihint]#Cancel previous notifications#.  Die Kontaktauswahl selektiert die
Gruppe _Windows_, in der auch _Bruno Weizenkeim_ Mitglied ist.
Dann wird aus der Tabelle die Zeile _Bruno Weizenkeim / SMS_ entfernt.
Nach dem Abarbeiten der Regel sieht die Tabelle also so aus:

[cols=2]
|===
|Wer (Kontakt) |Wie (Methode) 

|Harry Hirsch |Email
|Bruno Weizenkeim |Email
|===


Sollte eine spätere Regel wieder eine SMS-Alarmierungen für Bruno definieren,
so hätte diese Vorrang und die SMS würde wieder in die Tabelle aufgenommen.
Zusammengefasst:

* Regeln können gezielt Alarmierungen unterdrücken (löschen).
* Löschregeln müssen _nach_ den Regeln kommen, welche Alarme erzeugen.
* Eine Löschregel hebt nicht eine frühere _Regel_ auf, sondern Alarme, die aus (möglicherweise verschiedenen) früheren Regel stammen.
* Spätere Regeln können vormals gelöschte Alarme wieder hinzufügen.


[#fallback]
=== Was ist, wenn keine Regel greift?

Wer konfiguriert, kann auch Fehler machen. Ein möglicher Fehler bei der
Alarmierung wäre, dass das Monitoring ein kritisches Problem entdeckt und
keine einzige Alarmierungsregel greift.

Um Sie vor so einem Fall zu schützen, bietet {CMK} in den [.guihint]#Global settings#
die Einstellung [.guihint]#Notifications > Fallback email address for rule based notifications#.
Tragen Sie hier eine E-Mail-Adresse ein. An diese werden Alarme
verschickt, auf die keine einzige Alarmierungsregel greift.

Die Fallbackadresse wird allerdings nur dann verwendet,
wenn _keine Regel greift_, nicht wenn kein Alarm erzeugt würde! Denn das explizite
Löschen von Alarmen ist ja erwünscht und kein Konfigurationsfehler.

Die Angabe einer Fallbackadresse wird optisch „empfohlen“, durch eine Warnung:

image::warning_fallback_email.png[]

Falls Sie keinen Versand an diese Adresse wünschen, so tragen Sie einfach
_als erste_ Regel eine Regel ein, die alle bisherigen Alarmierungen
löscht. Diese Regel ist für die Alarmierung wirkungslos, da ja hier noch keine Alarme erzeugt
wurden. Aber damit stellen Sie sicher, dass immer eine Regel greift und lassen
die Warnung verschwinden.

[#personal]
== Benutzerdefinierte Alarmierung

=== Übersicht

Eine nützliche Besonderheit von {CMK}s Alarmierungssystem ist, dass
Benutzer sich auch ohne Administratorrechte ihre Alarmierung anpassen können.
Sie können

* Alarme hinzufügen, die sie sonst nicht bekommen würden („abonnieren“),
* Alarme löschen, die sie sonst bekommen würden (falls nicht gesperrt),
* Parameter von Alarmen anpassen und
* ihre Alarmierung vorübergehend ganz abschalten.

=== Benutzerdefinierte Regeln

Der Einstieg aus Sicht des Benutzers sind seine icon:button_sidebar_settings[] persönlichen
Einstellungen. Dort befindet sich der Knopf icon:context_button_notifications[], wo er
mit icon:context_button_new_rule[] neue Regeln erzeugen kann.

Benutzerdefinierte Regeln sind bis auf einen kleinen Unterschied fast wie die
normalen Regeln: Sie enthalten (natürlich) keine Kontaktauswahl. Als Kontakt
ist automatisch der Benutzer selbst gewählt. Dadurch kann ein Benutzer nur
für _sich selbst_ Alarme hinzufügen oder löschen.

Löschen kann der Benutzer Alarme nur dann, wenn in der Regel, die sie erzeugt,
die Option [.guihint]#allow users to deactivate this notification# aktiviert ist:

image::notification_rule_part1.png[]

Was die Reihenfolge betrifft, kommen die Benutzeregeln immer _nach_ den
globalen Regeln und sie können die bisher erzeugte Alarmtabelle anpassen. Bis
auf gerade beschriebene Sperren der Löschung gelten also die globalen Regeln
immer als Defaulteinstellung, die vom Benutzer angepasst werden kann.

Wenn Sie ein Anpassen ganz unterbinden möchten, können Sie der Rolle
der Benutzer die link:wato_user.html#roles[Berechtigung]
[.guihint]#General Permissions > Edit personal notification settings# entziehen.

Als Administrator können Sie sich alle Benutzerregeln anzeigen lassen, wenn Sie
icon:context_button_show_user_rules[] drücken:

[{image-border}]
image::user_notifications.png[]

Mit icon:button_edit[] können Sie diese auch editieren.


=== Vorübergehende Abschaltung

Die komplette Abschaltung der Alarmierung durch einen Benutzer selbst ist
mit der link:wato_user.html#roles[Berechtigung] [.guihint]#Disable all personal notifications#
geschützt, welche *per Default aus* ist. Nur wenn Sie dieses Recht
in die Rolle des Benutzers aufnehmen, bekommt er dafür in seinen persönlichen
Einstellungen eine entsprechende Checkbox:

image::disable_all_notifications.png[]

Da Sie als Administrator einfachen Zugriff auf die persönlichen Einstellungen
der Benutzer haben, können Sie das Abschalten auch stellvertretend für den
Benutzer machen -- auch wenn diesem oben genannte Berechtigung fehlt. Sie
finden diese in den Eigenschaften des Benutzerprofils. Damit können Sie
z.B. während eines Urlaubs eines Kollegen sehr schnell dessen Alarme still
schalten, ohne an der eigentlichen Konfiguration etwas ändern zu müssen.


[#conditions]
== Wann genau Alarme erzeugt werden

=== Einleitung

Ein großer Teil der Komplexität im Alarmierungssystem von {CMK} liegt
in den zahlreichen Tuningmöglichkeiten, mit denen unwichtige Alarme
vermieden werden können. Die meisten davon betreffen Situationen,
in denen bereits beim Auftreten der Ereignisse Alarme verzögert oder
unterdrückt werden. Auch gibt es eine im Monitoringkern eingebaute
Intelligenz, die bestimmte Alarme von Haus aus unterdrückt. Alle
diese Aspekte wollen wir Ihnen in diesem Kapitel vorstellen.

=== Geplante Wartungszeiten

[{image-left}]
image::icon_downtime.png[width=50]

Während sich ein Host oder Service in einer link:basics_downtimes.html[geplanten Wartungszeit]
befindet, ist für dieses Objekt die Alarmierung
unterdrückt. Das ist -- neben einer korrekten Berechnung von
Verfügbarkeiten -- der wichtigste Grund, warum man überhaupt eine Wartungszeit im Monitoring
hinterlegt. Interessant sind dabei folgende Details:

// LI:Ist beim link:cmc.html[CMC] ein Host in Wartung, dann gelten _automatisch_ auch alle seine Services als in Wartung, ohne dass man explizit eine Wartung für diese eintragen muss. Bei Nagios gilt das _nicht_.
* Ist ein Host in Wartung, dann gelten _automatisch_ auch alle seine Services als in Wartung, ohne dass man explizit eine Wartung für diese eintragen muss.
* Endet die Wartungszeit eines Objekts, das _während_ der Wartungszeit in einen Problemzustand gewechselt hat, dann wird dieses Problem exakt beim Ablauf der Wartung nachträglich alarmiert.
* Der Beginn und das Ende einer Wartungszeit selbst ist auch ein Ereignis, welches alarmiert wird.

Services, die sich in einer Wartungszeit befinden, werden mit einem orangen Pause-Zeichen
icon:icon_downtime[] markiert, Hosts mit einem blauen icon:icon_derived_downtime[].
Auch Services, dessen Hosts sich in Wartung befinden, bekommen
das blaue Pause-Zeichen.

=== Alarmierungsperioden

[{image-left}]
image::icon_outofnot.png[width=50]

Per Konfiguration können Sie für jeden Host und Service eine Alarmierungsperiode festlegen.
Dies ist eine link:timeperiods.html[Zeitperiode], welche Zeiträume festlegt, auf die die Alarmierung
beschränkt werden soll.

Die Konfiguration geschieht über die Regelsätze
[.guihint]#Monitoring Configuration > Notification period for hosts#
bzw. [.guihint]#... services#. Ein Objekt, welches sich gerade nicht in seiner
Alarmierungsperiode befindet, wird durch ein graues Pause-Zeichen icon:icon_outofnot[] markiert.

Ereignisse zu einem Objekt, das sich gerade _nicht_ in seiner
Alarmierungsperiode befindet, werden nicht alarmiert. Alarme werden nachgeholt,
wenn die Alarmierungsperiode wieder aktiv wird und der Host/Service sich
immer noch in einem Problemzustand befindet. Dabei wird nur der jeweils
letzte Zustand alarmiert, auch wenn es außerhalb der Periode mehrere
Zustandswechsel gab.

Übrigens gibt es auch bei den Alarmierungsregeln die Möglichkeit, eine
Alarmierung auf eine bestimmte Zeitperiode zu beschränken. Damit können Sie
die Zeitbereiche _zusätzlich_ einschränken. Allerdings werden Alarme,
die durch eine Regel mit Zeitbedingung verworfen wurden, später *nicht*
automatisch nachgeholt!


=== Der Zustand des Hosts, auf dem ein Service läuft

Wenn ein Host komplett ausfällt oder zumindest für das Monitoring nicht
erreichbar ist, können natürlich auch die Services des Hosts nicht mehr
überwacht werden. _Aktive_ Checks werden dann in der Regel {CRIT} oder
{UNKNOWN}, weil diese gezielt versuchen, den Host zu erreichen und dabei in
einen Fehler laufen. Alle anderen Checks -- also die überwiegende Mehrheit --
werden in so einem Fall ausgelassen und verharren in ihrem alten Zustand. Sie
werden mit der Zeit icon:icon_stale[] [.guihint]#stale#.

Natürlich wäre es sehr lästig, wenn alle Probleme von aktiven Checks in so
einem Zustand alarmiert würden. Denn wenn z.B. ein Webserver nicht erreichbar
ist -- und dies auch schon alarmiert wurde -- wäre es wenig informativ,
wenn nun auch für jeden einzelnen HTTP-Dienst, den dieser bereit stellt, eine
Email generiert würde.

Um dies zu vermeiden, erzeugt der Monitoringkern für Services grundsätzlich
nur dann Alarme, wenn der Host den Zustand {UP} hat. Das
ist auch der Grund, warum die Erreichbarkeit von Hosts separat überprüft wird.
Wenn Sie nichts anderes konfiguriert haben, geschieht dies durch einen Ping.

{cre-only}
Wenn Sie die {RE} verwenden (oder einer der {EE} mit
Nagios als Kern), dann kann es in seltenen Fällen bei einem Host-Problem
trotzdem zu einer Alarmierung eines aktiven Services kommen. Der Grund liegt
darin, dass Nagios die Resultate von Hostchecks für eine kurze Zeit in der
Zukunft als gültig betrachtet. Wenn zwischen dem letzten erfolgreichen Ping
an den Server und dem nächsten aktiven Checks nur wenige Sekunden vergehen,
kann es sein, dass Nagios den Host noch als {UP} wertet, obwohl dieser bereits
{DOWN} ist. Der CMC hingegen hält den Service-Alarm solange in Wartestellung,
bis der Zustand des Hosts geklärt ist und vermeidet den unerwünschten
Alarm so zuverlässig.


[#parents]
=== Parenthosts

Stellen Sie sich vor, ein wichtiger Netzwerkrouter zu einem
Unternehmensstandort mit Hunderten von Hosts fällt aus. Alle Hosts sind
dann für das Monitoring nicht mehr erreichbar und gehen auf {DOWN}. Hunderte
Alarmierungen werden ausgelöst. Nicht sehr schön.

Um das zu vermeiden, können Sie den Router als link:wato_hosts.html#parents[Parenthost]
der Hosts definieren. Wenn es redundante Routen gibt, kann man auch mehrere
Parents definieren. Sobald alle Parents auf {DOWN} gehen, werden die jetzt
nicht erreichbaren Hosts auf den Zustand {UNREACH} gesetzt und die Alarmierung
für diese wird unterdrückt. Das Problem mit dem Router selbst wird hingegen
durchaus alarmiert.

{cee-only}
Der link:cmc.html[CMC] verhält sich intern übrigens geringfügig anders
als Nagios.  Um Fehlalarme zu vermeiden, richtige Alarme aber korrekt
durchzuführen, achtet er sehr genau auf die exakten _Zeitpunkte_
der jeweiligen Hostchecks. Scheitert ein Hostcheck, so
wartet der Kern zunächst das Ergebnis des Hostchecks der Parenthosts ab,
bevor ein Alarm erzeugt wird. Dieses Warten geschieht asynchron und ohne das
übrige Monitoring zu beeinträchtigen. Alarmierungen von Hosts können sich
dadurch geringfügig verzögern.


=== Per Regel abgeschaltete Alarmierung

Über die Regelsätze [.guihint]#Monitoring configuration > Enable/disable notifications for hosts#
bzw. [.guihint]#... for services# können Sie Hosts und Services bestimmen,
für die grundsätzliche keine Alarme erzeugt werden sollen. Wie oben erwähnt,
unterbindet dann bereits der Kern eine Alarmierung. Eine nachträgliche Alarmierungsregel
für ein „abonnieren“ von Alarmen solcher Services wäre _wirkungslos!_


=== Manuelles Abschalten der Alarmierung

[{image-left}]
image::icon_notif_man_disabled.png[width=50]

Auch ist es möglich, bei einzelnen Hosts oder Services per link:commands.html[Kommando] die Alarmierung
vorübergehend abzuschalten:



image::disable_notifications.png[]

Solche Hosts oder Services werden dann mit einem Icon icon:icon_notif_man_disabled[] markiert.
Da Kommandos im Gegensatz zu Regeln weder Konfigurationsberechtigung noch ein
[.guihint]#Acivate changes# benötigen, können sie daher eine schnelle Lösung für das Operating sein, auf
eine Situation zu reagieren.

*Wichtig:* Im Gegensatz zu icon:icon_downtime[] Wartungszeiten, haben
abgeschaltete Alarme keinen Einfluss auf die Berechnung der link:availability.html[Verfügbarkeit.]
Wenn Sie also während eines ungeplanten Ausfalls einfach nur die Alarmierung abschalten
aber Ihre Verfügbarkeitsberechnung nicht verfälschen möchten, sollten Sie keine
Wartungszeiten dafür eintragen!


=== Alarmierung global ausschalten

In der [.guihint]#Master control# finden Sie einen Hauptschalter für die
Alarmierung:

image::notifications_disabled.png[width=240]

Dieser Schalter ist ausgesprochen nützlich, wenn Sie am System größere
Änderungen vornehmen, durch die bei einem Fehler unter Umständen eine
Vielzahl von Services auf kritisch geht. Sie ersparen sich so den Unmut
Ihrer Kollegen über die vielen nutzlosen Emails. Bitte vergessen Sie
aber nicht, die Alarmierung später wieder einzuschalten.

Im link:distributed_monitoring.html[verteilten Monitoring] gibt es diesen Schalter
einmal pro Instanz. Ein Abschalten der Alarmierung auf der Masterinstanz
lässt Alarme auf den Slaves weiterhin aktiviert -- selbst wenn diese zentral
zum Master weitergeleitet und von dort zugestellt werden.

Alarme, die angefallen wären, während die Alarmierung abgeschaltet war,
werden beim Wiedereinschalten *nicht nachgeholt.*


=== Verzögerung der Alarmierung

Vielleicht haben Sie Services, die gelegentlich für kurze Zeit in einen
Problemstatus gehen, der aber nur sehr kurz anhält und für Sie nicht
kritisch ist.  In solchen Fällen sind Alarme sehr lästig, aber auch einfach
zu unterdrücken. Dazu dienen die Regelsätze
[.guihint]#Monitoring configuration > Delay host notifications# und [.guihint]#Delay service notifications.#


Sie stellen hier eine Dauer in Minuten ein. Ein Alarm wird dann solange
zurückgehalten, bis diese Zeit abgelaufen ist. Tritt vorher der {OK} /
{UP}-Zustand wieder ein, so wird kein Alarm erzeugt.  Natürlich bedeutet
das aber dann auch, dass Sie im Falle eines _wirklichen_ Problems erst
mit einer Verzögerung alarmiert werden.

Und noch besser als eine Verzögerung der Alarmierung ist natürlich,
den eigentlichen Grund der sporadischen Probleme loszuwerden. Aber das ist
eine andere Geschichte ...


=== Mehrere Checkversuche

Eine zur Verzögerung der Alarmierung sehr ähnliche Methode ist das Erlauben
von mehreren Checkversuchen, wenn ein Service in einen Problemzustand geht. Dies geschieht
über die Regelsätze [.guihint]#Monitoring configuration > Maximum number of check attempts for host#
bzw. [.guihint]#... service.#

Wenn Sie hier z.B. eine 3 einstellen, dann führt ein Check mit dem Resultat
{CRIT} zunächst zu keiner Alarmierung. Man spricht dann zunächst von einem
_weichen_ {CRIT}-Zustand. Der _harte_ Zustand ist dann immer noch
{OK}. Erst wenn drei Versuche in Folge zu einem nicht-OK-Zustand führen,
wechselt der Service in den harten Zustand und eine Alarmierung wird ausgelöst.

Im Gegensatz zur verzögerten Alarmierung haben Sie hier noch die
Möglichkeit, sich Ansichten zu definieren, welche solche Probleme
ausblenden. Auch link:bi.html[BI-Aggregate] können so gebaut werden, dass nur
die harten Zustände berücksichtigt werden, nicht die weichen.


=== Unstetige Hosts und Services

[{image-left}]
image::icon_flapping.png[width=50]

Wenn ein Host oder Service binnen kurzer Zeit mehrfach den Zustand
ändert, so gilt er als _unstetig._ Dies ist sozusagen ein eigener
Zustand. Die Idee dabei ist das Vermeiden von exzessiven Alarmen in
Phasen, in denen ein Dienst nicht (ganz) stabil läuft. Auch in der
link:availability.html[Verfügbarkeitsberechnung] können Sie solche Phasen speziell
auswerten.

Unstetige Objekte werden mit dem Symbol icon:icon_flapping[] markiert.
Während ein Objekt unstetig ist, erzeugen weitere Zustandswechsel keine
Alarme mehr. Dafür wird aber jeweils ein Alarm ausgelöst, wenn das Objekt
in den Zustand unstetig ein- oder austritt.

Sie können die Erkennung von Unstetigkeiten auf folgende Arten beeinflussen:

* Die [.guihint]#Master control# hat einen Hauptschalter für die Erkennung von Unstetigkeiten [.guihint]#(Flap Detection).#
* Über die Regelsätze [.guihint]#Monitoring configuration > Enable/disable flapping detection for hosts# bzw. [.guihint]#... services# können Sie Objekte von der Erkennung ausklammern.
* In den {CEE} können Sie mit der globalen Option [.guihint]#Monitoring core > Tuning of flap detection# die Parameter der Unstetigkeitserkennung festlegen und sie mehr oder weniger empfindlich einstellen.

image::tuning_flap_detection.png[]

Bitte konsultieren Sie die icon:icon_help[] Onlinehilfe für Details zu den
einstellbaren Werten.


=== Periodisch wiederholte Alarmierungen und Eskalationen

Bei Systemen mit einem hohen Servicelevel kann es sinnvoll sein, es nicht
bei einer einzelnen Alarmierung zu belassen, falls das Problem über einen
längeren Zeitraum weiterhin besteht. Sie können {CMK} so einrichten,
dass es in einem festen Intervall immer weitere Alarme versendet, solange bis das Problem

* entweder icon:icon_ack[] quittiert
* oder behoben wurde.

Die Einstellung dafür finden Sie in den Regelsätzen
[.guihint]#Monitoring configuration > Periodic notifications during host problems#
bzw. [.guihint]#... service problems:#

image::periodic_notifications.png[]

Sobald diese Option aktiv ist, wird {CMK} für ein fortbestehendes Problem
im konfigurierten Intervall weitere Alarmierungen erzeugen. Die Alarme
bekommen eine laufende Nummer, welche bei 1 beginnt.

Periodische Alarme haben nicht nur den Nutzen, das Problem immer wieder in
Erinnerung zu rufen (also den Operator damit zu _nerven_), sondern sie
bilden auch die Grundlage für _Eskalationen._ Dies bedeutet, dass nach
Ablauf einer bestimmten Zeit die Alarmierung an andere Personen eskaliert
werden kann.

Um eine Eskalierung einzurichten, erzeugen Sie eine _zusätzliche_
Alarmierungsregel, welche die Bedingung
[.guihint]#Restrict to n<sup>th</sup> to m<sup>th</sup> notification# verwendet.
Tragen Sie hier als Bereich für die Laufnummern
3 bis 99999 ein, so greift diese Regel ab der dritten Alarmierung.
Die Eskalierung kann dann entweder durch die Wahl einer anderen
Methode (z.B. SMS) erfolgen oder durch die Alarmierung von anderen
Personen (Kontaktauswahl).

[{image-border}]
image::notification_escalation.png[]

Mit der Option [.guihint]#Throttle periodic notifications# können Sie die Rate der
wiederholten Alarme nach einer bestimmten Zeit reduzieren und so z.B. am
ersten Tag alle zwei Stunden eine Email senden lassen und später das Ganze
auf einmal am Tag beschränken.


== Der Weg eines Alarms von Anfang bis Ende

=== Überblick

Um die Zusammenhänge von allen Einstellmöglichkeiten und Rahmenbedingungen
genau zu verstehen und um eine sinnvolle Fehlerdiagnose zu ermöglichen,
wenn mal eine Alarmierung nicht wie erwartet geschieht oder ausbleibt,
beschreiben wir hier alle Einzelheiten zum Ablauf einer Alarmierung.
Dabei sind folgende Komponenten beteiligt:

[cols=3]
|===
|Komponente |Aufgabe |Logdatei 

|Nagios |Monitoringkern in der {CRE}. Der Kern erkennt Ereignisse und erzeugt _Rohalarme._ |`var/log/nagios.log +var/nagios/debug.log`
|CMC |Der link:cmc.html[{CMK} Micro Core] ist der Kern der {EE} und erfüllt die gleiche Aufgabe wie Nagios in der {CRE}. |`var/log/cmc.log`
|Alarmierungsmodul |Das Alarmierungsmodul wertet die Alarmierungsregeln aus, um aus einem Rohalarm fertige Alarme zu erzeugen. Es ruft die Alarmierungsskripten auf. |`var/log/notify.log`
|Alarmspooler |Der Alarmspooler (nur {EE}) dient der asynchronen Zustellung von Alarmen und dem zentralisierten Alarmieren in verteilten Umgebungen. |`var/log/mknotifyd.log`
|Alarmierungsskript |Für jede Alarmierungsmethode gibt es ein link:notifications.html#scripts[Skript,] welches die eigentliche Zustellung durchführt (z.B. eine HTML-Email generiert und versendet). |`var/check_mk/notify.log`
|===



=== Der Monitoringkern

==== Rohalarme

Wie oben beschrieben, beginnt jede Alarmierung mit einem Ereignis im
Monitoringkern. Wenn alle link:notifications.html#conditions[Bedingungen] erfüllt
sind und es grünes Licht für eine Alarmierung gibt, erzeugt der Kern einen
_Rohalarm_ an den internen Hilfskontakt [.guihint]#check-mk-notify.# Der
Rohalarm enthält noch keine Angabe zu den eigentlichen Kontakten oder der
Alarmierungsmethode.

In der Monitoringhistorie des Services sieht ein Rohalarm so aus:

[{image-border}]
image::raw_notification.png[]

* Das Symbol ist ein icon:icon_alert_cmk_notify[] hellgrauer Lautsprecher.
* Als Kontakt wird `check-mk-notify` angegeben.
* Als Alarmierungskommando wird `check-mk-notify` angegeben.

Der Rohalarm geht dann an das Alarmierungsmodul von {CMK}, welches die
Auswertung der Alarmierungsregeln übernimmt. Dieses Modul wird
von Nagios als externes Programm aufgerufen (`cmk --notify`). Der
CMC hingegen hält das Modul als permanenten Hilfsprozess in Bereitschaft
([.guihint]#Notification helper#) und vermeidet so das Erzeugen von Prozessen,
um Rechenzeit zu sparen.

==== Fehlerdiagnose im Monitoringkern Nagios

{cre-only}
Der in der {CRE} verwendete Nagios-Kern loggt alle Ereignisse nach
`var/log/nagios.log`. Diese Datei ist gleichzeitig der Ort, wo die
Monitoringhistorie gespeichert wird, welche Sie auch in der GUI abfragen,
wenn Sie z.B. die Alarme eines Hosts oder Services sehen möchten.

Interessanter sind aber die Meldungen in der Datei `var/nagios/debug.log`,
welche Sie bekommen, wenn Sie in `etc/nagios/nagios.d/logging.cfg`
die Variable `debug_level` auf `32` setzen.
Nach einem Core-Neustart{nbsp}...

[{shell}]
----
{c-omd} omd restart nagios
----

&#8230; finden Sie nützliche Informationen über Gründe, warum Alarme erzeugt oder
unterdrückt wurden:

.var/nagios/debug.log
[{file}]
----
[1592405483.152931] [032.0] [pid=18122] ** Service Notification Attempt ** Host: 'localhost', Service: 'backup4', Type: 0, Options: 0, Current State: 2, Last Notification: Wed Jun 17 16:24:06 2020
[1592405483.152941] [032.0] [pid=18122] Notification viability test passed.
[1592405485.285985] [032.0] [pid=18122] 1 contacts were notified.  Next possible notification time: Wed Jun 17 16:51:23 2020
[1592405485.286013] [032.0] [pid=18122] 1 contacts were notified.
----


==== Fehlerdiagnose im Monitoringkern CMC

{cee-only}
In den {CEE} finden Sie in der Logdatei
`var/log/cmc.log` ein Protokoll des Monitoringkerns. In der
Standardeinstellung enthält dies keine Angaben zu Alarmen. Sie können
aber ein sehr detailliertes Logging einschalten, mit der globalen Option
[.guihint]#Monitoring Core > Logging of the notification mechanics.# Der Kern gibt
dann darüber Auskunft, warum er ein Ereignis für die Alarmierung an das
Alarmsystem weitergibt oder warum (noch) nicht:

[{shell}]
----
{c-omd} tail -f var/log/cmc.log
2020-06-17 15:54:48 [5] [core 12317] Executing external command: PROCESS_SERVICE_CHECK_RESULT;localhost;backup3;2;myfakecheckresult
2020-06-17 15:55:54 [5] [core 12317] Executing external command: LOG;SERVICE NOTIFICATION: hh;localhost;backup3;CRITICAL;bulk mybulk;myfakecheckresult
2020-06-17 15:55:54 [5] [core 12317] Executing external command: LOG;SERVICE NOTIFICATION: hh;localhost;backup3;OK;bulk mybulk;OK - Backup3 is OK
2020-06-17 15:55:54 [5] [core 12317] Executing external command: LOG;SERVICE NOTIFICATION RESULT: hh;localhost;backup3;OK;bulk mybulk;;
----


Bitte beachten Sie, dass dies teilweise sehr viele Meldungen erzeugen kann. Es ist aber
nützlich, wenn man später die Frage beantworten will, warum in einer bestimmten
Situation _kein_ Alarm erzeugt wurde.



=== Regelauswertung durch das Alarmierungsmodul

Nachdem der Kern einen Rohalarm erzeugt hat, durchläuft dieser die
Kette der Alarmierungsregeln. Resultat ist eine Tabelle von Alarmen.
Neben den Daten aus dem Rohalarm enthält jeder Alarm folgende zusätzliche
Informationen:

* Den *Kontakt*, der alarmiert werden soll
* Die *Methode* für die Alarmierung
* *Parameter* für diese Methode

Bei einer synchronen Zustellung wird jetzt pro Eintrag in der Tabelle
das passende link:notifications.html#scripts[Alarmierungsskript] aufgerufen.
Bei einer link:notifications.html#async[asynchronen Zustellung] wird der Alarm
per Datei an den Alarmspooler übergeben.

==== Analyse der Regelkette in WATO

Wenn Sie komplexere Regelwerke erstellen, stehen Sie sicher gelegentlich vor
der Frage, welche Regeln denn nun auf einen bestimmten Alarm greifen. Dazu
bietet {CMK} eine im WATO-Modul icon:icon_notifications[]
[.guihint]#Notifications# eingebaute Analysefunktion, welche Sie mit dem Knopf
icon:context_button_analyse[] erreichen.

Im Analysemodus werden Ihnen standardmäßig die letzten zehn Rohalarme angezeigt,
die das System erzeugt hat und welche die Regeln durchlaufen haben:

[{image-border}]
image::notification_analysis.png[]

Sollten Sie für Ihre Analyse eine größere Menge an Rohalarmen benötigen, können
Sie die Anzahl bequem über
[.guihint]#Global Settings > Notifications > Store notifications for rule analysis# erhöhen:

image::notifications_storenotifications.png[]

Für jeden dieser Rohalarme stehen Ihnen drei Aktionen zur Verfügung:

[cols=2]
|===

|icon:icon_analyze[] |Diese Aktion testet die Regelkette, in dem für jede Regel geprüft wird, ob das gewählte Ereignis alle Bedingungen der Regel erfüllen würde. Im Anschluss an die Regeln wird dann die daraus resultierende Tabelle von Alarmen angezeigt.
|icon:icon_toggle_context[] |Anzeige des kompletten Alarmkontexts.
|icon:icon_replay[] |Diese Aktion wiederholt diesen Rohalarm, als wäre er jetzt aufgetreten. Ansonsten ist die Anzeige gleich wie bei der Analyse. Damit können Sie nicht nur die Bedingungen der Regel überprüfen, sondern auch testen, wie eine Alarmierung dann aussieht.
|===


==== Logdatei des Alarmierungsmoduls

Eine weitere wichtige Diagnosemöglichkeit ist die Logdatei
`var/log/notify.log`. Während Tests mit der Alarmierung bietet sich
dazu der beliebte Befehl `tail -f` an:

[{shell}]
----
{c-omd} tail -f var/log/notify.log`
2020-06-08 18:30:35 ----------------------------------------------------------------------
2020-06-08 18:30:35 Analysing notification (localhost;backup3) context with 71 variables
2020-06-08 18:30:35 Global rule 'Notify all contacts of a host/service via HTML email'...;
2020-06-08 18:30:35  -> matches!
2020-06-08 18:30:35    - adding notification of cmkadmin via mail
2020-06-08 18:30:35 Executing 1 notifications:
2020-06-08 18:30:35   * notifying cmkadmin via mail, parameters: (no parameters), bulk: no
----

Die globale option [.guihint]#Notifications > Notification log level# steuert die
Ausführlichkeit dieser Datei in zwei Stufen. Stellen Sie dieses
auf [.guihint]#Full dump of all variables and command,# so finden Sie in der Logdatei
eine komplette Auflistung aller Variablen, die dem
link:notifications.html#scripts[Alarmierungsskript] bereitgestellt werden.

image::notification_log_level.png[]

Dies sieht dann z.B. so aus (Auszug):

.var/log/notify.log
[{file}]
----
2020-06-08 18:38:42 ----------------------------------------------------------------------
2020-06-08 18:38:42 Got raw notification (localhost;backup3) context with 71 variables
2020-06-08 18:38:42 Raw context:
                    CONTACTS=
                    HOSTACKAUTHOR=
                    HOSTACKCOMMENT=
                    HOSTADDRESS=localhost
                    HOSTALIAS=localhost
                    HOSTATTEMPT=1
                    HOSTCHECKCOMMAND=check-mk-host-ping

----


[#async]
=== Asynchrone Zustellung durch Alarmspooler

==== Synchron oder Asynchron

{cee-only}
Eine mächtige Zusatzfunktion der CEE ist der _Alarmspooler._ Dieser
ermöglicht eine asynchrone Zustellung von Alarmen. Was bedeutet asynchron
in diesem Zusammenhang?

 +

[cols=2]
|===

|*Synchrone Zustellung* |Das Alarmierungsmodul wartet, bis das link:notifications.html#scripts[Alarmierungsskript] fertig ausgeführt wurde. Sollte dies eine längere Ausführungszeit haben, stauen sich weitere Alarme auf. Wird das Monitoring angehalten, gehen diese Alarme verloren. Außerdem kann sich bei vielen Alarmen in kurzer Zeit ein Rückstau bis zum Kern bilden, so dass das Monitoring dadurch ins Stocken gerät.
|*Asynchrone Zustellung* |Jeder Alarm wird in einer Spooldatei unter `var/check_mk/notify/spool` abgelegt. Es kann sich kein Stau bilden. Bei einem Stopp des Monitorings bleiben die Spooldateien erhalten und Alarme werden später korrekt zugestellt. Das Abarbeiten der Spooldateien übernimmt der _Alarmspooler._
|===


Eine synchrone Zustellung ist dann vertretbar, wenn das Alarmierungsskript
schnell läuft und vor allem nicht in irgendeinen Timeout geraten kann. Bei
Alarmierungsmethoden, die auf vorhandene Spooler zurückgreifen, ist das
gegeben. Insbesondere bei Email und SMS kommen Spooldienste vom System zum
Einsatz. Das Alarmierungsskript übergibt eine Datei an den Spooler, wobei
keine Wartezustände auftreten können.

Bei Verwendung der link:notifications.html#syncsmtp[nachvollziehbaren Zustellung per SMTP]
oder anderen Skripten, welche Netzwerkverbindungen aufbauen,
sollten Sie *auf jeden Fall* asynchrone Zustellung einstellen. Dazu
gehören auch Skripte, welche per HTTP Textnachrichten (SMS) über das
Internet versenden.  Die Timeouts bei der Verbindung zu einem Netzwerkdienst
können bis zu mehrere Minuten lang sein und einen oben beschriebenen
Stau auslösen.


==== Asynchrone Zustellung konfigurieren

Seit Version {v16} ist die asynchrone Zustellung per Default
aktiviert. Bei älteren Versionen holen Sie dies wie folgt nach:

Stellen Sie zunächst sicher, dass der Alarmspooler (`mknotifyd`)
aktiviert ist. Dieser muss bei `omd status` angezeigt werden:

[{shell}]
----
{c-omd} omd status
mkeventd:       [green]#running#
liveproxyd:     [green]#running#
[hilite]#mknotifyd:#      [green]#running#
rrdcached:      [green]#running#
cmc:            [green]#running#
apache:         [green]#running#
crontab:        [green]#running#
-----------------------
Overall state:  [green]#running#
----

Fehlt hier der `mknotifyd`, so können Sie diesen aktivieren mit:

[{shell}]
----
{c-omd} omd -f config set MKNOTIFYD on
----

Der zweite Schritt ist das Aktivieren der asynchronen Zustellung. Setzen
Sie dazu die globale Einstellung [.guihint]#Notifications > Notification spooling#
auf den Wert [.guihint]#Asynchronous local delivery by notification spooler#:

image::notification_spooling.png[]

==== Fehlerdiagnose

Der Alarmspooler pflegt eine eigene Logdatei: `var/log/mknotifyd.log`.
Diese verfügt über drei Loglevels, welche Sie in der globalen Option
[.guihint]#Notifications > Notification spooler configuration > Verbosity of logging#
einstellen können. Per Default werden nur Start, Ende und Fehlermeldungen
geloggt. Bei der mittleren Stufe,
[.guihint]#Verbose logging (also spooled notifications),# können Sie das Bearbeiten der Spooldateien
sehen:

.var/log/mknotifyd.log
[{file}]
----
2020-06-08 19:08:19 [5] -----------------------------------------------------------------
2020-06-08 19:08:19 [5] Check_MK Notification Spooler version 1.6.0p11 starting
2020-06-08 19:08:19 [5] Log verbosity: 1
2020-06-08 19:08:19 [5] Daemonized with PID 27962.
2020-06-08 19:11:42 [6] processing spoolfile: /omd/sites/testing/var/check_mk/notify/spool/c0cba13a-5317-41dd-aeda-8344825f7961
----


[#bulk]
== Sammelalarmierung (Bulk notifications)

=== Übersicht

Jeder, der mit Monitoring arbeitet, hat schon einmal erlebt, dass ein
isoliertes Problem eine ganze Flut von (Folge-)Alarmen losgetreten hat.
Das Prinzip der link:notifications.html#parents[Parenthosts] ist ein Weg, dies in
bestimmten Fällen zu vermeiden, hilft aber leider auch nicht in allen Fällen.

Nehmen Sie ein Beispiel aus dem {CMK}-Projekt selbst: Einmal pro Tag
bauen wir für jede unterstützte Linux-Distribution Installationspakete
von {CMK}. Unser eigenes {CMK}-Monitoring ist so eingerichtet, dass
wir für jede Distribution einen Service haben, der nur dann {OK} ist, wenn
die richtige Anzahl von Paketen korrekt gebaut wurde. Nun kommt es gelegentlich
vor, dass ein genereller Fehler in der Software das Paketieren verhindert
und so gleichzeitig 43 Services auf {CRIT} gehen.

Die Sammelalarmierung ist bei uns so konfiguriert, dass in so einem
Fall nur eine einzige Email versendet wird, welche alle 43 Alarme nacheinander
auflistet. Das ist natürlich viel übersichtlicher als 43 einzelne Emails
und verhindert, dass man im Eifer des Gefechts eine 44ste Email, die zu einem
ganz anderen Problem gehört, übersieht.

Die Funktionsweise der Sammelalarmierung ist sehr einfach. Wenn ein Alarm
auftritt, so wird dieser zunächst eine kurze Zeit lang zurückgehalten.
Weitere Alarme, die während dieser Zeit kommen, werden dann gleich mit
in dieselbe Email gepackt. Das Sammeln stellen Sie _pro Regel_
ein. So können Sie z.B. tagsüber mit Einzelmails arbeiten, nachts
aber mit einer Sammelalarmierung. Wird in einer Regel die Sammelalarmierung
aktiviert, so erhalten Sie folgende Optionen:

[{image-border}]
image::bulk_notifications.png[]

Die Wartezeit können Sie beliebig konfigurieren. In vielen Fällen
genügt eine Minute, da spätestens dann alle verwandten Probleme
aufschlagen sollten. Sie können das natürlich auch auf größere Zeiten
einstellen. Dadurch entsteht aber eine grundsätzliche Verzögerung der
Alarmierung.

Da es natürlich keinen Sinn macht, _alles_ in einen Topf zu werfen,
können Sie bestimmen, welche Gruppen von Problemen jeweils gemeinsam
alarmiert werden sollen. Üblicherweise wird die Option _Host_ gewählt,
die dafür sorgt, dass nur Alarme vom gleichen Host zusammengefasst werden.

Hier noch ein paar Fakten zur Sammelalarmierung:

* Wenn das Sammeln in einer Regel eingeschaltet ist, kann das mit einer späteren wieder ausgeschaltet werden und umgekehrt.
* Die Sammelalarmierung geschieht immer pro Kontakt. Jeder hat quasi seinen _privaten Sammeltopf._
* Sie können die Größe des Topfs limitieren. Bei Erreichen der Anzahl wird der Sammelalarm sofort verschickt.


=== Sammelalarme und Zeitperioden

Was ist eigentlich, wenn ein Alarm innerhalb der Alarmierungsperiode liegt,
die Sammelalarmierung, die ihn enthält -- die ja etwas später kommt -- dann aber schon außerhalb
liegt? Und auch der umgekehrte Fall ist ja möglich{nbsp}...

Hier gilt ein ganz einfaches Prinzip: Alle Konfigurationen, die Alarme auf
Zeitperioden eingrenzen, gelten immer nur *für den eigentlichen Alarm*. Die
später folgende Sammelalarmierung wird immer *unabhängig* von sämtlichen
Zeitperioden zugestellt.

[#syncsmtp]
== Nachvollziehbare Zustellung per SMTP

=== Email ist nicht zuverlässig

{cee-only}
Monitoring ist nur nützlich, wenn man sich auch darauf verlassen kann.
Dazu gehört, dass Alarme _zuverlässig_ und _zeitnah_ ankommen. Nun
ist die Zustellung von Emails hier leider nicht ganz ideal. Denn der Versand
geschieht üblicherweise durch Übergabe der Email an den lokalen SMTP-Server.
Dieser versucht dann die Email selbständig und asynchron zuzustellen.

Bei einem vorübergehenden Fehler (z.B. falls der empfangende SMTP-Server
nicht erreichbar ist) wird die Email in eine Warteschlange versetzt und
später ein erneuter Versuch gestartet.  Dieses „später“ ist dann in
der Regel frühestens in 15-30 Minuten. Aber dann kann die Alarmierung
eventuell schon viel zu spät sein!

Ist die Email gar nicht zustellbar, so erzeugt der SMTP-Server eine hübsche
Fehlermeldung in seiner Logdatei und versucht, an den „Absender“ eine
Fehleremail zu generieren. Aber das Monitoringsystem ist kein richtiger
Absender und kann auch keine Emails empfangen.  In der Folge gehen solche
Fehler dann einfach unter und Alarme bleiben aus.


=== SMTP auf direktem Weg ermöglicht Fehlerauswertung

Die {CEE} bieten die Möglichkeit einer _nachvollziehbaren_ Zustellung per SMTP. Dabei
wird bewusst auf eine Hilfe des lokalen Mailservers verzichtet. Anstelle dessen
sendet {CMK} selbst die Email direkt via SMTP zu Ihrem Smarthost und
wertet die SMTP-Antwort auch selbst aus.

Dabei werden nicht nur SMTP-Fehler intelligent behandelt, es wird auch
eine korrekte Zustellung genau protokolliert. Es ist ein bisschen wie ein
Einschreiben: {CMK} bekommt quasi vom SMTP-Smarthost (empfangender Server)
eine Quittung, dass die Email übernommen wurde -- inklusive einer Mail-ID.

In der Historie des betroffenen Services können Sie das dann genau sehen.
Hier ist ein Beispiel, in dem ein Service testweise von Hand auf {CRIT} gesetzt
wurde. Folgende Abbildung zeigt die Ansicht icon:context_button_notifications[]:

[{image-border}]
image::notification_smtp_success.png[]

Sie sehen dabei drei Einzelschritte:

. Der Monitoringkern erzeugt einen icon:icon_alert_cmk_notify[] Rohalarm.
. Die Auswertung der Regeln ergibt einen icon:icon_alert_notify[] Alarm an den Benutzer [.guihint]#hh# mit der Methode `mail`.
. Die Email wurde erfolgreich an den Smarthost übergeben icon:icon_alert_notify_result[]. Dessen Antwort ist `250 - Ok: queued as 12345ABCDE`.

Das Ausführen des Alarmierungsskripts und die Antwort vom SMTP-Server können Sie
auch im `notify.log` sehen:

.var/log/notify.log
[{file}]
----
2016-11-07 13:51:13 Got spool file c8c1f33a (myserver123;CPU utilization) for local delivery via mail
2016-11-07 13:51:13      executing /omd/sites/mysite/share/check_mk/notifications/mail
2016-11-07 13:51:14      Output: success 250 - 2.0.0 Ok: queued as ECB7A82019
----

Die Message-ID `12345ABCDE` wird im Logfile des Smarthosts
auftauchen. Dort können Sie dann im Zweifel recherchieren, wo die Email
verblieben ist. Auf jeden Fall können Sie so belegen, das und wann Sie
von {CMK} korrekt übergeben wurde.

Wiederholen wir den Test von oben, jedoch diesmal mit einem falsch konfigurierten
Passwort für die SMTP-Übergabe an den Smarthost. Hier sieht man im Klartext die
SMTP-Fehlermeldung vom Smarthost: `(535, '5.7.8 Error: authentication failed:')`

[{image-border}]
image::notification_smtp_failed.png[]

Doch was tun bei gescheiterten Alarmierungen? Diese wiederum per Email zu alarmieren
ist augenscheinlich keine gute Lösung. Anstelle dessen zeigt {CMK} einen deutlichen
Warnhinweis in der [.guihint]#Tactical Overview# an:

image::failed_notifications_to.png[width=240]

Hier können Sie

* durch Klick auf den Text [.guihint]#... failed notifications# zu einer Liste der fehlgeschlagenen Zustellungen kommen und
* durch Klick auf icon:button_delete[] diese Meldungen quittieren und damit den Hinweis wieder entfernen.

==== Konfiguration der asynchronen Zustellung

Bitte beachten Sie, dass die direkte Zustellung per SMTP in Fehlersituationen
dazu führen kann, dass das Alarmierungsskript sehr lange läuft und am
Ende in einen Timeout gerät. Deswegen ist es unbedingt ratsam, dass Sie den
Alarmspooler verwenden und eine link:notifications.html#async[asynchrone] Zustellung
von Alarmen einstellen.

Das Verhalten bei wiederholbaren Fehlern (wie einem SMTP-Timeout) können Sie
in den globalen Einstellungen unter [.guihint]#Notifications > Notification spooler configuration#
pro Alarmierungsmethode einstellen:

[{image-border}]
image::plugin_timing_settings.png[width=480]

Neben einem optionalen Timeout (Default ist 60 Sekunden) und einer maximalen
Anzahl von Wiederholversuchen, können Sie festlegen, ob das Skript mehrfach
parallel laufen und so gleichzeitig mehrere Alarme versenden darf
([.guihint]#Maximum concurrent executions#). Ist das Alarmierungsskript
sehr langsam, kann eine parallele Ausführung sinnvoll sein. Allerdings muss
es dann auch so programmiert sein, dass eine Mehrfachausführung sauber
läuft (und nicht das Skript z.B. bestimmte Dateien für sich
beansprucht).

Eine mehrfache parallele Zustellung per SMTP ist unproblematisch, da der
Zielserver mehrere parallele Verbindungen verwalten kann. Bei der Zustellung
von SMS direkt über ein Modem ohne weiteren Spooler ist das sicher nicht der
Fall und Sie sollten dann bei der Einstellung 1 bleiben.

==== SMS und andere Alarmierungsmehoden

Eine synchrone Zustellung inklusive Fehlermeldung und Nachvollziehbarkeit
ist aktuell nur für HTML-Emails implementiert.  Wie Sie in einem eigenen
Alarmierungsskript einen Fehlerstatus zurückgeben können, erfahren Sie im
link:notifications.html#scripts[Abschnitt über das Schreiben von eigenen Skripten].


[#distributed]
== Alarmierung in verteilten Systemen

In verteilten Umgebungen -- also solchen mit mehr als einer {CMK}-Instanz
-- stellt sich die Frage, was mit Alarmen geschehen soll, die auf entfernten
Instanzen erzeugt werden. Hier gibt es grundsätzlich zwei Möglichkeiten:

. Lokale Zustellung
. Zentrale Zustellung auf dem Master (nur CEE)

Einzelheiten dazu finden Sie im Artikel über
link:distributed_monitoring.html#notifications[Verteiltes Monitoring].


[#scripts]
== Alarmierungsskripten

=== Grundprinzip

Alarmierung kann auf sehr vielfältige und individuelle Weise
geschehen. Typische Fälle sind:

* Übergabe von Alarmen an ein Ticket- oder externes Alarmierungssystem
* Versand von SMS über verschiedene Internetdienste
* Automatisierte Anrufe
* Weiterleitung an ein übergeordnetes Monitoringsystem

Aus diesem Grund bietet {CMK} eine sehr einfache Schnittstelle, mit der
Sie selbst eigene Alarmierungsskripten schreiben können.  Sie können diese
in jeder von Linux unterstützten Programmiersprache schreiben -- auch wenn
Shell, Perl und Python zusammen hier sicher 95% „Marktanteil“ haben.

//Die von {CMK} link:notifications.html#includedscripts[mitgelieferten Skripten] liegen unter
Die von {CMK} mitgelieferten Skripten liegen unter
`share/check_mk/notifications`.  Dieses Verzeichnis ist Teil der
Software und nicht für Änderungen vorgesehen. Legen Sie eigene Skripten
stattdessen in `local/share/check_mk/notifications` ab. Achten Sie
darauf, dass sie ausführbar sind (`chmod +x`). Sie werden dann
automatisch gefunden und bei den Alarmierungsregeln zur Auswahl angeboten.

Möchten Sie ein mitgeliefertes Skript anpassen, so kopieren
Sie es einfach von `share/check_mk/notifications` nach
`local/share/check_mk/notifications` und machen dort Ihre
Änderungen. Wenn Sie dabei den Dateinamen beibehalten, ersetzt Ihr
Skript automatisch die Originalversion und Sie müssen keine bestehenden
Alarmierungsregeln anpassen.

Einige weitere Beispielskripten werden unter
`share/doc/check_mk/treasures/notifications` mitgeliefert. Sie können
diese als Vorlage nehmen und anpassen. Die Konfiguration wird meist direkt
im Skript vorgenommen -- Hinweise dazu finden Sie dort in den Kommentaren.

Im Falle eines Alarms wird Ihr Skript mit den Rechten des Instanzbenutzers
aufgerufen. In *Umgebungsvariablen,* die mit `NOTIFY_` beginnen,
bekommt es alle Informationen über den betreffenden Host/Service,
das Ereignis, den zu alarmierenden Kontakt und Parameter, die
in der Alarmierungsregel angegeben wurden.

Texte, die das Skript in die *Standardausgabe* schreibt (`print`,
`echo`, etc.), erscheinen in `var/log/notify.log`.


=== Nachvollziehbare Alarmierung

{cee-only}
Alarmierungsskripte haben die Möglichkeit, über den Exitcode mitzuteilen,
ob ein wiederholbarer Fehler aufgetreten ist oder ein endgültiger:



[cols=2]
|===
|Exitcode |Bedeutung

|0 |Das Skript wurde erfolgreich ausgeführt.
|1 |Ein temporärer Fehler ist aufgetreten. Die Ausführung soll nach kurzer Zeit erneut probiert werden, bis die konfigurierte maximale Anzahl von Versuchen erreicht ist. Beispiel: HTTP-Verbindung zu SMS-Dienst konnte nicht aufgebaut werden.
|`2` und höher |Ein endgültiger Fehler ist aufgetreten. Die Alarmierung wird nicht wiederholt. Auf der GUI wird ein Alarmierungsfehler angezeigt. Der Fehler wird in der Historie des Hosts/Services angezeigt. Beispiel: der SMS-Dienst meldet den Fehler „Ungültige Authentifizierung“.
|===


Zudem wird in allen Fällen die *Standardausgabe* des
Alarmierungsskripts zusammen mit dem Status in die Monitoringhistorie des
Hosts/Services eingetragen und ist somit über die GUI sichtbar.

*Wichtig:* Für xref:#bulk[Sammelbenachrichtigungen] steht die nachvollziehbare Benachrichtigung nicht zur Verfügung!

Die Behandlung von Alarmierungsfehlern aus Sicht des Benutzers wird beim
Kapitel über link:notifications.html#syncsmtp[nachvollziehbare Zustellung per SMTP]
erklärt.


=== Ein einfaches Beispiel

Als Beispiel können Sie ein Skript erstellen, das alle Informationen zu dem Alarm
in eine Datei schreibt. Als Sprache kommt die Linux-Shell (BASH) zum Einsatz:

.local/share/check_mk/notifications/foobar
[{file}]
----
#!/bin/bash
# Foobar Teleprompter

env | grep NOTIFY_ | sort > $OMD_ROOT/tmp/foobar.out
echo "Successfully written $OMD_ROOT/tmp/foobar.out"
exit 0
----

Danach machen Sie das Skript ausführbar:

[{shell}]
----
{c-omd} chmod +x local/share/check_mk/notifications/foobar
----

Hier einige Erklärungen zum Skript:

* In der ersten Zeile stehen `#!` und der Pfad zum Interpreter der Skriptsprache (hier `/bin/bash`).
* In der zweiten Zeile steht nach dem Kommentarzeichen `#` ein *Titel* für das Skript. Dieser wird bei der Auswahl der Alarmierungsmethode in der Regel angezeigt.
* Der Befehl `env` gibt alle Umgebungsvariablen aus, die das Skript bekommen hat.
* Mit `grep NOTIFY_` werden die Variablen von {CMK} herausgefiltert{nbsp}...
* &#8230; und mit `sort` alphabetisch sortiert.
* `&gt; $OMD_ROOT/tmp/foobar.out` schreibt das Ergebnis in die Datei `tmp/foobar.out` innerhalb der Instanz.
* Das `exit 0` wäre an dieser Stelle eigentlich überflüssig, da die Shell immer den Exitcode des letzten Befehls übernimmt. Dieser ist hier `echo` und immer erfolgreich. Aber explizit ist immer besser.


==== Testlauf

Damit das Skript verwendet wird, müssen Sie es in einer Alarmierungsregel
als Methode einstellen. Selbstgeschriebene Skripte haben keine Parameterdeklaration.
Daher fehlen die ganzen Checkboxen, wie sie z.B. bei [.guihint]#HTML Email# angeboten
werden. Anstelle dessen kann der Benutzer eine Liste von Texten als Parameter
angeben, die dem Skript als `NOTIFY_PARAMETER_1` usw. bereitgestellt werden.
Für den Test übergeben Sie die Parameter `Fröhn`, `Klabuster`
und `Feinbein`:

image::notify_foobar.png[]

Nun setzen Sie zum Test den Service `CPU load` auf dem Host `myserver`
auf {CRIT}. Im `notify.log` sehen Sie die Ausführung des Skripts samt Parametern
und der erzeugten Spooler-Datei:

// Alt:
// sehen wir die Ausführung des Skripts und dessen einzeilige Ausgabe „`Successfully written ...`“

.var/log/notify.log
[{file}]
----
2020-06-09 21:18:47 Executing 1 notifications:
2020-06-09 21:18:47   * notifying hh via foobar, parameters: Fröhn, Klabuster, Feinbein, bulk: no
2020-06-09 21:18:47 Creating spoolfile: /omd/sites/mysite/var/check_mk/notify/spool/0168d6d5-7912-472c-aec0-affa60e5e3db
----

// Alt:
// 2016-11-15 12:30:49 executing /omd/sites/mysite/local/share/check_mk/notifications/foobar
// 2016-11-15 12:30:49 Output: Successfully written /omd/sites/mysite/tmp/foobar.out

Die Datei `tmp/foobar.out` enthält nun eine alphabetische Liste
aller {CMK}-Umgebungsvariablen, die Informationen über den Alarm
beinhalten. Dort können Sie sich orientieren, was für Werte für Ihr Skript
zur Verfügung stehen. Hier die ersten zehn Zeilen:

[{shell}]
----
{c-omd} head tmp/foobar.out
NOTIFY_CONTACTALIAS=Harry Hirsch
NOTIFY_CONTACTEMAIL=harryhirsch@checkmk.com
NOTIFY_CONTACTNAME=hh
NOTIFY_CONTACTPAGER=
NOTIFY_CONTACTS=hh
NOTIFY_DATE=2020-06-09
NOTIFY_HOSTACKAUTHOR=
NOTIFY_HOSTACKCOMMENT=
NOTIFY_HOSTADDRESS=127.0.0.1
NOTIFY_HOSTALIAS=myserver
----

Auch die Parameter lassen sich hier wiederfinden:

[{shell}]
----
{c-omd} grep PARAMETER tmp/foobar.out
NOTIFY_PARAMETERS=Fröhn Klabuster Feinbein
NOTIFY_PARAMETER_1=Fröhn
NOTIFY_PARAMETER_2=Klabuster
NOTIFY_PARAMETER_3=Feinbein
----

=== Umgebungsvariablen

Im obigen Beispiel haben Sie einige Umgebungsvariablen gesehen, die dem
Skript übergeben wurden. Welche Variablen genau bereitstehen, hängt von
der Art des Alarms und auch von der verwendeten {CMK}-Version und -Edition
ab. Neben dem Trick mit dem `env` gibt es noch zwei weitere Wege
zu einer vollständigen Liste aller Variablen:

* Das Hochschalten des Loglevels für `notify.log` in den globalen Einstellungen.
* Bei der Alarmierung per [.guihint]#HTML Email# gibt es eine Checkbox [.guihint]#Information to be displayed in the email body# und dort den Punkt [.guihint]#Complete variable list (for testing)#.

Folgendes sind die wichtigsten Variablen:

[cols=2]
|===

|OMD_ROOT |Homeverzeichnis der Instanz, z.B. `/omd/sites/mysite`
|OMD_SITE |Name der Instanz, z.B. `mysite`
|NOTIFY_WHAT |Bei Hostalarmen das Wort `HOST`, sonst `SERVICE`. Damit können Sie Ihr Skript so intelligent machen, dass es in beiden Fällen sinnvolle Informationen meldet.
|NOTIFY_CONTACTNAME |Benutzername (Login) des zu alarmierenden Kontakts
|NOTIFY_CONTACTEMAIL |E-Mail-Adresse des zu alarmierenden Kontakts
|NOTIFY_CONTACTPAGER |Eintrag im Feld [.guihint]#Pager# des Benutzerprofils des Kontakts. Da das Feld meist nicht für einen bestimmten Zweck belegt ist, können Sie es einfach nutzen, um eine für die Alarmierung nötige Information pro Benutzer zu speichern.
|NOTIFY_DATE |Datum des Alarms im ISO-8601-Format, also z.B. `2020-06-09`
|NOTIFY_LONGDATETIME |Datum und Uhrzeit in der nicht-lokalisierten Defaultdarstellung des Linuxsystems, also z.B. `Tue Jun 09 12:31:06 CET 2020`
|NOTIFY_SHORTDATETIME |Datum und Uhrzeit im ISO-Format, also z.B. `2020-06-09 12:31:06`
|NOTIFY_HOSTNAME |Name des betroffenen Hosts im Monitoring
|NOTIFY_HOSTOUTPUT |Ausgabe des Hostcheck-Plugins (also z.B. „`Packet received via smart PING`“). Diese Ausgabe ist nur bei Hostalarmen interessant, aber auch bei Servicealarmen vorhanden.
|NOTIFY_HOSTSTATE |Eines der Worte `UP`, `DOWN` oder `UNREACH`
|NOTIFY_NOTIFICATIONTYPE |Der Typ des Alarms (siehe in der Einleitung dieses Artikels). Er wird durch eines der folgenden Worte ausgedrückt:  `PROBLEM` - Normales Host- oder Serviceproblem + `RECOVERY` -- Host-/Service geht wieder {UP} / {OK} + `ACKNOWLEDGEMENT (...)` -- link:basics_ackn.html[Quittierung] eines Problems + `FLAPPINGSTART` -- Ein Host-/Service beginnt unstetig zu sein + `FLAPPINGSTOP` -- Ende der Unstetigkeit + `DOWNTIMESTART` -- Beginn einer geplanten link:basics_downtimes.html[Wartung]. + `DOWNTIMEEND` -- Normales Ende einer Wartung + `DOWNTIMECANCELLED` -- Vorzeitiger Abbruch einer Wartung + `CUSTOM` -- Alarm, der per link:commands.html[Kommando] manuell ausgelöst wurde + `ALERTHANDLER (...)` -- Alerthandlerausführung {CEE}  Bei den Typen mit `(...)` stehen in der Klammer weitere Informationen über die Art des Alarms.
|NOTIFY_PARAMETERS |Alle Parameter des Skripts durch Leerzeichen getrennt
|NOTIFY_PARAMETER_1 |Der erste Parameter des Skripts
|NOTIFY_PARAMETER_2 |Der zweite Parameter des Skriptes, usw.
|NOTIFY_SERVICEDESC |Der Name des Services, der alarmiert wird. Bei Hostalarmen ist diese Variable nicht vorhanden.
|NOTIFY_SERVICEOUTPUT |Ausgabe des Check-Plugins des Servicechecks (nicht bei Hostalarmen)
|NOTIFY_SERVICESTATE |Eines der Worte `OK`, `WARN`, `CRIT` oder `UNKNOWN`
|===


=== Sammelalarme

Wenn Ihr Skript link:notifications.html#bulk[Sammelalarme] unterstützen soll,
müssen Sie es speziell dafür präparieren, da hier dem Skript _mehrere
Alarme auf einmal_ übergeben werden. Aus diesem Grund funktioniert dann
auch die Übergabe per Umgebungsvariablen nicht mehr sinnvoll.

Deklarieren Sie Ihr Skript in der _dritten Zeile_ im Kopf wie folgt,
dann sendet das Alarmierungsmodul die Alarme auf der _Standardeingabe:_

.local/share/check_mk/notifications/mybulk
[{file}]
----
#!/bin/bash
# My Bulk Notification
# Bulk: yes
----

Auf der Standardeingabe werden dem Skript Blöcke von Variablen gesendet.
Jede Zeile hat die Form `NAME=VALUE`. Blöcke werden getrennt durch
Leerzeilen. Das ASCII-Zeichen mit dem Code 1 (`\a`) wird verwendet,
um innerhalb der Texte Newlines darzustellen.

Der erste Block enthält eine Liste von allgemeinen Variablen (z.B. Aufrufparameter).
Jeder weitere Block fasst die Variablen zu einem Alarm zusammen.

Am besten, Sie probieren das Ganze erstmal mit einem einfachen Test aus,
der die kompletten Daten in eine Datei schreibt und sehen sich an, wie
die Daten gesendet werden. Das kann z.B. so gehen:

.local/share/check_mk/notifications/mybulk
[{file}]
----
#!/bin/bash
# My Bulk Notification
# Bulk: yes

cat > $OMD_ROOT/tmp/mybulktest.out
----

//SK: Kommentar wegnehmen, sobald die unterhalb verlinkten Artikel live sind.
//SK: auch am Anfang dieses Kapitels den Link auf dieses hier "aktivieren"

//H2:Mitgelieferte Alarmierungsskripten#includedscripts
//
//Im Auslieferungszustand bringt {CMK} bereits eine ganze Reihe von Anbindungen an
//beliebete und weit verbreitete Instant-Messaging-Dienste, Ticket- und On-Call
//Management-Systeme mit:
//
//LI:link:notifications_jira.html[Jira]
//LI:link:notifications_mattermost.html[Mattermost]
//LI:link:notifications_pagerduty.html[PagerDuty]
//LI:link:notifications_pushover.html[Pushover]
//LI:link:notifications_opsgenie.html[Opsgenie]
//LI:link:notifications_servicenow.html[ServiceNow]
//LI:link:notifications_slack.html[Slack]
//LI:link:notifications_victorops.html[VictorOps]

[#files]
== Dateien und Verzeichnisse

=== Pfade von {CMK}

[cols=2]
|===
|Pfad |Bedeutung 

|var/log/cmc.log |Logdatei des link:cmc.html[CMC]. Falls das Notificationdebugging eingeschaltet ist, finden Sie hier genaue Angaben, warum Alarme (nicht) erzeugt wurden.
|var/log/notify.log |Logdatei des Alarmierungsmoduls
|var/log/mkotifyd.log |Logdatei des Alarmspoolers
|var/log/mkotifyd.state |Aktueller Zustand des Alarmspoolers. Das ist hauptsächlich bei einer link:distributed_monitoring.html#notifications[verteilten Alarmierung] relevant.
|var/nagios/debug.log |Debuglogfile von Nagios. Schalten Sie Debugmeldungen in `etc/nagios/nagios.d/logging.cfg` in der Variable `debug_level` ein.
|var/check_mk/notify/spool/ |Ablage der Spooldateien, die der Alarmspooler bearbeiten soll.
|var/check_mk/notify/deferred/ |Bei temporären Fehlern verschiebt der Alarmspooler die Dateien hierher und probiert es erst nach ein paar Minuten nochmal.
|var/check_mk/notify/corrupted/ |Defekte Spooldateien werden hierher verschoben.
|share/check_mk/notifications |Von {CMK} mitgelieferte Alarmierungsskripten. Ändern Sie hier nichts.
|local/share/check_mk/notifications |Ablageort für eigene Alarmierungsskripten. Möchten Sie ein mitgeliefertes Skript anpassen, so kopieren Sie es von `share/check_mk/notifications` hierher und behalten dessen Dateinamen bei.
|share/doc/check_mk/treasures/notifications |Hier finden Sie einige Alarmierungsskripten, die Sie geringfügig anpassen und verwenden können.
|===


[#maillog]
=== Logdateien des SMTP-Diensts

Die Logdateien des SMTP-Diensts sind Systemdateien und werden hier folglich
mit absoluten Pfaden angegeben. Wo die Logdatei genau liegt, hängt von Ihrer
Distribution ab.


[cols=2]
|===
|Pfad |Bedeutung 

|/var/log/mail.log |Logdatei des SMTP-Servers unter Debian und Ubuntu
|/var/log/mail |Logdatei des SMTP-Servers unter SUSE LINUX (SLES)
|/var/log/maillog |Logdatei des SMTP-Servers unter Red Hat
|===



