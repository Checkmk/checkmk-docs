include::global_attr.adoc[]
= Das Monitoring feinjustieren
:revdate: draft
:title: Das Monitoring feinjustieren
:description: Regeln und Hostmerkmale sind wichtige und mächtige Werkzeuge, um eine ganze Reihe von Fehlalarmen in {CMK} zu vermeiden. Um diese Themen geht es im aktuellen Kapitel des Leitfadens für {CMK} Einsteiger, der kompakt durch die ersten Schritte führt, um das IT-Monitoring mit {CMK} optimal einzurichten.

{related-start}
link:intro_users.html[Mit mehreren Benutzern arbeiten]
link:wato_rules.html[Host- und Serviceparameter]
{related-end}


[#false_positives]
== Fehlalarme -- der Tod jedes Monitorings

Ein Monitoring ist nur dann wirklich nützlich, wenn es präzise
ist. Das größte Hindernis für die Akzeptanz bei Kollegen (und wohl auch
bei Ihnen selbst) sind dabei _false positives_ -- oder auf gut deutsch
*Fehlalarme*.

Bei einigen {CMK}-Einsteigern haben wir erlebt, wie diese in kurzer Zeit sehr
viele Systeme in die Überwachung aufgenommen haben -- vielleicht deswegen,
weil das in {CMK} so einfach geht. Als sie dann kurz danach die Alarmierung für
alle aktiviert haben, wurden die Kolleginnen mit Hunderten von E-Mails pro
Tag überflutet, und bereits nach wenigen Tagen war die Begeisterung für
das Monitoring nachhaltig zerstört.

Auch wenn {CMK} sich wirklich Mühe gibt, für alle möglichen Einstellungen sinnvolle und vernünftige Standardwerte zu definieren, kann es einfach nicht präzise genug wissen, wie es in Ihrer IT-Umgebung unter Normalzuständen zugehen soll. Deswegen ist von Ihrer Seite ein bisschen Handarbeit erforderlich, um das Monitoring fein zu justieren (_fine-tuning_) bis auch der letzte Fehlalarm gar nicht erst gesendet wird. Abgesehen davon wird {CMK} auch etliche wirkliche Probleme finden, von denen Sie und Ihre Kolleginnen noch nichts geahnt haben. Auch die gilt es zuerst einmalig zu beheben -- und zwar in der Realität, nicht im Monitoring!

Bewährt hat sich folgender Grundsatz: erst Qualität, dann Quantität -- oder anders ausgedrückt:

* Nehmen Sie nicht zu viele Hosts auf einmal ins Monitoring auf.
* Sorgen Sie dafür, dass alle Services, bei denen nicht wirklich ein Problem besteht, zuverlässig auf {OK} sind.
* Aktivieren Sie die Alarmierung per E-Mail oder SMS erst, wenn {CMK} eine Zeit lang zuverlässig ohne oder mit sehr wenigen Fehlalarmen läuft.

*Hinweis:* Fehlalarme können natürlich nur bei eingeschalteter Alarmierung entstehen. Worum es im folgenden also geht, ist es die Vorstufe der Alarmierung abzustellen und die kritischen Zustände {DOWN}, {WARN} oder {CRIT} für unkritische Probleme zu vermeiden.

Welche Möglichkeiten zum Fine-Tuning Sie haben (damit all das grün wird, was keine Probleme verursacht), und wie Sie gelegentliche Aussetzer in den Griff bekommen, zeigen wir Ihnen in den folgenden Kapiteln zur Konfiguration.


[#rules]
== Regelbasiert konfigurieren

// TK: Regel und Regelsatz: Den Begriff Regelkette hab ich eliminiert.

Bevor wir ans Konfigurieren gehen, müssen wir uns zuerst kurz mit den
Einstellungen von Hosts und Services in {CMK} auseinandersetzen.
Da {CMK} für große und komplexe Umgebungen entwickelt wurde, geschieht
das anhand von *Regeln*. Dieses Konzept ist sehr leistungsfähig
und bringt auch in kleineren Umgebungen viele Vorteile.

Die Grundidee ist, dass Sie nicht für jeden Service jeden einzelnen
Parameter explizit festlegen, sondern so etwas umsetzen wie:
„_Auf allen produktiven Oracle-Servern werden Dateisysteme mit dem Präfix
`/var/ora` bei 90{nbsp}% Füllgrad_ {WARN} _und
bei 95{nbsp}%_ {CRIT}.“

So eine Regel kann mit einem Schlag Schwellwerte für Tausende von Dateisystemen
festlegen. Gleichzeitig dokumentiert sie auch sehr übersichtlich, welche Überwachungsrichtlinien in Ihrem Unternehmen gelten.

Basierend auf einer Grundregel können Sie dann Ausnahmen für Einzelfälle gesondert festlegen. Eine passende Regel könnte so aussehen:
„_Auf dem Oracle-Server `srvora123` wird das Dateisystem
`/var/ora/db01` bei 96{nbsp}% Füllgrad_ {WARN} _und bei
98{nbsp}%_ {CRIT}.“
Diese Ausnahmeregel wird in {CMK} in der gleichen Art und Weise wie die Grundregel festgelegt.

// TK: Hier wurden 2 Beispiele von Regeln zum Füllgrad von Dateisystemen gegeben. In "4. Regeln erstellen" wird dann eine andere Regel zum Füllgrad von Tablespaces umgesetzt. Die Beispiele sollten zusammenpassen und das umgesetzt werden, was am Anfang als Beispiel gegeben wurde.

Jede Regel hat den gleichen Aufbau. Sie besteht immer aus einer
*Bedingung* und einem *Wert.* Zusätzlich können Sie noch
eine Beschreibung und einen Kommentar hinterlegen, um den Sinn der
Regel zu dokumentieren.

Die Regeln sind in Regelsätzen (_rulesets_) organisiert. Für jede Art von
Parameter hat {CMK} einen passenden Regelsatz parat, so dass Sie aus mehreren hundert Regelsätzen auswählen können. So gibt es etwa einen mit dem
Namen [.guihint]#Filesystems (used space and growth)#, der die Schwellwerte für
alle Services festlegt, die Dateisysteme überwachen. Um das obige Beispiel umzusetzen, würden Sie aus diesem Regelsatz die Grundregel und die Ausnahmeregel festlegen. Um festzustellen, welche Schwellwerte für ein bestimmtes Dateisystem gültig sind, geht {CMK} alle für den Check gültigen Regeln der Reihe nach durch. Die erste Regel, bei der die Bedingung zutrifft, legt den Wert fest -- also in diesem Fall den Prozentwert, bei dessen Erreichen der Dateisystemcheck {WARN} oder {CRIT} wird.
// TK2SK: Regelabarbeitung der Reihe nach: Im CMK 1 Kurs hab ich gelernt, dass dies bei den Alarmierungsregeln nicht zutrifft, da die alle abgearbeitet und ausgewertet werden. Ist das 1 Anmerkung Wert - oder verwirrt es eher, da im Kap. Alarmierung nicht um Alarmierungsregeln geht?

[#find_rules]
== Regeln finden

Sie haben verschiedene Möglichkeiten zum Zugriff auf das Regelwerk von {CMK}.

Zum einen finden Sie die Regelsätze im [.guihint]#Setup#-Menü unter den Themen der Objekte, für die es Regelsätze gibt ([.guihint]#Hosts#, [.guihint]#Services# und [.guihint]#Agents#) in verschiedenen Kategorien. Für Services gibt es die folgenden Einträge mit Regelsätzen: [.guihint]#Service monitoring rules#, [.guihint]#Discovery rules#, [.guihint]#Enforced services#, [.guihint]#HTTP, TCP, Email, ...# und [.guihint]#Other services#. Wenn Sie einen dieser Einträge auswählen, werden Ihnen die zugehörigen Regelsätze auf der Hauptseite aufgelistet. Das können eine Handvoll sein, aber auch sehr, sehr viele wie bei den [.guihint]#Service monitoring rules#. Daher haben Sie auf der Ergebnisseite die Möglichkeit zu filtern: im [.guihint]#Filter#-Feld der Menüleiste.

Wenn Sie sich unsicher sind, in welcher Kategorie der Regelsatz zu finden ist, können Sie auch gleich *alle* Regeln durchsuchen, indem Sie
entweder das link:intro_gui.html#search_setup[Suchfeld im Setup-Menü] nutzen oder über [.guihint]#Setup > General > Rule search# die Seite zur Regelsuche öffnen. Wir werden den letztgenannten Weg im folgenden Kapitel gehen, in der wir die Erstellung einer Regel vorstellen.

Bei der großen Anzahl der verfügbaren Regelsätze ist es mit oder ohne Suche nicht immer einfach, den richtigen zu finden. Es gibt aber noch einen anderen Weg, mit dem Sie auf die passenden Regeln für einen bereits existierenden Service zugreifen können. Klicken in einer Statusansicht mit dem Service auf das icon:icon_menu[] Menü und wählen Sie den Eintrag [.guihint]#Parameters for this service#:

// TK2SK: Randfrage: Wenn ich mir statt Parameters for this service aber Parameters for this host anzeigen lasse: Welche Regelsätze werden da gelistet? Ich sehe Hunderte, von denen die meisten nichts mit meinem Host zu tun haben und für die gar kein Service da ist (Oracle Databases). Was nutzt mir dann diese Liste?

image::service_rule_icon.png[]

Sie erhalten eine Seite, von der aus Sie Zugriff auf alle Regelsätze dieses Services haben:

image::parameters_of_this_service.png[]

Im ersten Kasten mit dem Titel [.guihint]#Check origin and parameters# führt Sie
der Eintrag [.guihint]#Filesystems (used space and growth)# direkt zum
Regelsatz für die Schwellwerte der Dateisystemüberwachung. Sie können aber in der Übersicht sehen, dass {CMK} bereits Standardwerte festgelegt hat, so dass Sie eine Regel nur dann erstellen müssen, wenn Sie die Standardwerte ändern wollen.

// TK2SK: Im screenshot parameters_of_this_service.png ist als Check type "Inventorized check" zu sehen: Was ist das?


[#create_rules]
== Regeln erstellen

Wie sieht das mit den Regeln nun in der Praxis aus? Am besten starten Sie damit, die Regel, die Sie umsetzen wollen, in einem Satz zu formulieren, etwa in diesem: „_Auf allen produktiven Oracle-Servern werden die Tablespaces DW20 und DW30 bei 90{nbsp}% Füllgrad_ {WARN} _und bei 95{nbsp}%_ {CRIT}.“

Dann suchen Sie sich den passenden Regelsatz -- in diesem Beispiel über die Regelsuche: [.guihint]#Setup > General > Rule search#. Dies öffnet eine Seite, in der Sie nach „Oracle“ oder nach „tablespace“ suchen können (Groß- und Kleinschreibung spielen keine Rolle) und alle Regelsätze finden, die diesen Text im Namen oder in der (hier unsichtbaren) Beschreibung enthalten:

image::ruleset_search_tablespace.png[]

Der Regelsatz [.guihint]#Oracle Tablespaces# wird in zwei Kategorien gefunden. Die Zahl hinter dem Titel (hier überall `0`) zeigt die Anzahl der Regeln, die aus diesem Regelsatz bereits erstellt wurden. Klicken Sie auf den Namen in der Kategorie [.guihint]#Service monitoring rules#, so landen Sie in der Übersichtsseite des Regelsatzes:

// TK2SK: Zahl hinter der Regel: Nachdem die Regel für den Ora Tablespace angelegt wurde, wird statt 0 nunmehr 1/1 angezeigt: Bedeutung?
// TK2SK: Wenn ein Regelsatz mehrmals gefunden wird (wie hier): Was ist der Unterschied zwischen den Kategorien? Welchen soll man nehmen? Warum nicht den unter Enforced services?

image::ruleset_oracle_tablespaces.png[]

Der Regelsatz enthält noch keine Regeln. Sie können die erste mit dem Knopf
[.guihint]#Create rule in folder# erstellen. Dabei legen Sie bereits den ersten Teil der Bedingung der Regel fest, nämlich in welchem Ordner diese gelten soll. Wenn Sie die Voreinstellung [.guihint]#Main directory# z.B. auf [.guihint]#Windows# ändern, so gilt die neue Regel nur für Hosts die direkt im oder unterhalb vom Ordner [.guihint]#Windows# liegen.

Das Anlegen (und auch das spätere Bearbeiten) der Regel bringt Sie zu einem Formular mit drei Kästen [.guihint]#Rule Properties#, [.guihint]#Value# und [.guihint]#Conditions#. Wir werden uns die drei nacheinander vornehmen.

image::rule_ora_properties.png[]

Im Kasten [.guihint]#Rule Properties# sind alle Angaben optional. Neben den informativen Texten haben Sie hier auch die Möglichkeit, eine Regel vorübergehend zu deaktivieren. Das ist praktisch, denn so vermeiden Sie manchmal
ein Löschen und Neuanlegen, wenn Sie eine Regel vorübergehend nicht benötigen.

Was Sie im Kasten [.guihint]#Value# finden, hängt individuell vom Inhalt dessen ab, was gerade geregelt wird:

image::rule_ora_value.png[]

Wie Sie sehen, kann das schon eine ganze Menge an Parametern sein. Das Beispiel zeigt einen typischen Fall: Jeder einzelne Parameter kann per Checkbox aktiviert werden, und die Regel legt dann auch nur diesen fest. Sie können z.B. einen anderen Parameter von einer anderen Regel bestimmen lassen, wenn das Ihre Konfiguration vereinfacht. Im Beispiel werden nur die Schwellwerte für den prozentualen freien Platz im Tablespace definiert.

// TK: Sowohl bei der Beschreibung der Werte (Value) als auch der Bedingungen (Conditions) sollte erwähnt werden, ob es sich um UND oder ODER-Verknüpfungen handelt.

Der Kasten [.guihint]#Conditions# zur Festlegung der Bedingung sieht auf den ersten Blick etwas unübersichtlicher aus:

image::rule_ora_condition.png[]

Wir gehen nur auf die Parameter ein, die wir für die Festlegung der Beispielregel unbedingt benötigen:

// [.guihint]#Condition type# erlaubt das Verwenden von vordefinierten Bedingungen, die über die Option [.guihint]#Predef. Conditions# verwaltet werden. Das ist ein Feature für „Poweruser“, die sehr viele Regeln mit den immer gleichen Bedingungen verwenden. Lassen Sie das zunächst einfach auf [.guihint]#Explicit conditions# stehen.

Den Ordner ([.guihint]#Folder#) haben Sie beim Erstellen der Regel bereits ausgewählt, aber hier können Sie ihn nochmal ändern.

Die Host-Merkmale ([.guihint]#Host tags#) sind ein ganz wichtiges Feature von {CMK}, deshalb widmen wir ihnen gleich im Anschluss an dieses ein eigenes Kapitel. An dieser Stelle nutzen Sie eines der vordefinierten Host-Merkmale aus, um festzulegen, dass die Regel nur für Produktivsysteme gelten soll: Wählen Sie zunächst in der Liste die Host-Merkmalgruppe [.guihint]#Criticality# aus und klicken Sie danach auf [.guihint]#Add tag condition# und wählen den Wert [.guihint]#Productive system# aus.

// Mit den [.guihint]#Explicit hosts# können Sie die Regel auf einige ganz bestimmte Hosts beschränken.

Sehr wichtig für das Beispiel sind die [.guihint]#Explicit Tablespaces#, welche die Regel auf ganz bestimmte Services einschränken. Dazu sind zwei Anmerkungen wichtig:

* Der Name dieser Bedingung passt sich dem Regeltyp an. Wenn hier [.guihint]#Explicit Services# steht, geben Sie die *Namen* der betroffenen Services an. Ein solcher könnte z.B. `Tablespace DW20` lauten -- also inklusive des Worts `Tablespace`. Im gezeigten Beispiel hingegen möchte {CMK} von Ihnen lediglich den Namen des Tablespaces selbst wissen, also z.B. `DW20`.

* Die eingegebenen Texte werden immer gegen den Anfang gematcht. Die Eingabe von `DW20` greift also auch auf einen fiktiven Tablespace `DW20A`. Wenn Sie das verhindern möchten, hängen Sie das Zeichen `$` an das Ende an, also `DW20$`, denn es handelt sich hier um sogenannte link:regexes.html[reguläre Ausdrücke].

*Hinweis:* Die detaillierte Beschreibung aller anderen Parameter und eine ausführliche Erklärung zum wichtigen Konzept der Regeln finden Sie im link:wato_rules.html[Artikel über Regeln]. Mehr zu den [.guihint]#Service labels#, dem letzten Parameter im obigen Bild, erfahren Sie übrigens im link:labels.html[Artikel über Labels].

Nachdem alle Eingaben zur Festlegung komplett sind, sichern Sie die Regel mit [.guihint]#Save#. Nach dem Speichern findet sich im Regelsatz genau die eine neue Regel:

[{image-border}]
image::ruleset_ora_one_rule.png[]

*Tipp:* Wenn Sie statt mit einer später mit Hunderten von Regeln arbeiten, droht die Gefahr, den Überblick zu verlieren. {CMK} bietet auf jeder Seite, die Regeln auflisten, im Menü [.guihint]#Related# sehr hilfreiche Einträge an, um den Überblick zu behalten: Sie können sich die in der aktuellen Instanz genutzten Regeln anzeigen lassen ([.guihint]#Used rulesets#) und umgekehrt auch die, die gar nicht genutzt werden ([.guihint]#Ineffective rules#).


[#host_tags]
== Host-Merkmale (host tags)

=== So funktionieren Host-Merkmale

Im vorherigen Kapitel haben wir ein Beispiel für eine Regel gesehen, die nur für „produktive“ Systeme gelten soll. Genauer gesagt haben wir in der Regel
eine Bedingung über das Host-Merkmal (_host tag_) [.guihint]#Productive system# definiert. Warum haben wir die Bedingung als Merkmal definiert und sie nicht einfach für den Ordner festgelegt? Nun, Sie können nur eine einzige Ordnerstruktur definieren, und jeder Host kann nur in einem Ordner sein. Es gibt aber viele unterschiedliche Merkmale, die ein Host haben kann. Dafür ist die Ordnerstruktur zu beschränkt und nicht flexibel genug.

Dagegen können Sie Host-Merkmale den Hosts völlig frei und beliebig zuordnen -- egal, in welchem Ordner sich die Hosts befinden. In Ihren Regeln können Sie sich dann auf diese Merkmale beziehen. Das macht die Konfiguration nicht nur einfacher, sondern auch leichter verständlich und weniger fehleranfällig, als wenn Sie für jeden Host alles explizit festlegen würden.

Aber wie und wo legt man nun fest, welche Hosts welche Merkmale haben sollen? Und wie können Sie eigene Merkmale definieren?


=== Host-Merkmale definieren

Beginnen wir mit der Antwort auf die zweite Frage nach eigenen Merkmalen. Zunächst müssen Sie wissen, dass Merkmale in Gruppen organisiert sind, den sogenannten Host-Merkmalsgruppen (_host tag groups_). Nehmen wir als Beispiel den Standort (_location_). Eine Merkmalsgruppe könnte _Location_ heißen, und diese Gruppe könnte die Merkmale _Munich_,
_Austin_ und _Singapore_ enthalten. Grundsätzlich gilt dabei, dass
jedem Host aus jeder Merkmalsgruppe *genau ein Merkmal* zugewiesen wird. Sobald Sie also eine eigene Merkmalsgruppe definieren, trägt *jeder* Host eines der Merkmale aus dieser Gruppe. Hosts, bei denen Sie kein Merkmal aus der Gruppe gewählt haben, bekommen einfach per Default das erste zugewiesen.

Die Definition der Host-Merkmalsgruppen finden Sie im [.guihint]#Setup#-Menü: [.guihint]#Setup > Hosts > Tags#:

image::wato_tag_groups.png[]

Wie Sie sehen, sind einige Merkmalsgruppen bereits vordefiniert. Die meisten davon können Sie nicht ändern. Wir empfehlen Ihnen außerdem, die beiden vordefinierten Beispielgruppen [.guihint]#Criticality# und [.guihint]#Networking Segment# nicht anzutasten. Definieren Sie lieber Ihre eigenen Gruppen:

Klicken Sie auf [.guihint]#Add tag group#. Dies öffnet die Seite zum Erstellen einer neuen Merkmalsgruppe. Im ersten Kasten [.guihint]#Basic settings# vergeben Sie -- wie so oft in {CMK} -- eine interne ID, die als Schlüssel dient und später nicht mehr geändert werden kann. Zusätzlich zur ID legen Sie einen sprechenden Titel fest, den Sie später jederzeit ändern können. Mit [.guihint]#Topic# können Sie bestimmen, wo das Merkmal bei den Eigenschaften des Hosts später angeboten wird. Wenn Sie hier ein neues Topic erstellen, wird das Merkmal bei den Host-Eigenschaften in einem eigenen Kasten angezeigt.

// TK: Unter Basic settings (new_taggroup_basic.png) ist Help nicht beschrieben.

image::new_taggroup_basic.png[]

Im zweiten Kasten [.guihint]#Tag choices# geht es um die eigentlichen Merkmale, also die Auswahlmöglichkeiten der Gruppe. Klicken Sie [.guihint]#Add tag choice# um ein Merkmal zu erstellen und vergeben Sie auch hier pro Merkmal eine interne ID und einen Titel:

image::new_taggroup_choices.png[]

Hinweise:

* Die IDs müssen über alle Gruppen hinweg eindeutig sein.
* Auch Gruppen mit nur einer einzigen Auswahl sind erlaubt und sogar sinnvoll. Diese erscheinen dann als Checkboxen. Jeder Host hat dann das Merkmal --  oder eben nicht.
* An dieser Stelle können Sie die Hilfsmerkmale (_auxiliary tags_) erstmal ignorieren. Sie erhalten alle Informationen zu Hilfsmerkmalen im speziellen und zu Host-Merkmalen im allgemeinen im link:wato_rules.html[Artikel über Regeln].

Sobald Sie mit [.guihint]#Save# die neue Host-Merkmalsgruppe gesichert haben, können Sie sie nutzen.


=== Ein Merkmal einem Host zuordnen

Wie Sie einem Host Merkmale zuordnen, haben Sie schon gesehen: in den
Host-Eigenschaften beim Erstellen oder Bearbeiten eines Hosts. Im Kasten
[.guihint]#Custom attributes# (oder in einem eigenen, falls Sie ein Topic erstellt haben) taucht nun die neue Host-Merkmalsgruppe auf, und Sie können für den Host die Auswahl treffen und das Merkmal festlegen:

image::host_custom_attributes.png[]

// TK: Hier wäre es schön, ein Bsp. anzufügen, wie die Location einzusetzen ist: Im Snapin Virtual Host Tree nach vorheriger Konfiguration unter Global Settings > User Interface > Virtual Host Trees.

Nachdem Sie jetzt die wichtigen Prinzipien der Konfiguration mit Regeln und Host-Merkmalen kennengelernt haben, möchten wir Ihnen in den restlichen Kapiteln einige konkrete Empfehlungen geben, um in einem neuen {CMK}-System Fehlalarme zu reduzieren.


[#filesystems]
== Dateisystem-Schwellwerte anpassen

Überprüfen Sie die Schwellwerte für die Überwachung von Dateisystemen und passen Sie diese gegebenenfalls an. Die Standardwerte hatten wir bereits   weiter oben bei der link:intro_finetune.html#find_rules[Suche nach Regeln] kurz gezeigt.

Per Default nimmt {CMK} beim Füllgrad von Dateisystemen die Schwellen 80{nbsp}% für {WARN} und 90{nbsp}% für {CRIT}. Nun sind 80{nbsp}% bei einer 2{nbsp}TByte großen Festplatte immerhin 400{nbsp}GByte -- vielleicht ein bisschen viel
Puffer für eine Warnung. Daher hier ein paar Tipps zum Thema Dateisysteme:

* Legen Sie Ihre eigenen Regeln an im Regelsatz [.guihint]#Filesystem (used space and growth)#.
* Die Parameter erlauben Schwellwerte, die von der Größe des Dateisystems abhängen. Wählen Sie dazu [.guihint]#Levels for filesystems > Levels for filesystem used space > Dynamic levels#. Mit dem Knopf [.guihint]#Add new element# definieren Sie jetzt pro Plattengröße eigene Schwellwerte.
* Noch einfacher geht es mit dem [.guihint]#Magic factor#, den wir im link:intro_bestpractise.html#magic_factor[letzten Kapitel] vorstellen.


[#hosts_downtime]
== Hosts in die Wartung schicken

Manche Server werden turnusmäßig neu gestartet -- sei es, um Patches einzuspielen oder einfach, weil das so vorgesehen ist. Sie können Fehlalarme zu diesen Zeiten auf zwei Arten vermeiden:

{cre-only}
In der {CRE} definieren Sie zunächst eine Zeitperiode (_timeperiod_), welche die Zeiten des Reboots abdeckt. Wie das geht, erfahren Sie im link:timeperiods.html[Artikel über Zeitperioden]. Danach legen Sie jeweils eine Regel in den Regelsätzen [.guihint]#Notification period for hosts# und [.guihint]#Notification period for services# für die betroffenen Hosts an und wählen dort die zuvor definierte Zeitperiode aus. Die zweite Regel für die Services ist nötig, damit auch Services, die in dieser Zeit auf {CRIT} gehen, keinen Alarm auslösen. Falls nun während dieser Zeiten Probleme auftreten (und rechtzeitig wieder verschwinden), wird keine Alarmierung ausgelöst.

// TK2SK: Die einführende Beschreibung der Hilfe der Regelsätze "Notification period for hosts" + "Notification period for services" liest sich so, als ob das Gegenteil dessen gemacht wird, was gewollt ist, eben KEINE Notifications zu versenden: "If you specify a notification period for a host then notifications about problems of that host (not of its services!) will only be sent if those problems occur within the notification period. ..."

{cee-only}
In den {CEE} gibt es regelmäßige Wartungszeiten für diesen Zweck, die Sie für die betroffenen Hosts setzen können.

*Tipp:* Eine Alternative zur Erstellung von Wartungszeiten für Hosts, die wir im link:intro_monitor.html#downtimes[Kapitel über Wartungszeiten] schon beschrieben haben, ist in den {EE} der Regelsatz [.guihint]#Recurring downtimes for hosts#. Dieser hat den großen Vorteil, dass auch Hosts, die erster später in die Überwachung aufgenommen werden, automatisch diese Wartungszeiten erhalten.


[#hosts_down]
== Abgeschaltete Hosts ignorieren

Nicht immer ist es ein Problem, wenn ein Rechner abgeschaltet wird. Ein klassisches Beispiel sind Drucker. Diese mit {CMK} zu überwachen ist durchaus sinnvoll. Manche Anwender organisieren sogar die Nachbestellung von Toner
mit {CMK}. In aller Regel ist aber das Ausschalten eines Druckers vor Feierabend kein Problem. Dumm ist nur, wenn {CMK} hier alarmiert, weil der entsprechende Host {DOWN} ist.

Sie können {CMK} mitteilen, dass es völlig in Ordnung ist, wenn ein Host ausgeschaltet ist. Dazu suchen Sie den Regelsatz [.guihint]#Host check command# und setzen Sie den Wert auf [.guihint]#Always assume host to be up#:

image::host_check_command.png[]

Stellen Sie im Kasten [.guihint]#Conditions# sicher, dass diese Regel wirklich nur auf die passenden Hosts angewendet wird -- je nach der von Ihnen gewählten Struktur. Sie können dazu z.B. ein Host-Merkmal definieren und hier nutzen oder Sie können die Regel über einen Ordner festlegen, in dem sich alle Drucker befinden.

Jetzt werden alle Drucker grundsätzlich als {UP} angezeigt -- egal, wie ihr Status tatsächlich ist.

Die Services des Druckers werden allerdings weiterhin geprüft und ein Timeout
würde zu einem {CRIT} Zustand führen. Um auch dies zu vermeiden, konfigurieren Sie für die betroffenen Hosts im Regelsatz [.guihint]#Status of the {CMK} services#
eine Regel, in der Sie Timeouts und Verbindungsprobleme jeweils auf {OK} setzen:

image::rule_status_of_cmk_services.png[]


[#switchports]
== Switchports konfigurieren

Wenn Sie mit {CMK} einen Switch überwachen, dann werden Sie feststellen, dass bei der Service-Konfiguration automatisch für jeden Port, der zu dem Zeitpunkt {UP} ist, ein Service angelegt wird. Dies ist eine sinnvolle Standardeinstellung für Core- und Distribution-Switches -- also solche, an denen nur Infrastrukturgeräte oder Server angeschlossen sind. Bei Switches, an denen Endgeräte wie Arbeitsplätze oder Drucker angeschlossen sind, führt das aber einerseits zu ständigen Alarmen, falls ein Port auf {DOWN} geht, und andererseits zu ständig neu gefundenen Services, weil ein bisher nicht überwachter Port umgekehrt {UP} geht.

Hier haben sich zwei Vorgehensweisen bewährt: So können Sie erstens die Überwachung auf die Uplink-Ports beschränken. Dazu legen Sie eine Regel bei den link:intro_finetune.html#services_disabled[deaktivierten Services] an, welche die anderen Ports von der Überwachung ausschließt.
// TK2SK: Überwachung auf die Uplink-Ports: Ist das verständlich? Oder andersrum: Ich versteh das nicht.

Viel interessanter ist jedoch die zweite Methode: Hier überwachen Sie zwar alle Ports, erlauben aber den Zustand {DOWN} als gültigen Zustand. Der Vorteil: Auch für Ports, an denen Endgeräte hängen, haben Sie eine Überwachung der Übertragungsfehler und erkennen so sehr schnell schlechte Patchkabel oder Fehler in der Autonegotiation. Um das umzusetzen, benötigen Sie zwei Regeln:

Der erste Regelsatz [.guihint]#Network interface and switch port discovery# legt fest, unter welchen Bedingungen Switchports überwacht werden sollen. Legen Sie eine Regel für die gewünschten Switches an und wählen Sie aus, ob einzelne Interfaces ([.guihint]#Configure discovery of single interfaces#) oder Gruppen ([.guihint]#Configure grouping of interfaces#) gefunden werden sollen. Aktivieren Sie dann unter [.guihint]#Conditions for this rule to apply > Match port states# zusätzlich zu  [.guihint]#1 - up# auch [.guihint]#2 - down#:

image::port_discovery.png[]

// TK: Der Regelsatz "Network interface and switch port discovery" sieht in der 2.0 komplett anders aus als in der 1.6. Bin nicht sicher, ob das mit den von mir gewählten Einstellungen so funktioniert, wie es funktionieren soll.

In der Service-Konfiguration der Switches werden nun auch die Ports mit dem Zustand {DOWN} angeboten, und Sie können sie zur Liste der überwachten Services hinzufügen. Bevor Sie die Änderung aktivieren, benötigen Sie noch die zweite Regel, die dafür sorgt, dass dieser Zustand als {OK} gewertet wird.

Der Regelsatz heißt [.guihint]#Network interfaces and switch ports#. Erstellen Sie eine neue Regel und aktivieren Sie die Option [.guihint]#Operational state#, deaktivieren Sie darunter [.guihint]#Ignore the operational state# und aktivieren Sie dann bei den [.guihint]#Allowed operational states# die Zustände [.guihint]#1 - up# und [.guihint]#2 - down# (und eventuell weitere Zustände).


[#services_disabled]
== Services dauerhaft deaktivieren

Bei manchen Services, die einfach nicht zuverlässig auf {OK} zu bekommen sind, ist es am Ende besser, sie gar nicht zu überwachen. Hier könnten Sie nun einfach bei den betroffenen Hosts in der Service-Konfiguration (auf der Seite [.guihint]#Services of host#) die Services manuell aus der Überwachung herausnehmen, indem Sie sie auf [.guihint]#Undecided# setzen. Dies ist aber umständlich und fehleranfällig.

Viel besser ist es, wenn Sie Regeln definieren, nach denen bestimmte Services *systematisch* nicht überwacht werden. Dafür gibt es den Regelsatz [.guihint]#Disabled services#. Hier können Sie z.B. eine Regel anlegen, nach der Dateisysteme mit dem Mount-Punkt `/var/test` grundsätzlich nicht überwacht werden sollen.

*Tipp:* Wenn Sie in der Service-Konfiguration eines Hosts einen einzelnen Service durch Klick auf icon:icon_service_to_disabled[] deaktivieren, wird für den Host automatisch eine Regel in eben diesem Regelsatz angelegt. Diese Regel können Sie manuell bearbeiten und z.B. den expliziten Hostnamen entfernen. Dann wird der betroffene Service auf allen Hosts abgeschaltet.

Weitere Informationen können Sie im link:wato_services.html[Artikel über die Konfiguration von Services] nachlesen.


[#average_value]
== Durch Mittelwert Ausreißer abfangen

Ein Grund für sporadische Alarmierungen sind oft Schwellwerte auf Auslastungsmetriken, wie z.B. die CPU-Auslastung (_CPU utilization_), die nur kurzfristig überschritten werden. In der Regel sind solche kurzen Spitzen kein Problem und sollten vom Monitoring auch nicht bemängelt werden.

Aus diesem Grund haben eine ganze Reihe von Check-Plugins in ihrer Konfiguration die Möglichkeit, dass die Messwerte vor der Anwendung der Schwellen über einen längeren Zeitraum gemittelt werden. Ein Beispiel dafür ist der Regelsatz für die CPU-Auslastung für nicht-Unix-Systeme mit dem Namen [.guihint]#CPU utilization for simple devices#. Hier gibt es den Parameter [.guihint]#Averaging for total CPU utilization#:

image::cpu_util_average.png[]

Wenn Sie diesen aktivieren und `15` eintragen, wird die CPU-Auslastung zunächst über einen Zeitraum von 15 Minuten gemittelt und die Schwellwerte erst danach auf diesen Mittelwert angewendet.


[#sporadic_errors]
== Sporadische Fehler kontrollieren

Wenn alles nichts hilft und Services immer wieder gelegentlich für einen einzelnen Check (also für eine Minute) auf {WARN} oder {CRIT} gehen, gibt es eine letzte Methode, die Fehlalarme verhindert: den Regelsatz [.guihint]#Maximum number of check attempts for service#.

Legen Sie dort eine Regel an und setzen Sie den Wert z.B. auf `3`, so
wird ein Service, der z.B. von {OK} auf {WARN} geht, zunächst noch keine
Alarmierung auslösen und auch im [.guihint]#Overview# noch nicht als
Problem angezeigt werden. Der Zwischenzustand, in dem sich der Service befindet wird als „weicher Zustand“ (_soft state_) bezeichnet. Erst wenn der Zustand in drei aufeinanderfolgenden Checks (was insgesamt dann knapp über zwei Minuten dauert) nicht {OK} ist, wird das hartnäckige Problem gemeldet. Nur ein harter Zustand (_hard state_) löst eine Alarmierung aus.
// TK: Hard state vs. soft state (harter Zustand vs. weicher Zustand): Ich finde die existierenden Beschreibungen verbesserungsfähig (monitoring_basics.html#checkintervall und availability.html#softstates). Insbesondere fehlt die Definition des hard state und wie sich der soft state in der GUI bemerkbar macht.
// Im link:monitoring_basics.html#checkintervall[Artikel über die Grundlagen des Monitorings] erhalten Sie mehr Informationen zur Konfiguration der Checks.

Das ist zugegeben keine schöne Lösung. Sie sollten immer versuchen, das Problem
an der Wurzel zu packen, aber manchmal sind die Dinge einfach so, wie sie sind,
und mit den „check attempts“ haben Sie für solche Fälle zumindest einen
gangbaren Weg zur Umgehung.


[#discovery]
== Liste der Services aktuell halten

In einem Rechenzentrum wird ständig gearbeitet, und so wird die Liste der zu überwachenden Services nie konstant bleiben. Damit Sie dabei möglichst nichts übersehen, richtet {CMK} für Sie automatisch einen besonderen Service auf jedem Host ein. Dieser heißt [.guihint]#Check_MK Discovery#:

image::discovery_service.png[]

Dieser prüft in der Voreinstellung alle zwei Stunden, ob neue (noch nicht überwachte) Services gefunden oder bestehende weggefallen sind. Ist dies der Fall, so geht der Service auf {WARN}. Sie können dann die Service-Konfiguration aufrufen (auf der Seite [.guihint]#Services of host#) und die Services wieder auf den aktuellen Stand bringen.

Detaillierte Informationen zu diesem „Discovery Check“ erhalten Sie im link:wato_services.html#discovery_check[Artikel über die Konfiguration von Services]. Dort erfahren Sie auch, wie Sie nicht überwachte Services automatisch hinzufügen lassen können, was die Arbeit in großen Konfiguration erheblich erleichtert.

*Tipp:* Über [.guihint]#Monitor > Analyze > Unmonitored services# können Sie sich eine Statusansicht aufrufen, die Ihnen die neuen und weggefallenen Services anzeigt.
// Diese können Sie dann regelmäßig abarbeiten.

// *Tipp:* Manche Anwender speichern ein Lesezeichen für eine Statusansicht, die alle Discovery-Services auf allen Hosts zeigt, die nicht im Zustand {OK} sind. Diese können Sie dann regelmäßig -- z.B. einmal pro Tag -- abarbeiten.

link:intro_users.html[Weiter geht es mit mehreren Benutzern]
